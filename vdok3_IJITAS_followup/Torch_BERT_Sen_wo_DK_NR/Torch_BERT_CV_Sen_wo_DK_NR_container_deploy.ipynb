{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Sending build context to Docker daemon  40.45kB\n",
      "Step 1/32 : FROM nvidia/cuda:10.0-cudnn7-devel-ubuntu16.04\n",
      " ---> 225b79605de8\n",
      "Step 2/32 : RUN apt-get -y update && apt-get -y upgrade && apt-get install -y --no-install-recommends          curl          git          unzip          bzip2          libgl1-mesa-glx          wget          nginx          ca-certificates     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> f81dac796496\n",
      "Step 3/32 : RUN git clone https://github.com/pyenv/pyenv.git .pyenv\n",
      " ---> Using cache\n",
      " ---> 29b7049525ea\n",
      "Step 4/32 : WORKDIR /\n",
      " ---> Using cache\n",
      " ---> 1794dc1050f9\n",
      "Step 5/32 : ENV HOME  /\n",
      " ---> Using cache\n",
      " ---> 710d1b71c6eb\n",
      "Step 6/32 : ENV PYENV_ROOT /.pyenv\n",
      " ---> Using cache\n",
      " ---> a30013e47bf5\n",
      "Step 7/32 : ENV PATH $PYENV_ROOT/shims:$PYENV_ROOT/bin:$PATH\n",
      " ---> Using cache\n",
      " ---> a48564c82db3\n",
      "Step 8/32 : RUN pyenv install anaconda3-5.0.0\n",
      " ---> Using cache\n",
      " ---> c3ed4ddab997\n",
      "Step 9/32 : RUN pyenv global anaconda3-5.0.0\n",
      " ---> Using cache\n",
      " ---> 65c508120e0b\n",
      "Step 10/32 : RUN pyenv rehash\n",
      " ---> Using cache\n",
      " ---> 66bdb3840a4d\n",
      "Step 11/32 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> 6047104a257b\n",
      "Step 12/32 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> d8cb40faabaf\n",
      "Step 13/32 : ENV PATH=\"/opt/program:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 51bceb4a60c8\n",
      "Step 14/32 : ENV PYTHONIOENCODING=utf-8\n",
      " ---> Using cache\n",
      " ---> c8a745d7115b\n",
      "Step 15/32 : WORKDIR /opt/program\n",
      " ---> Using cache\n",
      " ---> 6de9a03efd99\n",
      "Step 16/32 : RUN git clone https://github.com/mack-the-psych/plimac3.git\n",
      " ---> Using cache\n",
      " ---> 8c10524ee2be\n",
      "Step 17/32 : RUN echo \"/opt/program/plimac3/Lib\" > /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/plimac-custom.pth\n",
      " ---> Using cache\n",
      " ---> 1f685b3e7033\n",
      "Step 18/32 : RUN echo \"/opt/program/plimac3/Tools\" >> /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/plimac-custom.pth\n",
      " ---> Using cache\n",
      " ---> e870aaa642ef\n",
      "Step 19/32 : RUN conda install -c anaconda setuptools\n",
      " ---> Using cache\n",
      " ---> 06877fef41d7\n",
      "Step 20/32 : RUN pip install --upgrade pip &&     pip install tensorflow-gpu==1.14.0 --user &&     pip install ml_metrics==0.1.4 &&     pip install --upgrade scipy==1.1.0 &&     conda clean --all &&     conda install pytorch==1.0.0 torchvision==0.2.1 cuda100 -c pytorch &&     pip install torchtext==0.4.0 &&     pip install attrdict==2.0.1 &&     pip uninstall --yes numpy &&     pip install numpy==1.16.4 &&     pip uninstall --yes gast &&     pip install gast==0.2.2 &&     pip install -U gevent==1.4.0 --ignore-installed &&     pip install gunicorn\n",
      " ---> Using cache\n",
      " ---> 5d94a0ac1fc5\n",
      "Step 21/32 : WORKDIR /opt/program\n",
      " ---> Using cache\n",
      " ---> 9c91bc6c5f5f\n",
      "Step 22/32 : RUN git clone https://github.com/mack-the-psych/vdok3.git\n",
      " ---> Using cache\n",
      " ---> 9e1d3284468b\n",
      "Step 23/32 : RUN echo \"/opt/program/vdok3/prep\" > /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/vdok3-custom.pth\n",
      " ---> Using cache\n",
      " ---> b9ef5d6f32ed\n",
      "Step 24/32 : RUN echo \"/opt/program/vdok3/extract\" >> /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/vdok3-custom.pth\n",
      " ---> Using cache\n",
      " ---> ed3b292d0e77\n",
      "Step 25/32 : RUN echo \"/opt/program/vdok3/process\" >> /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/vdok3-custom.pth\n",
      " ---> Using cache\n",
      " ---> 0da41942eca6\n",
      "Step 26/32 : RUN echo \"/opt/program/vdok3/reorganize\" >> /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/vdok3-custom.pth\n",
      " ---> Using cache\n",
      " ---> ce0aab64eaf8\n",
      "Step 27/32 : RUN echo \"/opt/program/vdok3/train\" >> /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/vdok3-custom.pth\n",
      " ---> Using cache\n",
      " ---> 3b7fa4f87f53\n",
      "Step 28/32 : RUN echo \"/opt/program/vdok3/train/pytorch_advanced/nlp_sentiment_bert\" >> /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/vdok3-custom.pth\n",
      " ---> Using cache\n",
      " ---> 0da9f8e55dcf\n",
      "Step 29/32 : WORKDIR /opt/program/vdok3/train/pytorch_advanced/nlp_sentiment_bert\n",
      " ---> Using cache\n",
      " ---> 85c4183b3e50\n",
      "Step 30/32 : RUN python make_folders_and_data_downloads.py\n",
      " ---> Using cache\n",
      " ---> 2125e32b7b14\n",
      "Step 31/32 : COPY vdok3_sage /opt/program\n",
      " ---> f88223f9c732\n",
      "Step 32/32 : WORKDIR /opt/program\n",
      " ---> Running in 992d2037be03\n",
      "Removing intermediate container 992d2037be03\n",
      " ---> aaa6ce57afdd\n",
      "Successfully built aaa6ce57afdd\n",
      "Successfully tagged sagemaker-vdok3-bert-cv-sen-wo-dknr:latest\n",
      "The push refers to repository [822408253028.dkr.ecr.us-west-2.amazonaws.com/sagemaker-vdok3-bert-cv-sen-wo-dknr]\n",
      "cd9d737593e3: Preparing\n",
      "eb94f24f5ad7: Preparing\n",
      "be23f8a4ed08: Preparing\n",
      "2333bf2d8c34: Preparing\n",
      "bcf0b9fb86f7: Preparing\n",
      "d1c87b4917ba: Preparing\n",
      "1379185bec41: Preparing\n",
      "34c09c07d44f: Preparing\n",
      "8da672bd8fef: Preparing\n",
      "301342a5ac2c: Preparing\n",
      "3ac2454fe7ca: Preparing\n",
      "9b9ef40c3fb2: Preparing\n",
      "49fa2998b485: Preparing\n",
      "72400ed43881: Preparing\n",
      "97e5b4ec388b: Preparing\n",
      "b20c62adb3cf: Preparing\n",
      "bf18a6c0e470: Preparing\n",
      "0de0186b0e0f: Preparing\n",
      "d152753df06e: Preparing\n",
      "653349137921: Preparing\n",
      "e71e95da3d2b: Preparing\n",
      "6d2269456418: Preparing\n",
      "521a1bca4c9e: Preparing\n",
      "0fd113e52582: Preparing\n",
      "9fd67b1e1831: Preparing\n",
      "f1c9680a678d: Preparing\n",
      "fa4b3468268c: Preparing\n",
      "66ad31b9547f: Preparing\n",
      "8d897fc1271a: Preparing\n",
      "b0c360818224: Preparing\n",
      "d35aa7fd29b6: Preparing\n",
      "c0eeb6e15fd7: Preparing\n",
      "91cba8fa7129: Preparing\n",
      "d152753df06e: Waiting\n",
      "653349137921: Waiting\n",
      "e71e95da3d2b: Waiting\n",
      "6d2269456418: Waiting\n",
      "521a1bca4c9e: Waiting\n",
      "0fd113e52582: Waiting\n",
      "9fd67b1e1831: Waiting\n",
      "fa4b3468268c: Waiting\n",
      "66ad31b9547f: Waiting\n",
      "8d897fc1271a: Waiting\n",
      "b0c360818224: Waiting\n",
      "d35aa7fd29b6: Waiting\n",
      "c0eeb6e15fd7: Waiting\n",
      "91cba8fa7129: Waiting\n",
      "f1c9680a678d: Waiting\n",
      "d1c87b4917ba: Waiting\n",
      "1379185bec41: Waiting\n",
      "34c09c07d44f: Waiting\n",
      "9b9ef40c3fb2: Waiting\n",
      "8da672bd8fef: Waiting\n",
      "301342a5ac2c: Waiting\n",
      "3ac2454fe7ca: Waiting\n",
      "49fa2998b485: Waiting\n",
      "72400ed43881: Waiting\n",
      "bf18a6c0e470: Waiting\n",
      "0de0186b0e0f: Waiting\n",
      "97e5b4ec388b: Waiting\n",
      "b20c62adb3cf: Waiting\n",
      "cd9d737593e3: Pushed\n",
      "2333bf2d8c34: Pushed\n",
      "bcf0b9fb86f7: Pushed\n",
      "be23f8a4ed08: Pushed\n",
      "1379185bec41: Pushed\n",
      "34c09c07d44f: Pushed\n",
      "d1c87b4917ba: Pushed\n",
      "9b9ef40c3fb2: Pushed\n",
      "8da672bd8fef: Pushed\n",
      "49fa2998b485: Pushed\n",
      "97e5b4ec388b: Pushed\n",
      "b20c62adb3cf: Pushed\n",
      "bf18a6c0e470: Pushed\n",
      "72400ed43881: Pushed\n",
      "3ac2454fe7ca: Pushed\n",
      "d152753df06e: Pushed\n",
      "eb94f24f5ad7: Pushed\n",
      "6d2269456418: Pushed\n",
      "653349137921: Pushed\n",
      "0fd113e52582: Pushed\n",
      "e71e95da3d2b: Pushed\n",
      "9fd67b1e1831: Pushed\n",
      "f1c9680a678d: Pushed\n",
      "fa4b3468268c: Pushed\n",
      "8d897fc1271a: Pushed\n",
      "66ad31b9547f: Pushed\n",
      "b0c360818224: Pushed\n",
      "d35aa7fd29b6: Pushed\n",
      "c0eeb6e15fd7: Pushed\n",
      "521a1bca4c9e: Pushed\n",
      "91cba8fa7129: Pushed\n",
      "0de0186b0e0f: Pushed\n",
      "301342a5ac2c: Pushed\n",
      "latest: digest: sha256:5771639581e30892c91fa35d90d1697e44eb0532c2f1482340df0aafe640e7e4 size: 7229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.5 ms, sys: 781 µs, total: 21.2 ms\n",
      "Wall time: 5min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "# Makoto.Sano@Mack-the-Psych.com\n",
    "algorithm_name=sagemaker-vdok3-bert-cv-sen-wo-dknr\n",
    "\n",
    "cd container\n",
    "\n",
    "chmod +x vdok3_sage/train\n",
    "chmod +x vdok3_sage/serve\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build  -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "# Makoto.Sano@Mack-the-Psych.com\n",
    "prefix = 'vdok3_bert_cv_sen_wo_dknr'\n",
    "\n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sess = sage.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIRECTORY = 'data'\n",
    "\n",
    "data_location = sess.upload_data(WORK_DIRECTORY, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-17 03:59:48 Starting - Starting the training job...\n",
      "2021-08-17 04:00:11 Starting - Launching requested ML instancesProfilerReport-1629172787: InProgress\n",
      "......\n",
      "2021-08-17 04:01:12 Starting - Preparing the instances for training.........\n",
      "2021-08-17 04:02:38 Downloading - Downloading input data\n",
      "2021-08-17 04:02:38 Training - Downloading the training image.....................\n",
      "2021-08-17 04:06:16 Training - Training image download completed. Training in progress...\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34mStarting the training.\u001b[0m\n",
      "\u001b[34mbert.embeddings.word_embeddings.weight→embeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.position_embeddings.weight→embeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.token_type_embeddings.weight→embeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.gamma→embeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.beta→embeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.weight→encoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.bias→encoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.weight→encoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.bias→encoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.weight→encoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.bias→encoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.weight→encoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.bias→encoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.gamma→encoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.beta→encoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.weight→encoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.bias→encoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.weight→encoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.bias→encoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.gamma→encoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.beta→encoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.weight→encoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.bias→encoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.weight→encoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.bias→encoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.weight→encoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.bias→encoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.weight→encoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.bias→encoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.gamma→encoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.beta→encoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.weight→encoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.bias→encoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.weight→encoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.bias→encoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.gamma→encoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.beta→encoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.weight→encoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.bias→encoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.weight→encoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.bias→encoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.weight→encoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.bias→encoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.weight→encoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.bias→encoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.gamma→encoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.beta→encoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.weight→encoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.bias→encoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.weight→encoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.bias→encoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.gamma→encoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.beta→encoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.weight→encoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.bias→encoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.weight→encoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.bias→encoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.weight→encoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.bias→encoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.weight→encoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.bias→encoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.gamma→encoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.beta→encoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.weight→encoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.bias→encoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.weight→encoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.bias→encoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.gamma→encoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.beta→encoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.weight→encoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.bias→encoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.weight→encoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.bias→encoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.weight→encoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.bias→encoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.weight→encoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.bias→encoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.gamma→encoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.beta→encoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.weight→encoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.bias→encoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.weight→encoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.bias→encoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.gamma→encoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.beta→encoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.weight→encoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.bias→encoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.weight→encoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.bias→encoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.weight→encoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.bias→encoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.weight→encoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.bias→encoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.gamma→encoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.beta→encoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.weight→encoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.bias→encoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.weight→encoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.bias→encoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.gamma→encoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.beta→encoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.weight→encoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.bias→encoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.weight→encoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.bias→encoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.weight→encoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.bias→encoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.weight→encoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.bias→encoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.gamma→encoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.beta→encoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.weight→encoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.bias→encoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.weight→encoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.bias→encoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.gamma→encoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.beta→encoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.weight→encoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.bias→encoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.weight→encoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.bias→encoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.weight→encoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.bias→encoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.weight→encoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.bias→encoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.gamma→encoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.beta→encoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.weight→encoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.bias→encoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.weight→encoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.bias→encoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.gamma→encoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.beta→encoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.weight→encoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.bias→encoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.weight→encoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.bias→encoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.weight→encoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.bias→encoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.weight→encoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.bias→encoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.gamma→encoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.beta→encoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.weight→encoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.bias→encoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.weight→encoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.bias→encoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.gamma→encoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.beta→encoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.weight→encoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.bias→encoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.weight→encoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.bias→encoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.weight→encoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.bias→encoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.weight→encoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.bias→encoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.gamma→encoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.beta→encoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.weight→encoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.bias→encoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.weight→encoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.bias→encoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.gamma→encoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.beta→encoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.weight→encoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.bias→encoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.weight→encoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.bias→encoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.weight→encoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.bias→encoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.weight→encoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.bias→encoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.gamma→encoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.beta→encoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.weight→encoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.bias→encoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.weight→encoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.bias→encoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.gamma→encoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.beta→encoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.weight→encoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.bias→encoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.weight→encoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.bias→encoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.weight→encoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.bias→encoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.weight→encoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.bias→encoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.gamma→encoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.beta→encoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.weight→encoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.bias→encoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.weight→encoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.bias→encoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.gamma→encoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.beta→encoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.weight→pooler.dense.weight\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.bias→pooler.dense.bias\u001b[0m\n",
      "\u001b[34m----------------\u001b[0m\n",
      "\u001b[34mRANDOM SET:  0\u001b[0m\n",
      "\u001b[34mConcat Value Len: 1725\u001b[0m\n",
      "\u001b[34m(tensor([[  101,  3888,  6198,  ...,     0,     0,     0],\n",
      "        [  101,  1996,  3778,  ...,     0,     0,     0],\n",
      "        [  101, 14923, 16860,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1996,  3011,  ...,     0,     0,     0],\n",
      "        [  101,  1996, 21334,  ...,     0,     0,     0],\n",
      "        [  101,  1996, 21334,  ...,     0,     0,     0]]), tensor([74, 50, 84, 73, 48, 82, 50, 81, 50, 69, 66, 78, 99, 76, 46, 75, 74, 64,\n",
      "        66, 37, 59, 44, 80, 54, 37, 51, 50, 84, 66, 57, 59, 57]))\u001b[0m\n",
      "\u001b[34mtensor([1, 2, 0, 2, 1, 2, 0, 1, 3, 1, 1, 0, 1, 2, 2, 0, 1, 2, 1, 0, 0, 1, 1, 2,\n",
      "        1, 2, 1, 0, 1, 0, 0, 1])\u001b[0m\n",
      "\u001b[34m['[CLS]', 'the', 'pressure', 'inside', 'the', 'volcano', 'pushes', 'the', 'lava', 'out', '.', 'i', 'feel', 'pressure', 'on', 'my', 'back', 'when', 'my', 'friend', 'pushes', 'me', 'on', 'the', 'swing', '.', 'when', 'you', 'jump', 'on', 'the', 'bed', 'you', 'put', 'pressure', 'on', 'the', 'mattress', '.', 'my', 'mom', 'is', 'press', '##uring', 'me', 'to', 'do', 'my', 'homework', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34mUsing device:  cuda:0\u001b[0m\n",
      "\u001b[34m-----start-------\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 1.1765 || 10iter: 0.9442 sec. || Accuracy: 0.46875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 1.0655 || 10iter: 0.8834 sec. || Accuracy: 0.53125\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 1.1191 || 10iter: 0.8835 sec. || Accuracy: 0.53125\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 1.3252 || 10iter: 0.8825 sec. || Accuracy: 0.40625\u001b[0m\n",
      "\u001b[34mEpoch 1/10 | train |  Loss: 1.2085 Acc: 0.4449\u001b[0m\n",
      "\u001b[34mEpoch 1/10 |  val  |  Loss: 1.1736 Acc: 0.4493\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 1.0940 || 10iter: 0.8870 sec. || Accuracy: 0.53125\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 1.1344 || 10iter: 0.8868 sec. || Accuracy: 0.3125\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 1.1721 || 10iter: 0.8867 sec. || Accuracy: 0.4375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 1.0087 || 10iter: 0.8872 sec. || Accuracy: 0.65625\u001b[0m\n",
      "\u001b[34mEpoch 2/10 | train |  Loss: 1.1283 Acc: 0.5029\u001b[0m\n",
      "\u001b[34mEpoch 2/10 |  val  |  Loss: 1.1328 Acc: 0.4870\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 1.0084 || 10iter: 0.8901 sec. || Accuracy: 0.5625\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.9287 || 10iter: 0.8880 sec. || Accuracy: 0.59375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.9630 || 10iter: 0.8884 sec. || Accuracy: 0.5625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.8139 || 10iter: 0.8879 sec. || Accuracy: 0.59375\u001b[0m\n",
      "\u001b[34mEpoch 3/10 | train |  Loss: 1.0577 Acc: 0.5507\u001b[0m\n",
      "\u001b[34mEpoch 3/10 |  val  |  Loss: 1.0178 Acc: 0.5565\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 1.0222 || 10iter: 0.8888 sec. || Accuracy: 0.5\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.9301 || 10iter: 0.8884 sec. || Accuracy: 0.65625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 1.0919 || 10iter: 0.8883 sec. || Accuracy: 0.53125\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.9233 || 10iter: 0.8872 sec. || Accuracy: 0.53125\u001b[0m\n",
      "\u001b[34mEpoch 4/10 | train |  Loss: 0.9816 Acc: 0.5906\u001b[0m\n",
      "\u001b[34mEpoch 4/10 |  val  |  Loss: 1.0429 Acc: 0.5449\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.7387 || 10iter: 0.8895 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.9340 || 10iter: 0.8872 sec. || Accuracy: 0.5625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.9405 || 10iter: 0.8877 sec. || Accuracy: 0.53125\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.8298 || 10iter: 0.8880 sec. || Accuracy: 0.59375\u001b[0m\n",
      "\u001b[34mEpoch 5/10 | train |  Loss: 0.9113 Acc: 0.6109\u001b[0m\n",
      "\u001b[34mEpoch 5/10 |  val  |  Loss: 0.9223 Acc: 0.6087\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.7306 || 10iter: 0.8894 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.8553 || 10iter: 0.8857 sec. || Accuracy: 0.53125\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 1.0480 || 10iter: 0.8899 sec. || Accuracy: 0.4375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.9935 || 10iter: 0.8886 sec. || Accuracy: 0.5625\u001b[0m\n",
      "\u001b[34mEpoch 6/10 | train |  Loss: 0.8450 Acc: 0.6217\u001b[0m\n",
      "\u001b[34mEpoch 6/10 |  val  |  Loss: 0.9748 Acc: 0.5942\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.8554 || 10iter: 0.8941 sec. || Accuracy: 0.625\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.6571 || 10iter: 0.8883 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.8155 || 10iter: 0.8881 sec. || Accuracy: 0.6875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.7670 || 10iter: 0.8900 sec. || Accuracy: 0.6875\u001b[0m\n",
      "\u001b[34mEpoch 7/10 | train |  Loss: 0.7811 Acc: 0.6775\u001b[0m\n",
      "\u001b[34mEpoch 7/10 |  val  |  Loss: 0.8644 Acc: 0.6435\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.5529 || 10iter: 0.8922 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.8537 || 10iter: 0.8898 sec. || Accuracy: 0.625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.7137 || 10iter: 0.8881 sec. || Accuracy: 0.65625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.7996 || 10iter: 0.8880 sec. || Accuracy: 0.625\u001b[0m\n",
      "\u001b[34mEpoch 8/10 | train |  Loss: 0.7702 Acc: 0.6754\u001b[0m\n",
      "\u001b[34mEpoch 8/10 |  val  |  Loss: 0.8813 Acc: 0.6348\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.9500 || 10iter: 0.8928 sec. || Accuracy: 0.5\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.9141 || 10iter: 0.8904 sec. || Accuracy: 0.53125\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.8969 || 10iter: 0.8894 sec. || Accuracy: 0.625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.6358 || 10iter: 0.8911 sec. || Accuracy: 0.6875\u001b[0m\n",
      "\u001b[34mEpoch 9/10 | train |  Loss: 0.7192 Acc: 0.7167\u001b[0m\n",
      "\u001b[34mEpoch 9/10 |  val  |  Loss: 0.8977 Acc: 0.6174\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.5439 || 10iter: 0.8925 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.6897 || 10iter: 0.8902 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.8217 || 10iter: 0.8894 sec. || Accuracy: 0.6875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.5000 || 10iter: 0.8893 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mEpoch 10/10 | train |  Loss: 0.6950 Acc: 0.7145\u001b[0m\n",
      "\u001b[34mEpoch 10/10 |  val  |  Loss: 0.8323 Acc: 0.6580\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/18 [00:00<?, ?it/s]#015 11%|█         | 2/18 [00:00<00:01, 12.39it/s]#015 22%|██▏       | 4/18 [00:00<00:01, 12.39it/s]#015 33%|███▎      | 6/18 [00:00<00:00, 12.40it/s]#015 44%|████▍     | 8/18 [00:00<00:00, 12.38it/s]#015 56%|█████▌    | 10/18 [00:00<00:00, 12.35it/s]#015 67%|██████▋   | 12/18 [00:00<00:00, 12.35it/s]#015 78%|███████▊  | 14/18 [00:01<00:00, 12.34it/s]#015 89%|████████▉ | 16/18 [00:01<00:00, 12.35it/s]#015100%|██████████| 18/18 [00:01<00:00, 12.46it/s]#015100%|██████████| 18/18 [00:01<00:00, 12.39it/s]\u001b[0m\n",
      "\u001b[34mTest Data 574 Accuracy: 0.6672\u001b[0m\n",
      "\u001b[34mRecall                      0.6672\u001b[0m\n",
      "\u001b[34mPrecision                   0.6561\u001b[0m\n",
      "\u001b[34mF1                          0.6587\u001b[0m\n",
      "\u001b[34mKappa                       0.4769\u001b[0m\n",
      "\u001b[34mQuadratic Weighted Kappa    0.5151\u001b[0m\n",
      "\u001b[34mdtype: float64\u001b[0m\n",
      "\u001b[34mConfusion Matrix:\n",
      "     0    1   2  3\u001b[0m\n",
      "\u001b[34m0  100   48  20  0\u001b[0m\n",
      "\u001b[34m1   29  209  35  0\u001b[0m\n",
      "\u001b[34m2    7   35  74  1\u001b[0m\n",
      "\u001b[34m3    4    1  11  0\u001b[0m\n",
      "\u001b[34m----------------\u001b[0m\n",
      "\u001b[34mRANDOM SET:  1\u001b[0m\n",
      "\u001b[34mConcat Value Len: 1725\u001b[0m\n",
      "\u001b[34m(tensor([[  101,  3888,  6198,  ...,     0,     0,     0],\n",
      "        [  101,  2023, 12779,  ...,     0,     0,     0],\n",
      "        [  101, 14923, 16860,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1996,  3011,  ...,     0,     0,     0],\n",
      "        [  101,  6890,  6701,  ...,     0,     0,     0],\n",
      "        [  101,  1996, 21334,  ...,     0,     0,     0]]), tensor([74, 84, 92, 73, 57, 82, 50, 81, 50, 69, 66, 37, 99, 76, 55, 75, 74, 64,\n",
      "        66, 37, 59, 80, 80, 54, 37, 65, 50, 84, 66, 57, 80, 57]))\u001b[0m\n",
      "\u001b[34mtensor([1, 3, 0, 2, 0, 2, 0, 1, 3, 1, 1, 1, 1, 2, 2, 0, 1, 2, 1, 0, 0, 2, 1, 2,\n",
      "        1, 1, 1, 0, 1, 0, 2, 1])\u001b[0m\n",
      "\u001b[34m['[CLS]', 'this', 'volcano', 'close', 'to', 'mexico', 'city', 'sometimes', 'er', '##upt', '##s', '.', 'a', 'person', 'is', 'shaking', 'a', 'soda', 'can', '.', 'when', 'he', 'opens', 'the', 'can', ',', 'the', 'soda', 'er', '##upt', '##s', '.', 'the', 'heat', 'caused', 'the', 'dry', 'grass', 'to', 'er', '##upt', 'into', 'flames', '.', 'my', 'parents', 'er', '##upt', 'into', 'cheers', 'when', 'i', 'score', 'a', 'goal', '.', 'when', 'you', 'hear', 'a', 'really', 'funny', 'joke', ',', 'you', 'might', 'er', '##upt', 'into', 'laughter', '.', 'my', 'brother', 'erupted', 'when', 'my', 'mother', 'told', 'him', 'he', 'was', 'getting', 'grounded', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34mUsing device:  cuda:0\u001b[0m\n",
      "\u001b[34m-----start-------\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 1.0697 || 10iter: 0.8918 sec. || Accuracy: 0.5\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.8763 || 10iter: 0.8904 sec. || Accuracy: 0.59375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.9324 || 10iter: 0.8892 sec. || Accuracy: 0.625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 1.0125 || 10iter: 0.8886 sec. || Accuracy: 0.53125\u001b[0m\n",
      "\u001b[34mEpoch 1/10 | train |  Loss: 1.0016 Acc: 0.5725\u001b[0m\n",
      "\u001b[34mEpoch 1/10 |  val  |  Loss: 0.8833 Acc: 0.6464\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.6658 || 10iter: 0.8923 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.8360 || 10iter: 0.8907 sec. || Accuracy: 0.6875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.7687 || 10iter: 0.8898 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.6844 || 10iter: 0.8916 sec. || Accuracy: 0.59375\u001b[0m\n",
      "\u001b[34mEpoch 2/10 | train |  Loss: 0.7688 Acc: 0.6891\u001b[0m\n",
      "\u001b[34mEpoch 2/10 |  val  |  Loss: 0.8941 Acc: 0.6145\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.5109 || 10iter: 0.8923 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.5629 || 10iter: 0.8912 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.6699 || 10iter: 0.8903 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.9468 || 10iter: 0.8929 sec. || Accuracy: 0.625\u001b[0m\n",
      "\u001b[34mEpoch 3/10 | train |  Loss: 0.7273 Acc: 0.6913\u001b[0m\n",
      "\u001b[34mEpoch 3/10 |  val  |  Loss: 0.8597 Acc: 0.6638\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.7433 || 10iter: 0.8939 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.8585 || 10iter: 0.8913 sec. || Accuracy: 0.6875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.5623 || 10iter: 0.8921 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.7271 || 10iter: 0.8927 sec. || Accuracy: 0.625\u001b[0m\n",
      "\u001b[34mEpoch 4/10 | train |  Loss: 0.6746 Acc: 0.7312\u001b[0m\n",
      "\u001b[34mEpoch 4/10 |  val  |  Loss: 0.7936 Acc: 0.7072\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.5693 || 10iter: 0.8931 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.5852 || 10iter: 0.8936 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.6143 || 10iter: 0.8937 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.5720 || 10iter: 0.8937 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mEpoch 5/10 | train |  Loss: 0.6587 Acc: 0.7174\u001b[0m\n",
      "\u001b[34mEpoch 5/10 |  val  |  Loss: 0.7883 Acc: 0.6957\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.5359 || 10iter: 0.8966 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.6872 || 10iter: 0.8980 sec. || Accuracy: 0.65625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.5706 || 10iter: 0.8936 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.5770 || 10iter: 0.8935 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mEpoch 6/10 | train |  Loss: 0.6236 Acc: 0.7406\u001b[0m\n",
      "\u001b[34mEpoch 6/10 |  val  |  Loss: 0.8714 Acc: 0.6841\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.4880 || 10iter: 0.8955 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.5202 || 10iter: 0.8950 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.6809 || 10iter: 0.8926 sec. || Accuracy: 0.625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.6227 || 10iter: 0.8920 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mEpoch 7/10 | train |  Loss: 0.5970 Acc: 0.7536\u001b[0m\n",
      "\u001b[34mEpoch 7/10 |  val  |  Loss: 0.8284 Acc: 0.6725\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.3797 || 10iter: 0.8955 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.4205 || 10iter: 0.8929 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.5635 || 10iter: 0.8932 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.4479 || 10iter: 0.8933 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mEpoch 8/10 | train |  Loss: 0.5769 Acc: 0.7725\u001b[0m\n",
      "\u001b[34mEpoch 8/10 |  val  |  Loss: 0.8844 Acc: 0.6638\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.5157 || 10iter: 0.8956 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.7670 || 10iter: 0.8920 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.7306 || 10iter: 0.8929 sec. || Accuracy: 0.6875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.4941 || 10iter: 0.8922 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mEpoch 9/10 | train |  Loss: 0.5885 Acc: 0.7601\u001b[0m\n",
      "\u001b[34mEpoch 9/10 |  val  |  Loss: 0.7306 Acc: 0.7391\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.5703 || 10iter: 0.8958 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.5127 || 10iter: 0.8942 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.6967 || 10iter: 0.8924 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.3818 || 10iter: 0.8934 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mEpoch 10/10 | train |  Loss: 0.5395 Acc: 0.8029\u001b[0m\n",
      "\u001b[34mEpoch 10/10 |  val  |  Loss: 0.7558 Acc: 0.7304\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/18 [00:00<?, ?it/s]#015 11%|█         | 2/18 [00:00<00:01, 12.36it/s]#015 22%|██▏       | 4/18 [00:00<00:01, 12.35it/s]#015 33%|███▎      | 6/18 [00:00<00:00, 12.35it/s]#015 44%|████▍     | 8/18 [00:00<00:00, 12.34it/s]#015 56%|█████▌    | 10/18 [00:00<00:00, 12.35it/s]#015 67%|██████▋   | 12/18 [00:00<00:00, 12.34it/s]#015 78%|███████▊  | 14/18 [00:01<00:00, 12.33it/s]#015 89%|████████▉ | 16/18 [00:01<00:00, 12.32it/s]#015100%|██████████| 18/18 [00:01<00:00, 12.43it/s]#015100%|██████████| 18/18 [00:01<00:00, 12.37it/s]\u001b[0m\n",
      "\u001b[34mTest Data 574 Accuracy: 0.7282\u001b[0m\n",
      "\u001b[34mRecall                      0.7282\u001b[0m\n",
      "\u001b[34mPrecision                   0.7365\u001b[0m\n",
      "\u001b[34mF1                          0.7244\u001b[0m\n",
      "\u001b[34mKappa                       0.5885\u001b[0m\n",
      "\u001b[34mQuadratic Weighted Kappa    0.6861\u001b[0m\n",
      "\u001b[34mdtype: float64\u001b[0m\n",
      "\u001b[34mConfusion Matrix:\n",
      "     0    1   2  3\u001b[0m\n",
      "\u001b[34m0  121   30  15  1\u001b[0m\n",
      "\u001b[34m1   29  194  31  0\u001b[0m\n",
      "\u001b[34m2    4   30  99  0\u001b[0m\n",
      "\u001b[34m3    0    1  15  4\u001b[0m\n",
      "\u001b[34m----------------\u001b[0m\n",
      "\u001b[34mRANDOM SET:  2\u001b[0m\n",
      "\u001b[34mConcat Value Len: 1725\u001b[0m\n",
      "\u001b[34m(tensor([[  101,  3888,  6198,  ...,     0,     0,     0],\n",
      "        [  101,  2023, 12779,  ...,     0,     0,     0],\n",
      "        [  101, 14923, 16860,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  3888,  6198,  ...,     0,     0,     0],\n",
      "        [  101,  6890,  6701,  ...,     0,     0,     0],\n",
      "        [  101,  1996, 23879,  ...,     0,     0,     0]]), tensor([ 74,  84,  92,  84,  57,  85,  85,  81,  50,  81,  66,  37,  99, 101,\n",
      "         55,  44,  74,  64,  46,  61,  59,  80,  86,  54,  37,  65, 103,  84,\n",
      "         68,  86,  80,  74]))\u001b[0m\n",
      "\u001b[34mtensor([1, 3, 0, 1, 0, 0, 1, 1, 3, 1, 1, 1, 1, 0, 2, 0, 1, 2, 0, 1, 0, 2, 1, 2,\n",
      "        1, 1, 0, 0, 1, 3, 2, 0])\u001b[0m\n",
      "\u001b[34m['[CLS]', 'this', 'volcano', 'close', 'to', 'mexico', 'city', 'sometimes', 'er', '##upt', '##s', '.', 'a', 'person', 'is', 'shaking', 'a', 'soda', 'can', '.', 'when', 'he', 'opens', 'the', 'can', ',', 'the', 'soda', 'er', '##upt', '##s', '.', 'the', 'heat', 'caused', 'the', 'dry', 'grass', 'to', 'er', '##upt', 'into', 'flames', '.', 'my', 'parents', 'er', '##upt', 'into', 'cheers', 'when', 'i', 'score', 'a', 'goal', '.', 'when', 'you', 'hear', 'a', 'really', 'funny', 'joke', ',', 'you', 'might', 'er', '##upt', 'into', 'laughter', '.', 'my', 'brother', 'erupted', 'when', 'my', 'mother', 'told', 'him', 'he', 'was', 'getting', 'grounded', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34mUsing device:  cuda:0\u001b[0m\n",
      "\u001b[34m-----start-------\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.7398 || 10iter: 0.8943 sec. || Accuracy: 0.65625\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.6829 || 10iter: 0.8908 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.9898 || 10iter: 0.8908 sec. || Accuracy: 0.59375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.7816 || 10iter: 0.8901 sec. || Accuracy: 0.65625\u001b[0m\n",
      "\u001b[34mEpoch 1/10 | train |  Loss: 0.8341 Acc: 0.6652\u001b[0m\n",
      "\u001b[34mEpoch 1/10 |  val  |  Loss: 0.8382 Acc: 0.6435\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.5428 || 10iter: 0.8940 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.6176 || 10iter: 0.8948 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.6101 || 10iter: 0.8934 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.7480 || 10iter: 0.8921 sec. || Accuracy: 0.65625\u001b[0m\n",
      "\u001b[34mEpoch 2/10 | train |  Loss: 0.6472 Acc: 0.7500\u001b[0m\n",
      "\u001b[34mEpoch 2/10 |  val  |  Loss: 0.8187 Acc: 0.6725\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.4371 || 10iter: 0.8937 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.4957 || 10iter: 0.8906 sec. || Accuracy: 0.6875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.7045 || 10iter: 0.8929 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.9984 || 10iter: 0.8933 sec. || Accuracy: 0.65625\u001b[0m\n",
      "\u001b[34mEpoch 3/10 | train |  Loss: 0.6047 Acc: 0.7449\u001b[0m\n",
      "\u001b[34mEpoch 3/10 |  val  |  Loss: 0.7824 Acc: 0.6928\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.7393 || 10iter: 0.8951 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.4778 || 10iter: 0.8921 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.3983 || 10iter: 0.8916 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.5286 || 10iter: 0.8931 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mEpoch 4/10 | train |  Loss: 0.5676 Acc: 0.7797\u001b[0m\n",
      "\u001b[34mEpoch 4/10 |  val  |  Loss: 0.7626 Acc: 0.6870\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.5183 || 10iter: 0.8942 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.3982 || 10iter: 0.8914 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.4107 || 10iter: 0.8930 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.5578 || 10iter: 0.8907 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mEpoch 5/10 | train |  Loss: 0.5654 Acc: 0.7775\u001b[0m\n",
      "\u001b[34mEpoch 5/10 |  val  |  Loss: 0.8065 Acc: 0.6899\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.5007 || 10iter: 0.8941 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.4542 || 10iter: 0.8914 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.4499 || 10iter: 0.8940 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.4697 || 10iter: 0.8935 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mEpoch 6/10 | train |  Loss: 0.5345 Acc: 0.7862\u001b[0m\n",
      "\u001b[34mEpoch 6/10 |  val  |  Loss: 0.7506 Acc: 0.7014\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.5010 || 10iter: 0.8949 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.4475 || 10iter: 0.8918 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.5573 || 10iter: 0.8914 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.6407 || 10iter: 0.8938 sec. || Accuracy: 0.625\u001b[0m\n",
      "\u001b[34mEpoch 7/10 | train |  Loss: 0.4931 Acc: 0.7899\u001b[0m\n",
      "\u001b[34mEpoch 7/10 |  val  |  Loss: 0.7661 Acc: 0.7043\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.2330 || 10iter: 0.8944 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.2996 || 10iter: 0.8927 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.4380 || 10iter: 0.8956 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.3314 || 10iter: 0.8941 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mEpoch 8/10 | train |  Loss: 0.4859 Acc: 0.8109\u001b[0m\n",
      "\u001b[34mEpoch 8/10 |  val  |  Loss: 0.8234 Acc: 0.6870\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.4561 || 10iter: 0.8968 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.3920 || 10iter: 0.8956 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.3759 || 10iter: 0.8947 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.3768 || 10iter: 0.8957 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mEpoch 9/10 | train |  Loss: 0.4565 Acc: 0.8174\u001b[0m\n",
      "\u001b[34mEpoch 9/10 |  val  |  Loss: 0.7538 Acc: 0.7014\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.3874 || 10iter: 0.8971 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.3837 || 10iter: 0.8955 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.4774 || 10iter: 0.8954 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1671 || 10iter: 0.8960 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mEpoch 10/10 | train |  Loss: 0.4289 Acc: 0.8326\u001b[0m\n",
      "\u001b[34mEpoch 10/10 |  val  |  Loss: 0.7832 Acc: 0.6957\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/18 [00:00<?, ?it/s]#015 11%|█         | 2/18 [00:00<00:01, 12.34it/s]#015 22%|██▏       | 4/18 [00:00<00:01, 12.33it/s]#015 33%|███▎      | 6/18 [00:00<00:00, 12.34it/s]#015 44%|████▍     | 8/18 [00:00<00:00, 12.34it/s]#015 56%|█████▌    | 10/18 [00:00<00:00, 12.29it/s]#015 67%|██████▋   | 12/18 [00:00<00:00, 12.30it/s]#015 78%|███████▊  | 14/18 [00:01<00:00, 12.30it/s]#015 89%|████████▉ | 16/18 [00:01<00:00, 12.30it/s]#015100%|██████████| 18/18 [00:01<00:00, 12.43it/s]#015100%|██████████| 18/18 [00:01<00:00, 12.35it/s]\u001b[0m\n",
      "\u001b[34mTest Data 574 Accuracy: 0.7979\u001b[0m\n",
      "\u001b[34mRecall                      0.7979\u001b[0m\n",
      "\u001b[34mPrecision                   0.8023\u001b[0m\n",
      "\u001b[34mF1                          0.7970\u001b[0m\n",
      "\u001b[34mKappa                       0.6879\u001b[0m\n",
      "\u001b[34mQuadratic Weighted Kappa    0.7340\u001b[0m\n",
      "\u001b[34mdtype: float64\u001b[0m\n",
      "\u001b[34mConfusion Matrix:\n",
      "     0    1   2  3\u001b[0m\n",
      "\u001b[34m0  127   36  10  1\u001b[0m\n",
      "\u001b[34m1   11  226  20  0\u001b[0m\n",
      "\u001b[34m2    6   25  97  3\u001b[0m\n",
      "\u001b[34m3    1    0   3  8\u001b[0m\n",
      "\u001b[34m----------------\u001b[0m\n",
      "\u001b[34mRANDOM SET:  3\u001b[0m\n",
      "\u001b[34mConcat Value Len: 1722\u001b[0m\n",
      "\u001b[34m(tensor([[  101,  2023, 12779,  ...,     0,     0,     0],\n",
      "        [  101, 14923, 16860,  ...,     0,     0,     0],\n",
      "        [  101,  1996, 23879,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  6890,  6701,  ...,     0,     0,     0],\n",
      "        [  101,  1996,  3778,  ...,     0,     0,     0],\n",
      "        [  101, 14923, 16860,  ...,     0,     0,     0]]), tensor([ 84,  92,  70,  57,  75,  44,  37, 128,  82,  90,  37,  57,  74,  55,\n",
      "         76,  58,  66,  87,  37,  72,  80,  86,  63,  93,  65, 103,  65,  68,\n",
      "         76,  80,  45,  85]))\u001b[0m\n",
      "\u001b[34mtensor([3, 0, 0, 0, 1, 0, 1, 0, 2, 0, 1, 0, 1, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 3,\n",
      "        1, 0, 0, 1, 1, 2, 1, 0])\u001b[0m\n",
      "\u001b[34m['[CLS]', 'cesar', 'chavez', 'is', 'a', 'hero', 'because', 'he', 'showed', 'farm', '##work', '##ers', 'how', 'to', 'work', 'together', 'to', 'get', 'better', 'pay', 'and', 'a', 'safe', 'place', 'to', 'work', '.', 'ellen', 'och', '##oa', 'is', 'a', 'hero', 'because', 'she', 'was', 'the', 'first', 'hispanic', 'woman', 'to', 'travel', 'to', 'space', '.', 'the', 'fire', '##fighter', 'is', 'a', 'hero', 'because', 'he', 'saves', 'the', 'lives', 'of', 'many', 'people', '.', 'my', 'grandmother', 'is', 'my', 'hero', 'because', 'she', 'always', 'takes', 'good', 'care', 'of', 'me', 'when', 'my', 'parents', 'are', 'working', '.', 'i', 'save', 'every', 'day', 'and', 'when', 'it', 's', 'nighttime', 'in', 'the', 'morning', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34mUsing device:  cuda:0\u001b[0m\n",
      "\u001b[34m-----start-------\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.9961 || 10iter: 0.8918 sec. || Accuracy: 0.53125\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.9994 || 10iter: 0.8931 sec. || Accuracy: 0.625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.4682 || 10iter: 0.8962 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.5889 || 10iter: 0.8937 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mEpoch 1/10 | train |  Loss: 0.9196 Acc: 0.6125\u001b[0m\n",
      "\u001b[34mEpoch 1/10 |  val  |  Loss: 0.7476 Acc: 0.6977\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.5797 || 10iter: 0.8962 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.7742 || 10iter: 0.8941 sec. || Accuracy: 0.59375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.5744 || 10iter: 0.8965 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.4454 || 10iter: 0.8941 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mEpoch 2/10 | train |  Loss: 0.6049 Acc: 0.7620\u001b[0m\n",
      "\u001b[34mEpoch 2/10 |  val  |  Loss: 0.7328 Acc: 0.7180\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.4072 || 10iter: 0.8967 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.6607 || 10iter: 0.8929 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.6158 || 10iter: 0.8931 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.9004 || 10iter: 0.8914 sec. || Accuracy: 0.6875\u001b[0m\n",
      "\u001b[34mEpoch 3/10 | train |  Loss: 0.5560 Acc: 0.7750\u001b[0m\n",
      "\u001b[34mEpoch 3/10 |  val  |  Loss: 0.6937 Acc: 0.7413\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.3603 || 10iter: 0.8977 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.2635 || 10iter: 0.8953 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.4928 || 10iter: 0.8973 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.2752 || 10iter: 0.8930 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mEpoch 4/10 | train |  Loss: 0.4990 Acc: 0.8135\u001b[0m\n",
      "\u001b[34mEpoch 4/10 |  val  |  Loss: 0.7339 Acc: 0.7180\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.2368 || 10iter: 0.8960 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.5975 || 10iter: 0.8919 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.8099 || 10iter: 0.8932 sec. || Accuracy: 0.6875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.5000 || 10iter: 0.8945 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mEpoch 5/10 | train |  Loss: 0.5234 Acc: 0.8222\u001b[0m\n",
      "\u001b[34mEpoch 5/10 |  val  |  Loss: 0.7892 Acc: 0.7093\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.6201 || 10iter: 0.8966 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.4911 || 10iter: 0.8939 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.4828 || 10iter: 0.8936 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.7087 || 10iter: 0.8926 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mEpoch 6/10 | train |  Loss: 0.4749 Acc: 0.8033\u001b[0m\n",
      "\u001b[34mEpoch 6/10 |  val  |  Loss: 0.7290 Acc: 0.7180\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.4193 || 10iter: 0.8980 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.4009 || 10iter: 0.8962 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.3675 || 10iter: 0.8925 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.5698 || 10iter: 0.8915 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mEpoch 7/10 | train |  Loss: 0.4434 Acc: 0.8237\u001b[0m\n",
      "\u001b[34mEpoch 7/10 |  val  |  Loss: 0.7922 Acc: 0.7209\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.6827 || 10iter: 0.8950 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.3544 || 10iter: 0.8934 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.5080 || 10iter: 0.8923 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.6251 || 10iter: 0.8966 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mEpoch 8/10 | train |  Loss: 0.4341 Acc: 0.8266\u001b[0m\n",
      "\u001b[34mEpoch 8/10 |  val  |  Loss: 0.7687 Acc: 0.7035\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.2810 || 10iter: 0.8971 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.3795 || 10iter: 0.8948 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.2422 || 10iter: 0.8957 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.5766 || 10iter: 0.8943 sec. || Accuracy: 0.6875\u001b[0m\n",
      "\u001b[34mEpoch 9/10 | train |  Loss: 0.4129 Acc: 0.8447\u001b[0m\n",
      "\u001b[34mEpoch 9/10 |  val  |  Loss: 0.7886 Acc: 0.7209\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.4172 || 10iter: 0.8978 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.4039 || 10iter: 0.8967 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.5292 || 10iter: 0.8938 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.2973 || 10iter: 0.8959 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mEpoch 10/10 | train |  Loss: 0.3878 Acc: 0.8585\u001b[0m\n",
      "\u001b[34mEpoch 10/10 |  val  |  Loss: 0.8205 Acc: 0.7093\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/19 [00:00<?, ?it/s]#015 11%|█         | 2/19 [00:00<00:01, 12.32it/s]#015 21%|██        | 4/19 [00:00<00:01, 12.31it/s]#015 32%|███▏      | 6/19 [00:00<00:01, 12.31it/s]#015 42%|████▏     | 8/19 [00:00<00:00, 12.31it/s]#015 53%|█████▎    | 10/19 [00:00<00:00, 12.31it/s]#015 63%|██████▎   | 12/19 [00:00<00:00, 12.31it/s]#015 74%|███████▎  | 14/19 [00:01<00:00, 12.31it/s]#015 84%|████████▍ | 16/19 [00:01<00:00, 12.31it/s]#015 95%|█████████▍| 18/19 [00:01<00:00, 12.31it/s]#015100%|██████████| 19/19 [00:01<00:00, 12.77it/s]\u001b[0m\n",
      "\u001b[34mTest Data 577 Accuracy: 0.8510\u001b[0m\n",
      "\u001b[34mRecall                      0.8510\u001b[0m\n",
      "\u001b[34mPrecision                   0.8546\u001b[0m\n",
      "\u001b[34mF1                          0.8488\u001b[0m\n",
      "\u001b[34mKappa                       0.7699\u001b[0m\n",
      "\u001b[34mQuadratic Weighted Kappa    0.8478\u001b[0m\n",
      "\u001b[34mdtype: float64\u001b[0m\n",
      "\u001b[34mConfusion Matrix:\n",
      "     0    1    2  3\u001b[0m\n",
      "\u001b[34m0  130   34    4  1\u001b[0m\n",
      "\u001b[34m1   10  243   13  0\u001b[0m\n",
      "\u001b[34m2    0   11  109  3\u001b[0m\n",
      "\u001b[34m3    0    0   10  9\u001b[0m\n",
      "\u001b[34m----------------\u001b[0m\n",
      "\u001b[34mALL DATA (Macro Average):\n",
      "         Recall  Precision        F1     Kappa  Quadratic Weighted Kappa\u001b[0m\n",
      "\u001b[34mcount  4.000000   4.000000  4.000000  4.000000                  4.000000\u001b[0m\n",
      "\u001b[34mmean   0.761075   0.762375  0.757225  0.630800                  0.695750\u001b[0m\n",
      "\u001b[34mstd    0.080283   0.085758  0.083172  0.126601                  0.138215\u001b[0m\n",
      "\u001b[34mmin    0.667200   0.656100  0.658700  0.476900                  0.515100\u001b[0m\n",
      "\u001b[34m25%    0.712950   0.716400  0.707975  0.560600                  0.643350\u001b[0m\n",
      "\u001b[34m50%    0.763050   0.769400  0.760700  0.638200                  0.710050\u001b[0m\n",
      "\u001b[34m75%    0.811175   0.815375  0.809950  0.708400                  0.762450\u001b[0m\n",
      "\u001b[34mmax    0.851000   0.854600  0.848800  0.769900                  0.847800\u001b[0m\n",
      "\u001b[34m----------------\u001b[0m\n",
      "\u001b[34mALL DATA (Micro Average):\u001b[0m\n",
      "\u001b[34mRecall                      0.7612\u001b[0m\n",
      "\u001b[34mPrecision                   0.7646\u001b[0m\n",
      "\u001b[34mF1                          0.7586\u001b[0m\n",
      "\u001b[34mKappa                       0.6316\u001b[0m\n",
      "\u001b[34mQuadratic Weighted Kappa    0.6997\u001b[0m\n",
      "\u001b[34mdtype: float64\u001b[0m\n",
      "\u001b[34mConfusion Matrix:\n",
      "     0    1    2   3\u001b[0m\n",
      "\u001b[34m0  478  148   49   3\u001b[0m\n",
      "\u001b[34m1   79  872   99   0\u001b[0m\n",
      "\u001b[34m2   17  101  379   7\u001b[0m\n",
      "\u001b[34m3    5    2   39  21\u001b[0m\n",
      "\u001b[34mTraining complete.\u001b[0m\n",
      "\n",
      "2021-08-17 04:11:22 Uploading - Uploading generated training model\n",
      "2021-08-17 04:14:20 Completed - Training job completed\n",
      "Training seconds: 708\n",
      "Billable seconds: 708\n"
     ]
    }
   ],
   "source": [
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "\n",
    "# Makoto.Sano@Mack-the-Psych.com\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/sagemaker-vdok3-bert-cv-sen-wo-dknr:latest'.format(account, region)\n",
    "vdok3bert = sage.estimator.Estimator(image,\n",
    "                       role, 1, 'ml.p3.2xlarge',\n",
    "                       output_path=\"s3://{}/output\".format(sess.default_bucket()),\n",
    "                       sagemaker_session=sess)\n",
    "vdok3bert.fit(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "predictor = vdok3bert.deploy(1, 'ml.p3.2xlarge', serializer=csv_serializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score_Class,Sentence-Score\n",
      "2,0\n",
      "2,1\n",
      "2,2\n",
      "3,3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_in = pd.read_csv('data/Pick4-Refmt_Serialized-Sen-ELVA.PILOT.PRE-POST-TEST.csv')\n",
    "np_in = np.vstack((np.array(df_in.columns), df_in.to_numpy()))\n",
    "print(predictor.predict(np_in).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "sess.delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_output_folder = \"batch-transform-output\"\n",
    "output_path=\"s3://{}/{}\".format(sess.default_bucket(), transform_output_folder)\n",
    "\n",
    "transformer = vdok3bert.transformer(instance_count=1,\n",
    "                               instance_type='ml.p3.2xlarge',\n",
    "                               output_path=output_path,\n",
    "                               assemble_with='Line',\n",
    "                               accept='text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................................\u001b[34mStarting the inference server with 8 workers.\u001b[0m\n",
      "\u001b[34m[2021-08-17 04:32:26 +0000] [41] [INFO] Starting gunicorn 20.1.0\u001b[0m\n",
      "\u001b[34m[2021-08-17 04:32:26 +0000] [41] [INFO] Listening at: unix:/tmp/gunicorn.sock (41)\u001b[0m\n",
      "\u001b[34m[2021-08-17 04:32:26 +0000] [41] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-08-17 04:32:26 +0000] [45] [INFO] Booting worker with pid: 45\u001b[0m\n",
      "\u001b[34m[2021-08-17 04:32:26 +0000] [46] [INFO] Booting worker with pid: 46\u001b[0m\n",
      "\u001b[34m[2021-08-17 04:32:27 +0000] [47] [INFO] Booting worker with pid: 47\u001b[0m\n",
      "\u001b[34m[2021-08-17 04:32:27 +0000] [55] [INFO] Booting worker with pid: 55\u001b[0m\n",
      "\u001b[34m[2021-08-17 04:32:27 +0000] [70] [INFO] Booting worker with pid: 70\u001b[0m\n",
      "\u001b[34m[2021-08-17 04:32:27 +0000] [71] [INFO] Booting worker with pid: 71\u001b[0m\n",
      "\u001b[34m[2021-08-17 04:32:27 +0000] [72] [INFO] Booting worker with pid: 72\u001b[0m\n",
      "\u001b[34m[2021-08-17 04:32:27 +0000] [80] [INFO] Booting worker with pid: 80\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34mbert.embeddings.word_embeddings.weight→embeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.position_embeddings.weight→embeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.token_type_embeddings.weight→embeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.gamma→embeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.beta→embeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.weight→encoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.bias→encoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.weight→encoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.bias→encoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.weight→encoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.bias→encoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.weight→encoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.bias→encoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.gamma→encoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.beta→encoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.weight→encoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.bias→encoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.weight→encoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.bias→encoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.gamma→encoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.beta→encoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.weight→encoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.bias→encoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.weight→encoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.bias→encoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.weight→encoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.bias→encoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.weight→encoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.bias→encoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.gamma→encoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.beta→encoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.weight→encoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.bias→encoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.weight→encoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.bias→encoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.gamma→encoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.beta→encoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.weight→encoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.bias→encoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.weight→encoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.bias→encoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.weight→encoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.bias→encoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.weight→encoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.bias→encoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.gamma→encoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.beta→encoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.weight→encoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.bias→encoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.weight→encoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.bias→encoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.gamma→encoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.beta→encoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.weight→encoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.bias→encoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.weight→encoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.bias→encoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.weight→encoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.bias→encoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.weight→encoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.bias→encoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.gamma→encoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.beta→encoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.weight→encoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.bias→encoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.weight→encoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.bias→encoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.gamma→encoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.beta→encoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.weight→encoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.bias→encoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.weight→encoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.bias→encoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.weight→encoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.bias→encoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.weight→encoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.bias→encoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.gamma→encoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.beta→encoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.weight→encoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.bias→encoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.weight→encoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.bias→encoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.gamma→encoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.beta→encoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.weight→encoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.bias→encoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.weight→encoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.bias→encoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.weight→encoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.bias→encoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.weight→encoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.bias→encoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.gamma→encoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.beta→encoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.weight→encoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.bias→encoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.weight→encoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.bias→encoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.gamma→encoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.beta→encoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.weight→encoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.bias→encoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.weight→encoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.bias→encoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.weight→encoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.bias→encoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.weight→encoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.bias→encoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.gamma→encoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.beta→encoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.weight→encoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.bias→encoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.weight→encoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.bias→encoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.gamma→encoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.beta→encoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.weight→encoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.bias→encoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.weight→encoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.bias→encoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.weight→encoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.bias→encoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.weight→encoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.bias→encoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.gamma→encoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.beta→encoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.weight→encoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.bias→encoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.weight→encoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.bias→encoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.gamma→encoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.beta→encoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.weight→encoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.bias→encoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.weight→encoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.bias→encoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.weight→encoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.bias→encoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.weight→encoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.bias→encoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.gamma→encoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.beta→encoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.weight→encoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.bias→encoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.weight→encoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.bias→encoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.gamma→encoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.beta→encoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.weight→encoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.bias→encoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.weight→encoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.bias→encoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.weight→encoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.bias→encoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.weight→encoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.bias→encoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.gamma→encoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.beta→encoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.weight→encoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.bias→encoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.weight→encoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.bias→encoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.gamma→encoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.beta→encoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.weight→encoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.bias→encoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.weight→encoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.bias→encoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.weight→encoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.bias→encoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.weight→encoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.bias→encoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.gamma→encoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.beta→encoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.weight→encoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.bias→encoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.weight→encoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.bias→encoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.gamma→encoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.beta→encoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.weight→encoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.bias→encoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.weight→encoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.bias→encoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.weight→encoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.bias→encoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.weight→encoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.bias→encoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.gamma→encoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.beta→encoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.weight→encoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.bias→encoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.weight→encoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.bias→encoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.gamma→encoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.beta→encoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.weight→pooler.dense.weight\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.bias→pooler.dense.bias\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Aug/2021:04:32:44 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Aug/2021:04:32:44 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 4 records\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/1 [00:00<?, ?it/s]#015100%|██████████| 1/1 [00:00<00:00, 38.95it/s]\u001b[0m\n",
      "\u001b[34mTest Data 4 Accuracy: 0.5000\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Aug/2021:04:32:44 +0000] \"POST /invocations HTTP/1.1\" 200 43 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [17/Aug/2021:04:32:44 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [17/Aug/2021:04:32:44 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 4 records\u001b[0m\n",
      "\u001b[35m#015  0%|          | 0/1 [00:00<?, ?it/s]#015100%|██████████| 1/1 [00:00<00:00, 38.95it/s]\u001b[0m\n",
      "\u001b[35mTest Data 4 Accuracy: 0.5000\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [17/Aug/2021:04:32:44 +0000] \"POST /invocations HTTP/1.1\" 200 43 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2021-08-17T04:32:44.789:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n",
      "\u001b[34mStarting the inference server with 8 workers.\u001b[0m\n",
      "\u001b[34m[2021-08-17 04:32:26 +0000] [41] [INFO] Starting gunicorn 20.1.0\u001b[0m\n",
      "\u001b[34m[2021-08-17 04:32:26 +0000] [41] [INFO] Listening at: unix:/tmp/gunicorn.sock (41)\u001b[0m\n",
      "\u001b[34m[2021-08-17 04:32:26 +0000] [41] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-08-17 04:32:26 +0000] [45] [INFO] Booting worker with pid: 45\u001b[0m\n",
      "\u001b[34m[2021-08-17 04:32:26 +0000] [46] [INFO] Booting worker with pid: 46\u001b[0m\n",
      "\u001b[34m[2021-08-17 04:32:27 +0000] [47] [INFO] Booting worker with pid: 47\u001b[0m\n",
      "\u001b[34m[2021-08-17 04:32:27 +0000] [55] [INFO] Booting worker with pid: 55\u001b[0m\n",
      "\u001b[34m[2021-08-17 04:32:27 +0000] [70] [INFO] Booting worker with pid: 70\u001b[0m\n",
      "\u001b[34m[2021-08-17 04:32:27 +0000] [71] [INFO] Booting worker with pid: 71\u001b[0m\n",
      "\u001b[34m[2021-08-17 04:32:27 +0000] [72] [INFO] Booting worker with pid: 72\u001b[0m\n",
      "\u001b[34m[2021-08-17 04:32:27 +0000] [80] [INFO] Booting worker with pid: 80\u001b[0m\n",
      "\u001b[35mStarting the inference server with 8 workers.\u001b[0m\n",
      "\u001b[35m[2021-08-17 04:32:26 +0000] [41] [INFO] Starting gunicorn 20.1.0\u001b[0m\n",
      "\u001b[35m[2021-08-17 04:32:26 +0000] [41] [INFO] Listening at: unix:/tmp/gunicorn.sock (41)\u001b[0m\n",
      "\u001b[35m[2021-08-17 04:32:26 +0000] [41] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2021-08-17 04:32:26 +0000] [45] [INFO] Booting worker with pid: 45\u001b[0m\n",
      "\u001b[35m[2021-08-17 04:32:26 +0000] [46] [INFO] Booting worker with pid: 46\u001b[0m\n",
      "\u001b[35m[2021-08-17 04:32:27 +0000] [47] [INFO] Booting worker with pid: 47\u001b[0m\n",
      "\u001b[35m[2021-08-17 04:32:27 +0000] [55] [INFO] Booting worker with pid: 55\u001b[0m\n",
      "\u001b[35m[2021-08-17 04:32:27 +0000] [70] [INFO] Booting worker with pid: 70\u001b[0m\n",
      "\u001b[35m[2021-08-17 04:32:27 +0000] [71] [INFO] Booting worker with pid: 71\u001b[0m\n",
      "\u001b[35m[2021-08-17 04:32:27 +0000] [72] [INFO] Booting worker with pid: 72\u001b[0m\n",
      "\u001b[35m[2021-08-17 04:32:27 +0000] [80] [INFO] Booting worker with pid: 80\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34mbert.embeddings.word_embeddings.weight→embeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.position_embeddings.weight→embeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[35mbert.embeddings.word_embeddings.weight→embeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[35mbert.embeddings.position_embeddings.weight→embeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.token_type_embeddings.weight→embeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.gamma→embeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.beta→embeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.weight→encoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.bias→encoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.weight→encoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.bias→encoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.weight→encoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.bias→encoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.weight→encoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.bias→encoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.gamma→encoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.beta→encoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.weight→encoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.bias→encoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.weight→encoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.bias→encoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.gamma→encoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.beta→encoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.weight→encoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.bias→encoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.weight→encoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.bias→encoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.weight→encoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.bias→encoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.weight→encoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.bias→encoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.gamma→encoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.beta→encoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.weight→encoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.bias→encoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.weight→encoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.bias→encoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.gamma→encoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.beta→encoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.weight→encoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.embeddings.token_type_embeddings.weight→embeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[35mbert.embeddings.LayerNorm.gamma→embeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.embeddings.LayerNorm.beta→embeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.query.weight→encoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.query.bias→encoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.key.weight→encoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.key.bias→encoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.value.weight→encoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.value.bias→encoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.dense.weight→encoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.dense.bias→encoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.LayerNorm.gamma→encoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.LayerNorm.beta→encoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.intermediate.dense.weight→encoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.intermediate.dense.bias→encoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.dense.weight→encoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.dense.bias→encoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.LayerNorm.gamma→encoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.LayerNorm.beta→encoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.query.weight→encoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.query.bias→encoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.key.weight→encoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.key.bias→encoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.value.weight→encoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.value.bias→encoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.dense.weight→encoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.dense.bias→encoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.LayerNorm.gamma→encoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.LayerNorm.beta→encoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.intermediate.dense.weight→encoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.intermediate.dense.bias→encoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.dense.weight→encoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.dense.bias→encoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.LayerNorm.gamma→encoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.LayerNorm.beta→encoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.query.weight→encoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.bias→encoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.weight→encoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.bias→encoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.weight→encoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.bias→encoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.weight→encoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.bias→encoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.gamma→encoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.beta→encoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.weight→encoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.bias→encoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.weight→encoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.bias→encoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.gamma→encoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.beta→encoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.weight→encoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.bias→encoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.weight→encoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.bias→encoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.weight→encoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.bias→encoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.weight→encoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.bias→encoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.gamma→encoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.beta→encoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.weight→encoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.bias→encoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.weight→encoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.bias→encoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.gamma→encoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.beta→encoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.weight→encoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.query.bias→encoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.key.weight→encoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.key.bias→encoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.value.weight→encoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.value.bias→encoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.dense.weight→encoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.dense.bias→encoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.LayerNorm.gamma→encoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.LayerNorm.beta→encoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.intermediate.dense.weight→encoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.intermediate.dense.bias→encoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.dense.weight→encoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.dense.bias→encoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.LayerNorm.gamma→encoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.LayerNorm.beta→encoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.query.weight→encoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.query.bias→encoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.key.weight→encoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.key.bias→encoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.value.weight→encoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.value.bias→encoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.dense.weight→encoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.dense.bias→encoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.LayerNorm.gamma→encoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.LayerNorm.beta→encoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.intermediate.dense.weight→encoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.intermediate.dense.bias→encoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.dense.weight→encoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.dense.bias→encoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.LayerNorm.gamma→encoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.LayerNorm.beta→encoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.query.weight→encoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.bias→encoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.weight→encoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.bias→encoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.weight→encoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.bias→encoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.weight→encoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.bias→encoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.gamma→encoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.beta→encoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.weight→encoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.bias→encoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.weight→encoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.bias→encoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.gamma→encoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.beta→encoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.weight→encoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.bias→encoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.weight→encoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.bias→encoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.weight→encoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.bias→encoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.weight→encoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.bias→encoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.gamma→encoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.beta→encoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.weight→encoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.bias→encoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.weight→encoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.bias→encoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.gamma→encoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.beta→encoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.weight→encoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.bias→encoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.weight→encoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.bias→encoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.weight→encoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.query.bias→encoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.key.weight→encoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.key.bias→encoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.value.weight→encoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.value.bias→encoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.dense.weight→encoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.dense.bias→encoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.LayerNorm.gamma→encoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.LayerNorm.beta→encoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.intermediate.dense.weight→encoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.intermediate.dense.bias→encoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.dense.weight→encoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.dense.bias→encoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.LayerNorm.gamma→encoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.LayerNorm.beta→encoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.query.weight→encoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.query.bias→encoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.key.weight→encoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.key.bias→encoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.value.weight→encoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.value.bias→encoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.dense.weight→encoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.dense.bias→encoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.LayerNorm.gamma→encoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.LayerNorm.beta→encoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.intermediate.dense.weight→encoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.intermediate.dense.bias→encoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.dense.weight→encoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.dense.bias→encoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.LayerNorm.gamma→encoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.LayerNorm.beta→encoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.query.weight→encoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.query.bias→encoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.key.weight→encoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.key.bias→encoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.value.weight→encoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.bias→encoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.weight→encoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.bias→encoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.gamma→encoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.beta→encoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.weight→encoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.bias→encoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.weight→encoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.bias→encoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.gamma→encoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.beta→encoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.weight→encoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.bias→encoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.weight→encoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.bias→encoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.weight→encoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.bias→encoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.weight→encoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.bias→encoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.gamma→encoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.beta→encoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.weight→encoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.bias→encoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.weight→encoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.bias→encoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.gamma→encoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.beta→encoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.weight→encoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.bias→encoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.weight→encoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.bias→encoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.weight→encoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.value.bias→encoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.dense.weight→encoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.dense.bias→encoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.LayerNorm.gamma→encoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.LayerNorm.beta→encoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.intermediate.dense.weight→encoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.intermediate.dense.bias→encoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.dense.weight→encoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.dense.bias→encoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.LayerNorm.gamma→encoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.LayerNorm.beta→encoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.query.weight→encoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.query.bias→encoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.key.weight→encoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.key.bias→encoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.value.weight→encoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.value.bias→encoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.dense.weight→encoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.dense.bias→encoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.LayerNorm.gamma→encoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.LayerNorm.beta→encoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.intermediate.dense.weight→encoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.intermediate.dense.bias→encoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.dense.weight→encoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.dense.bias→encoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.LayerNorm.gamma→encoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.LayerNorm.beta→encoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.query.weight→encoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.query.bias→encoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.key.weight→encoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.key.bias→encoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.value.weight→encoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.bias→encoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.weight→encoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.bias→encoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.gamma→encoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.beta→encoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.weight→encoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.bias→encoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.weight→encoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.bias→encoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.gamma→encoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.beta→encoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.weight→encoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.bias→encoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.weight→encoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.bias→encoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.weight→encoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.bias→encoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.weight→encoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.bias→encoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.gamma→encoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.beta→encoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.weight→encoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.bias→encoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.weight→encoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.bias→encoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.gamma→encoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.beta→encoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.weight→encoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.bias→encoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.weight→encoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.bias→encoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.weight→encoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.bias→encoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.weight→encoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.bias→encoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.gamma→encoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.value.bias→encoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.dense.weight→encoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.dense.bias→encoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.LayerNorm.gamma→encoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.LayerNorm.beta→encoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.intermediate.dense.weight→encoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.intermediate.dense.bias→encoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.dense.weight→encoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.dense.bias→encoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.LayerNorm.gamma→encoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.LayerNorm.beta→encoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.query.weight→encoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.query.bias→encoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.key.weight→encoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.key.bias→encoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.value.weight→encoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.value.bias→encoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.dense.weight→encoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.dense.bias→encoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.LayerNorm.gamma→encoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.LayerNorm.beta→encoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.intermediate.dense.weight→encoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.intermediate.dense.bias→encoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.dense.weight→encoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.dense.bias→encoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.LayerNorm.gamma→encoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.LayerNorm.beta→encoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.query.weight→encoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.query.bias→encoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.key.weight→encoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.key.bias→encoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.value.weight→encoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.value.bias→encoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.dense.weight→encoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.dense.bias→encoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.LayerNorm.gamma→encoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.beta→encoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.weight→encoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.bias→encoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.weight→encoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.bias→encoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.gamma→encoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.beta→encoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.weight→encoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.bias→encoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.weight→encoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.bias→encoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.weight→encoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.bias→encoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.weight→encoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.bias→encoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.gamma→encoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.beta→encoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.weight→encoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.bias→encoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.weight→encoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.bias→encoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.gamma→encoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.beta→encoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.weight→pooler.dense.weight\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.bias→pooler.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.LayerNorm.beta→encoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.intermediate.dense.weight→encoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.intermediate.dense.bias→encoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.dense.weight→encoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.dense.bias→encoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.LayerNorm.gamma→encoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.LayerNorm.beta→encoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.query.weight→encoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.query.bias→encoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.key.weight→encoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.key.bias→encoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.value.weight→encoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.value.bias→encoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.dense.weight→encoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.dense.bias→encoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.LayerNorm.gamma→encoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.LayerNorm.beta→encoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.intermediate.dense.weight→encoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.intermediate.dense.bias→encoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.dense.weight→encoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.dense.bias→encoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.LayerNorm.gamma→encoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.LayerNorm.beta→encoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.pooler.dense.weight→pooler.dense.weight\u001b[0m\n",
      "\u001b[35mbert.pooler.dense.bias→pooler.dense.bias\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Aug/2021:04:32:44 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Aug/2021:04:32:44 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 4 records\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/1 [00:00<?, ?it/s]#015100%|██████████| 1/1 [00:00<00:00, 38.95it/s]\u001b[0m\n",
      "\u001b[34mTest Data 4 Accuracy: 0.5000\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Aug/2021:04:32:44 +0000] \"POST /invocations HTTP/1.1\" 200 43 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [17/Aug/2021:04:32:44 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [17/Aug/2021:04:32:44 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 4 records\u001b[0m\n",
      "\u001b[35m#015  0%|          | 0/1 [00:00<?, ?it/s]#015100%|██████████| 1/1 [00:00<00:00, 38.95it/s]\u001b[0m\n",
      "\u001b[35mTest Data 4 Accuracy: 0.5000\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [17/Aug/2021:04:32:44 +0000] \"POST /invocations HTTP/1.1\" 200 43 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2021-08-17T04:32:44.789:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "Transform results: \n",
      "Score_Class,Sentence-Score\n",
      "2,0\n",
      "2,1\n",
      "2,2\n",
      "3,3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformer.transform(data_location + '/Pick4-Refmt_Serialized-Sen-ELVA.PILOT.PRE-POST-TEST.csv', content_type='text/csv', split_type='Line')\n",
    "transformer.wait()\n",
    "\n",
    "s3_client = sess.boto_session.client('s3')\n",
    "s3_client.download_file(sess.default_bucket(), \"{}/Pick4-Refmt_Serialized-Sen-ELVA.PILOT.PRE-POST-TEST.csv.out\".format(transform_output_folder), '/tmp/Pick4-Refmt_Serialized-Sen-ELVA.PILOT.PRE-POST-TEST.csv.out')\n",
    "with open('/tmp/Pick4-Refmt_Serialized-Sen-ELVA.PILOT.PRE-POST-TEST.csv.out') as f:\n",
    "    results = f.readlines()   \n",
    "print(\"Transform results: \\n{}\".format(''.join(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
