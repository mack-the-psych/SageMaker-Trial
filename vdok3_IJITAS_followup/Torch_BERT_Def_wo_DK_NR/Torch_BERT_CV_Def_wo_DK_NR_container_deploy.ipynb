{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Sending build context to Docker daemon  30.72kB\n",
      "Step 1/32 : FROM nvidia/cuda:10.0-cudnn7-devel-ubuntu16.04\n",
      " ---> 225b79605de8\n",
      "Step 2/32 : RUN apt-get -y update && apt-get -y upgrade && apt-get install -y --no-install-recommends          curl          git          unzip          bzip2          libgl1-mesa-glx          wget          nginx          ca-certificates     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> f81dac796496\n",
      "Step 3/32 : RUN git clone https://github.com/pyenv/pyenv.git .pyenv\n",
      " ---> Using cache\n",
      " ---> 29b7049525ea\n",
      "Step 4/32 : WORKDIR /\n",
      " ---> Using cache\n",
      " ---> 1794dc1050f9\n",
      "Step 5/32 : ENV HOME  /\n",
      " ---> Using cache\n",
      " ---> 710d1b71c6eb\n",
      "Step 6/32 : ENV PYENV_ROOT /.pyenv\n",
      " ---> Using cache\n",
      " ---> a30013e47bf5\n",
      "Step 7/32 : ENV PATH $PYENV_ROOT/shims:$PYENV_ROOT/bin:$PATH\n",
      " ---> Using cache\n",
      " ---> a48564c82db3\n",
      "Step 8/32 : RUN pyenv install anaconda3-5.0.0\n",
      " ---> Using cache\n",
      " ---> c3ed4ddab997\n",
      "Step 9/32 : RUN pyenv global anaconda3-5.0.0\n",
      " ---> Using cache\n",
      " ---> 65c508120e0b\n",
      "Step 10/32 : RUN pyenv rehash\n",
      " ---> Using cache\n",
      " ---> 66bdb3840a4d\n",
      "Step 11/32 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> 6047104a257b\n",
      "Step 12/32 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> d8cb40faabaf\n",
      "Step 13/32 : ENV PATH=\"/opt/program:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 51bceb4a60c8\n",
      "Step 14/32 : ENV PYTHONIOENCODING=utf-8\n",
      " ---> Using cache\n",
      " ---> c8a745d7115b\n",
      "Step 15/32 : WORKDIR /opt/program\n",
      " ---> Using cache\n",
      " ---> 6de9a03efd99\n",
      "Step 16/32 : RUN git clone https://github.com/mack-the-psych/plimac3.git\n",
      " ---> Using cache\n",
      " ---> 8c10524ee2be\n",
      "Step 17/32 : RUN echo \"/opt/program/plimac3/Lib\" > /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/plimac-custom.pth\n",
      " ---> Using cache\n",
      " ---> 1f685b3e7033\n",
      "Step 18/32 : RUN echo \"/opt/program/plimac3/Tools\" >> /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/plimac-custom.pth\n",
      " ---> Using cache\n",
      " ---> e870aaa642ef\n",
      "Step 19/32 : RUN conda install -c anaconda setuptools\n",
      " ---> Using cache\n",
      " ---> 06877fef41d7\n",
      "Step 20/32 : RUN pip install --upgrade pip &&     pip install tensorflow-gpu==1.14.0 --user &&     pip install ml_metrics==0.1.4 &&     pip install --upgrade scipy==1.1.0 &&     conda clean --all &&     conda install pytorch==1.0.0 torchvision==0.2.1 cuda100 -c pytorch &&     pip install torchtext==0.4.0 &&     pip install attrdict==2.0.1 &&     pip uninstall --yes numpy &&     pip install numpy==1.16.4 &&     pip uninstall --yes gast &&     pip install gast==0.2.2 &&     pip install -U gevent==1.4.0 --ignore-installed &&     pip install gunicorn\n",
      " ---> Using cache\n",
      " ---> 5d94a0ac1fc5\n",
      "Step 21/32 : WORKDIR /opt/program\n",
      " ---> Using cache\n",
      " ---> 9c91bc6c5f5f\n",
      "Step 22/32 : RUN git clone https://github.com/mack-the-psych/vdok3.git\n",
      " ---> Using cache\n",
      " ---> 9e1d3284468b\n",
      "Step 23/32 : RUN echo \"/opt/program/vdok3/prep\" > /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/vdok3-custom.pth\n",
      " ---> Using cache\n",
      " ---> b9ef5d6f32ed\n",
      "Step 24/32 : RUN echo \"/opt/program/vdok3/extract\" >> /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/vdok3-custom.pth\n",
      " ---> Using cache\n",
      " ---> ed3b292d0e77\n",
      "Step 25/32 : RUN echo \"/opt/program/vdok3/process\" >> /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/vdok3-custom.pth\n",
      " ---> Using cache\n",
      " ---> 0da41942eca6\n",
      "Step 26/32 : RUN echo \"/opt/program/vdok3/reorganize\" >> /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/vdok3-custom.pth\n",
      " ---> Using cache\n",
      " ---> ce0aab64eaf8\n",
      "Step 27/32 : RUN echo \"/opt/program/vdok3/train\" >> /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/vdok3-custom.pth\n",
      " ---> Using cache\n",
      " ---> 3b7fa4f87f53\n",
      "Step 28/32 : RUN echo \"/opt/program/vdok3/train/pytorch_advanced/nlp_sentiment_bert\" >> /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/vdok3-custom.pth\n",
      " ---> Using cache\n",
      " ---> 0da9f8e55dcf\n",
      "Step 29/32 : WORKDIR /opt/program/vdok3/train/pytorch_advanced/nlp_sentiment_bert\n",
      " ---> Using cache\n",
      " ---> 85c4183b3e50\n",
      "Step 30/32 : RUN python make_folders_and_data_downloads.py\n",
      " ---> Using cache\n",
      " ---> 2125e32b7b14\n",
      "Step 31/32 : COPY vdok3_sage /opt/program\n",
      " ---> 5844253c27d5\n",
      "Step 32/32 : WORKDIR /opt/program\n",
      " ---> Running in 03c57e29b8cb\n",
      "Removing intermediate container 03c57e29b8cb\n",
      " ---> f02ae4becd1f\n",
      "Successfully built f02ae4becd1f\n",
      "Successfully tagged sagemaker-vdok3-bert-cv-def-wo-dknr:latest\n",
      "The push refers to repository [822408253028.dkr.ecr.us-west-2.amazonaws.com/sagemaker-vdok3-bert-cv-def-wo-dknr]\n",
      "4b727aa85ba1: Preparing\n",
      "eb94f24f5ad7: Preparing\n",
      "be23f8a4ed08: Preparing\n",
      "2333bf2d8c34: Preparing\n",
      "bcf0b9fb86f7: Preparing\n",
      "d1c87b4917ba: Preparing\n",
      "1379185bec41: Preparing\n",
      "34c09c07d44f: Preparing\n",
      "8da672bd8fef: Preparing\n",
      "301342a5ac2c: Preparing\n",
      "3ac2454fe7ca: Preparing\n",
      "9b9ef40c3fb2: Preparing\n",
      "49fa2998b485: Preparing\n",
      "72400ed43881: Preparing\n",
      "97e5b4ec388b: Preparing\n",
      "b20c62adb3cf: Preparing\n",
      "bf18a6c0e470: Preparing\n",
      "0de0186b0e0f: Preparing\n",
      "d152753df06e: Preparing\n",
      "653349137921: Preparing\n",
      "e71e95da3d2b: Preparing\n",
      "6d2269456418: Preparing\n",
      "521a1bca4c9e: Preparing\n",
      "0fd113e52582: Preparing\n",
      "9fd67b1e1831: Preparing\n",
      "f1c9680a678d: Preparing\n",
      "fa4b3468268c: Preparing\n",
      "66ad31b9547f: Preparing\n",
      "8d897fc1271a: Preparing\n",
      "b0c360818224: Preparing\n",
      "d35aa7fd29b6: Preparing\n",
      "c0eeb6e15fd7: Preparing\n",
      "91cba8fa7129: Preparing\n",
      "72400ed43881: Waiting\n",
      "97e5b4ec388b: Waiting\n",
      "b20c62adb3cf: Waiting\n",
      "bf18a6c0e470: Waiting\n",
      "0de0186b0e0f: Waiting\n",
      "d152753df06e: Waiting\n",
      "653349137921: Waiting\n",
      "e71e95da3d2b: Waiting\n",
      "6d2269456418: Waiting\n",
      "521a1bca4c9e: Waiting\n",
      "0fd113e52582: Waiting\n",
      "9fd67b1e1831: Waiting\n",
      "f1c9680a678d: Waiting\n",
      "fa4b3468268c: Waiting\n",
      "66ad31b9547f: Waiting\n",
      "8d897fc1271a: Waiting\n",
      "b0c360818224: Waiting\n",
      "d35aa7fd29b6: Waiting\n",
      "c0eeb6e15fd7: Waiting\n",
      "91cba8fa7129: Waiting\n",
      "8da672bd8fef: Waiting\n",
      "301342a5ac2c: Waiting\n",
      "3ac2454fe7ca: Waiting\n",
      "9b9ef40c3fb2: Waiting\n",
      "49fa2998b485: Waiting\n",
      "d1c87b4917ba: Waiting\n",
      "1379185bec41: Waiting\n",
      "34c09c07d44f: Waiting\n",
      "be23f8a4ed08: Pushed\n",
      "2333bf2d8c34: Pushed\n",
      "4b727aa85ba1: Pushed\n",
      "bcf0b9fb86f7: Pushed\n",
      "d1c87b4917ba: Pushed\n",
      "34c09c07d44f: Pushed\n",
      "1379185bec41: Pushed\n",
      "8da672bd8fef: Pushed\n",
      "9b9ef40c3fb2: Pushed\n",
      "49fa2998b485: Pushed\n",
      "97e5b4ec388b: Pushed\n",
      "b20c62adb3cf: Pushed\n",
      "bf18a6c0e470: Pushed\n",
      "72400ed43881: Pushed\n",
      "3ac2454fe7ca: Pushed\n",
      "d152753df06e: Pushed\n",
      "653349137921: Pushed\n",
      "6d2269456418: Pushed\n",
      "eb94f24f5ad7: Pushed\n",
      "0fd113e52582: Pushed\n",
      "e71e95da3d2b: Pushed\n",
      "f1c9680a678d: Pushed\n",
      "fa4b3468268c: Pushed\n",
      "66ad31b9547f: Pushed\n",
      "8d897fc1271a: Pushed\n",
      "b0c360818224: Pushed\n",
      "d35aa7fd29b6: Pushed\n",
      "c0eeb6e15fd7: Pushed\n",
      "9fd67b1e1831: Pushed\n",
      "91cba8fa7129: Pushed\n",
      "521a1bca4c9e: Pushed\n",
      "0de0186b0e0f: Pushed\n",
      "301342a5ac2c: Pushed\n",
      "latest: digest: sha256:8add7536f9368b2ad011fab4be8b180546f1560ad0e112fc60e7a640ea02d607 size: 7229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.6 ms, sys: 2.48 ms, total: 22.1 ms\n",
      "Wall time: 5min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "# Makoto.Sano@Mack-the-Psych.com\n",
    "algorithm_name=sagemaker-vdok3-bert-cv-def-wo-dknr\n",
    "\n",
    "cd container\n",
    "\n",
    "chmod +x vdok3_sage/train\n",
    "chmod +x vdok3_sage/serve\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build  -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "# Makoto.Sano@Mack-the-Psych.com\n",
    "prefix = 'vdok3_bert_cv_def_wo_dknr'\n",
    "\n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sess = sage.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIRECTORY = 'data'\n",
    "\n",
    "data_location = sess.upload_data(WORK_DIRECTORY, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-17 02:34:02 Starting - Starting the training job...\n",
      "2021-08-17 02:34:28 Starting - Launching requested ML instancesProfilerReport-1629167642: InProgress\n",
      "......\n",
      "2021-08-17 02:35:32 Starting - Preparing the instances for training.........\n",
      "2021-08-17 02:36:48 Downloading - Downloading input data\n",
      "2021-08-17 02:36:48 Training - Downloading the training image.....................\n",
      "2021-08-17 02:40:29 Training - Training image download completed. Training in progress.\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34mStarting the training.\u001b[0m\n",
      "\u001b[34mbert.embeddings.word_embeddings.weight→embeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.position_embeddings.weight→embeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.token_type_embeddings.weight→embeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.gamma→embeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.beta→embeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.weight→encoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.bias→encoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.weight→encoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.bias→encoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.weight→encoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.bias→encoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.weight→encoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.bias→encoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.gamma→encoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.beta→encoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.weight→encoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.bias→encoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.weight→encoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.bias→encoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.gamma→encoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.beta→encoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.weight→encoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.bias→encoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.weight→encoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.bias→encoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.weight→encoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.bias→encoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.weight→encoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.bias→encoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.gamma→encoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.beta→encoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.weight→encoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.bias→encoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.weight→encoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.bias→encoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.gamma→encoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.beta→encoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.weight→encoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.bias→encoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.weight→encoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.bias→encoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.weight→encoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.bias→encoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.weight→encoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.bias→encoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.gamma→encoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.beta→encoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.weight→encoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.bias→encoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.weight→encoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.bias→encoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.gamma→encoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.beta→encoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.weight→encoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.bias→encoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.weight→encoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.bias→encoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.weight→encoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.bias→encoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.weight→encoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.bias→encoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.gamma→encoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.beta→encoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.weight→encoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.bias→encoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.weight→encoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.bias→encoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.gamma→encoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.beta→encoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.weight→encoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.bias→encoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.weight→encoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.bias→encoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.weight→encoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.bias→encoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.weight→encoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.bias→encoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.gamma→encoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.beta→encoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.weight→encoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.bias→encoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.weight→encoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.bias→encoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.gamma→encoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.beta→encoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.weight→encoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.bias→encoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.weight→encoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.bias→encoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.weight→encoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.bias→encoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.weight→encoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.bias→encoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.gamma→encoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.beta→encoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.weight→encoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.bias→encoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.weight→encoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.bias→encoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.gamma→encoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.beta→encoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.weight→encoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.bias→encoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.weight→encoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.bias→encoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.weight→encoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.bias→encoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.weight→encoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.bias→encoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.gamma→encoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.beta→encoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.weight→encoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.bias→encoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.weight→encoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.bias→encoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.gamma→encoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.beta→encoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.weight→encoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.bias→encoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.weight→encoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.bias→encoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.weight→encoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.bias→encoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.weight→encoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.bias→encoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.gamma→encoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.beta→encoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.weight→encoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.bias→encoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.weight→encoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.bias→encoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.gamma→encoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.beta→encoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.weight→encoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.bias→encoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.weight→encoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.bias→encoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.weight→encoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.bias→encoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.weight→encoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.bias→encoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.gamma→encoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.beta→encoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.weight→encoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.bias→encoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.weight→encoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.bias→encoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.gamma→encoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.beta→encoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.weight→encoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.bias→encoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.weight→encoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.bias→encoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.weight→encoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.bias→encoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.weight→encoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.bias→encoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.gamma→encoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.beta→encoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.weight→encoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.bias→encoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.weight→encoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.bias→encoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.gamma→encoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.beta→encoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.weight→encoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.bias→encoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.weight→encoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.bias→encoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.weight→encoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.bias→encoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.weight→encoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.bias→encoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.gamma→encoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.beta→encoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.weight→encoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.bias→encoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.weight→encoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.bias→encoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.gamma→encoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.beta→encoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.weight→encoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.bias→encoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.weight→encoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.bias→encoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.weight→encoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.bias→encoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.weight→encoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.bias→encoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.gamma→encoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.beta→encoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.weight→encoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.bias→encoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.weight→encoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.bias→encoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.gamma→encoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.beta→encoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.weight→pooler.dense.weight\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.bias→pooler.dense.bias\u001b[0m\n",
      "\u001b[34m----------------\u001b[0m\n",
      "\u001b[34mRANDOM SET:  0\u001b[0m\n",
      "\u001b[34mConcat Value Len: 1622\u001b[0m\n",
      "\u001b[34m(tensor([[ 101, 2009, 2965,  ...,    0,    0,    0],\n",
      "        [ 101, 5577, 2242,  ...,    0,    0,    0],\n",
      "        [ 101, 1037, 2711,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 2009, 2965,  ...,    0,    0,    0],\n",
      "        [ 101, 2242, 2008,  ...,    0,    0,    0],\n",
      "        [ 101, 1037, 2711,  ...,    0,    0,    0]]), tensor([26, 17, 24, 16, 16, 21, 25, 22, 19, 22, 14, 15, 20, 16, 23, 28, 16, 20,\n",
      "        16, 20, 16, 21, 12, 15, 16, 20, 21, 24, 23, 23, 14, 19]))\u001b[0m\n",
      "\u001b[34mtensor([1, 2, 0, 0, 2, 0, 0, 1, 1, 1, 1, 0, 1, 2, 2, 2, 2, 1, 0, 0, 1, 0, 0, 1,\n",
      "        2, 0, 0, 2, 0, 2, 1, 1])\u001b[0m\n",
      "\u001b[34m['[CLS]', 'describes', 'something', 'that', 'is', 'very', 'difficult', 'or', 'cannot', 'happen', 'that', 'you', 'can', 't', 'do', 'it', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34mUsing device:  cuda:0\u001b[0m\n",
      "\u001b[34m-----start-------\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 1.1582 || 10iter: 0.9214 sec. || Accuracy: 0.4375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 1.0756 || 10iter: 0.8803 sec. || Accuracy: 0.375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 1.1206 || 10iter: 0.8810 sec. || Accuracy: 0.34375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 1.0549 || 10iter: 0.8819 sec. || Accuracy: 0.5\u001b[0m\n",
      "\u001b[34mEpoch 1/10 | train |  Loss: 1.0869 Acc: 0.4183\u001b[0m\n",
      "\u001b[34mEpoch 1/10 |  val  |  Loss: 1.1099 Acc: 0.5000\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 1.0897 || 10iter: 0.8837 sec. || Accuracy: 0.375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 1.0267 || 10iter: 0.8794 sec. || Accuracy: 0.53125\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.9013 || 10iter: 0.8811 sec. || Accuracy: 0.5625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.9618 || 10iter: 0.8796 sec. || Accuracy: 0.5625\u001b[0m\n",
      "\u001b[34mEpoch 2/10 | train |  Loss: 1.0272 Acc: 0.4807\u001b[0m\n",
      "\u001b[34mEpoch 2/10 |  val  |  Loss: 1.0485 Acc: 0.5463\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.9357 || 10iter: 0.8824 sec. || Accuracy: 0.5\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.9903 || 10iter: 0.8796 sec. || Accuracy: 0.40625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.7743 || 10iter: 0.8804 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 1.0511 || 10iter: 0.8815 sec. || Accuracy: 0.4375\u001b[0m\n",
      "\u001b[34mEpoch 3/10 | train |  Loss: 0.9345 Acc: 0.5639\u001b[0m\n",
      "\u001b[34mEpoch 3/10 |  val  |  Loss: 0.9319 Acc: 0.6296\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.7294 || 10iter: 0.8871 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.8227 || 10iter: 0.8827 sec. || Accuracy: 0.65625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.7898 || 10iter: 0.8844 sec. || Accuracy: 0.625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.8622 || 10iter: 0.8844 sec. || Accuracy: 0.59375\u001b[0m\n",
      "\u001b[34mEpoch 4/10 | train |  Loss: 0.8685 Acc: 0.6225\u001b[0m\n",
      "\u001b[34mEpoch 4/10 |  val  |  Loss: 0.8893 Acc: 0.6451\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.6766 || 10iter: 0.8842 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.7085 || 10iter: 0.8846 sec. || Accuracy: 0.625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.9902 || 10iter: 0.8828 sec. || Accuracy: 0.5625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.6631 || 10iter: 0.8866 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mEpoch 5/10 | train |  Loss: 0.8165 Acc: 0.6602\u001b[0m\n",
      "\u001b[34mEpoch 5/10 |  val  |  Loss: 0.8328 Acc: 0.7068\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.7531 || 10iter: 0.8885 sec. || Accuracy: 0.625\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.7303 || 10iter: 0.8873 sec. || Accuracy: 0.625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.8264 || 10iter: 0.8909 sec. || Accuracy: 0.65625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.7151 || 10iter: 0.8851 sec. || Accuracy: 0.6875\u001b[0m\n",
      "\u001b[34mEpoch 6/10 | train |  Loss: 0.7874 Acc: 0.6510\u001b[0m\n",
      "\u001b[34mEpoch 6/10 |  val  |  Loss: 0.8370 Acc: 0.6512\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.8500 || 10iter: 0.8928 sec. || Accuracy: 0.65625\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.6903 || 10iter: 0.8864 sec. || Accuracy: 0.6875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.8432 || 10iter: 0.8857 sec. || Accuracy: 0.6875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.7802 || 10iter: 0.8843 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mEpoch 7/10 | train |  Loss: 0.7339 Acc: 0.6995\u001b[0m\n",
      "\u001b[34mEpoch 7/10 |  val  |  Loss: 0.8935 Acc: 0.6790\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.4498 || 10iter: 0.8866 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.7057 || 10iter: 0.8854 sec. || Accuracy: 0.625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.8326 || 10iter: 0.8843 sec. || Accuracy: 0.59375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.5212 || 10iter: 0.8843 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mEpoch 8/10 | train |  Loss: 0.6833 Acc: 0.7072\u001b[0m\n",
      "\u001b[34mEpoch 8/10 |  val  |  Loss: 0.8028 Acc: 0.7130\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.5627 || 10iter: 0.8890 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.7121 || 10iter: 0.8847 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.5202 || 10iter: 0.8835 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.4824 || 10iter: 0.8869 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mEpoch 9/10 | train |  Loss: 0.6430 Acc: 0.7257\u001b[0m\n",
      "\u001b[34mEpoch 9/10 |  val  |  Loss: 0.8960 Acc: 0.6698\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.5845 || 10iter: 0.8844 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.7396 || 10iter: 0.8857 sec. || Accuracy: 0.625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 1.0129 || 10iter: 0.8828 sec. || Accuracy: 0.59375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.7826 || 10iter: 0.8859 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mEpoch 10/10 | train |  Loss: 0.6267 Acc: 0.7357\u001b[0m\n",
      "\u001b[34mEpoch 10/10 |  val  |  Loss: 0.8450 Acc: 0.6481\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/17 [00:00<?, ?it/s]#015 12%|█▏        | 2/17 [00:00<00:01, 12.46it/s]#015 24%|██▎       | 4/17 [00:00<00:01, 12.45it/s]#015 35%|███▌      | 6/17 [00:00<00:00, 12.46it/s]#015 47%|████▋     | 8/17 [00:00<00:00, 12.45it/s]#015 59%|█████▉    | 10/17 [00:00<00:00, 12.45it/s]#015 71%|███████   | 12/17 [00:00<00:00, 12.45it/s]#015 82%|████████▏ | 14/17 [00:01<00:00, 12.43it/s]#015 94%|█████████▍| 16/17 [00:01<00:00, 12.43it/s]#015100%|██████████| 17/17 [00:01<00:00, 12.52it/s]\u001b[0m\n",
      "\u001b[34mTest Data 540 Accuracy: 0.6741\u001b[0m\n",
      "\u001b[34mRecall                      0.6741\u001b[0m\n",
      "\u001b[34mPrecision                   0.7008\u001b[0m\n",
      "\u001b[34mF1                          0.6747\u001b[0m\n",
      "\u001b[34mKappa                       0.5112\u001b[0m\n",
      "\u001b[34mQuadratic Weighted Kappa    0.5666\u001b[0m\n",
      "\u001b[34mdtype: float64\u001b[0m\n",
      "\u001b[34mConfusion Matrix:\n",
      "     0    1    2\u001b[0m\n",
      "\u001b[34m0  138   63   35\u001b[0m\n",
      "\u001b[34m1   23  124   28\u001b[0m\n",
      "\u001b[34m2    7   20  102\u001b[0m\n",
      "\u001b[34m----------------\u001b[0m\n",
      "\u001b[34mRANDOM SET:  1\u001b[0m\n",
      "\u001b[34mConcat Value Len: 1622\u001b[0m\n",
      "\u001b[34m(tensor([[ 101, 2009, 2965,  ...,    0,    0,    0],\n",
      "        [ 101, 5577, 2242,  ...,    0,    0,    0],\n",
      "        [ 101, 1037, 2711,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 2000, 2689,  ...,    0,    0,    0],\n",
      "        [ 101, 1996, 2844,  ...,    0,    0,    0],\n",
      "        [ 101, 1037, 2711,  ...,    0,    0,    0]]), tensor([26, 17, 24, 24, 11, 17, 25, 22, 19, 22, 24, 15, 33, 16, 23, 12, 16, 20,\n",
      "        16, 20, 16, 21, 12, 15, 16, 20, 17, 24, 23, 16, 24, 22]))\u001b[0m\n",
      "\u001b[34mtensor([1, 2, 0, 1, 0, 2, 0, 1, 1, 1, 0, 0, 2, 2, 2, 0, 2, 1, 0, 0, 1, 0, 0, 1,\n",
      "        2, 0, 2, 2, 0, 0, 2, 0])\u001b[0m\n",
      "\u001b[34m['[CLS]', 'describes', 'something', 'that', 'is', 'very', 'difficult', 'or', 'cannot', 'happen', 'that', 'you', 'can', 't', 'do', 'it', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34mUsing device:  cuda:0\u001b[0m\n",
      "\u001b[34m-----start-------\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.8814 || 10iter: 0.8880 sec. || Accuracy: 0.53125\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.7347 || 10iter: 0.8848 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.6867 || 10iter: 0.8906 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.8549 || 10iter: 0.8861 sec. || Accuracy: 0.6875\u001b[0m\n",
      "\u001b[34mEpoch 1/10 | train |  Loss: 0.8167 Acc: 0.6602\u001b[0m\n",
      "\u001b[34mEpoch 1/10 |  val  |  Loss: 0.7790 Acc: 0.6944\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.6911 || 10iter: 0.8903 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.8171 || 10iter: 0.8937 sec. || Accuracy: 0.59375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.5824 || 10iter: 0.8863 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.6933 || 10iter: 0.8853 sec. || Accuracy: 0.65625\u001b[0m\n",
      "\u001b[34mEpoch 2/10 | train |  Loss: 0.6556 Acc: 0.7250\u001b[0m\n",
      "\u001b[34mEpoch 2/10 |  val  |  Loss: 0.7946 Acc: 0.7068\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.6489 || 10iter: 0.8904 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.6820 || 10iter: 0.8866 sec. || Accuracy: 0.6875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.6256 || 10iter: 0.8876 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.5955 || 10iter: 0.8866 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mEpoch 3/10 | train |  Loss: 0.6229 Acc: 0.7481\u001b[0m\n",
      "\u001b[34mEpoch 3/10 |  val  |  Loss: 0.8494 Acc: 0.6636\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.5088 || 10iter: 0.8888 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.4674 || 10iter: 0.8875 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.6472 || 10iter: 0.8891 sec. || Accuracy: 0.65625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.3795 || 10iter: 0.8900 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mEpoch 4/10 | train |  Loss: 0.6015 Acc: 0.7519\u001b[0m\n",
      "\u001b[34mEpoch 4/10 |  val  |  Loss: 0.7160 Acc: 0.7315\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.7549 || 10iter: 0.8904 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.6844 || 10iter: 0.8904 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.6507 || 10iter: 0.8882 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.4322 || 10iter: 0.8916 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mEpoch 5/10 | train |  Loss: 0.5809 Acc: 0.7604\u001b[0m\n",
      "\u001b[34mEpoch 5/10 |  val  |  Loss: 0.7332 Acc: 0.7191\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.5961 || 10iter: 0.8894 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.4993 || 10iter: 0.8884 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.5429 || 10iter: 0.8902 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.3960 || 10iter: 0.8871 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mEpoch 6/10 | train |  Loss: 0.5081 Acc: 0.8020\u001b[0m\n",
      "\u001b[34mEpoch 6/10 |  val  |  Loss: 0.7972 Acc: 0.6914\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.6017 || 10iter: 0.8909 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.8609 || 10iter: 0.8903 sec. || Accuracy: 0.625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.5985 || 10iter: 0.8905 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.7748 || 10iter: 0.8900 sec. || Accuracy: 0.6875\u001b[0m\n",
      "\u001b[34mEpoch 7/10 | train |  Loss: 0.5214 Acc: 0.7928\u001b[0m\n",
      "\u001b[34mEpoch 7/10 |  val  |  Loss: 0.7812 Acc: 0.7160\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.6101 || 10iter: 0.8930 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.7633 || 10iter: 0.8869 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.5939 || 10iter: 0.8924 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.3934 || 10iter: 0.8899 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mEpoch 8/10 | train |  Loss: 0.4973 Acc: 0.8089\u001b[0m\n",
      "\u001b[34mEpoch 8/10 |  val  |  Loss: 0.7243 Acc: 0.7346\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.3270 || 10iter: 0.8917 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.5516 || 10iter: 0.8912 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.3022 || 10iter: 0.8891 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.3922 || 10iter: 0.8866 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mEpoch 9/10 | train |  Loss: 0.4704 Acc: 0.8020\u001b[0m\n",
      "\u001b[34mEpoch 9/10 |  val  |  Loss: 0.7626 Acc: 0.7315\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.3923 || 10iter: 0.8896 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.3584 || 10iter: 0.8884 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.6189 || 10iter: 0.8881 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.8172 || 10iter: 0.8883 sec. || Accuracy: 0.59375\u001b[0m\n",
      "\u001b[34mEpoch 10/10 | train |  Loss: 0.4532 Acc: 0.8228\u001b[0m\n",
      "\u001b[34mEpoch 10/10 |  val  |  Loss: 0.7769 Acc: 0.7191\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/17 [00:00<?, ?it/s]#015 12%|█▏        | 2/17 [00:00<00:01, 12.41it/s]#015 24%|██▎       | 4/17 [00:00<00:01, 12.41it/s]#015 35%|███▌      | 6/17 [00:00<00:00, 12.41it/s]#015 47%|████▋     | 8/17 [00:00<00:00, 12.41it/s]#015 59%|█████▉    | 10/17 [00:00<00:00, 12.40it/s]#015 71%|███████   | 12/17 [00:00<00:00, 12.39it/s]#015 82%|████████▏ | 14/17 [00:01<00:00, 12.38it/s]#015 94%|█████████▍| 16/17 [00:01<00:00, 12.37it/s]#015100%|██████████| 17/17 [00:01<00:00, 12.47it/s]\u001b[0m\n",
      "\u001b[34mTest Data 540 Accuracy: 0.7519\u001b[0m\n",
      "\u001b[34mRecall                      0.7519\u001b[0m\n",
      "\u001b[34mPrecision                   0.7647\u001b[0m\n",
      "\u001b[34mF1                          0.7499\u001b[0m\n",
      "\u001b[34mKappa                       0.6200\u001b[0m\n",
      "\u001b[34mQuadratic Weighted Kappa    0.6695\u001b[0m\n",
      "\u001b[34mdtype: float64\u001b[0m\n",
      "\u001b[34mConfusion Matrix:\n",
      "     0    1   2\u001b[0m\n",
      "\u001b[34m0  140   59  19\u001b[0m\n",
      "\u001b[34m1   21  168  22\u001b[0m\n",
      "\u001b[34m2    5    8  98\u001b[0m\n",
      "\u001b[34m----------------\u001b[0m\n",
      "\u001b[34mRANDOM SET:  2\u001b[0m\n",
      "\u001b[34mConcat Value Len: 1622\u001b[0m\n",
      "\u001b[34m(tensor([[ 101, 2009, 2965,  ...,    0,    0,    0],\n",
      "        [ 101, 5577, 2242,  ...,    0,    0,    0],\n",
      "        [ 101, 1037, 2711,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 2000, 2689,  ...,    0,    0,    0],\n",
      "        [ 101, 1996, 2844,  ...,    0,    0,    0],\n",
      "        [ 101, 1037, 2711,  ...,    0,    0,    0]]), tensor([29, 17, 24, 24, 11, 17, 18, 36, 19, 22, 24, 15, 33, 19, 23, 12, 16, 20,\n",
      "        16, 20, 16, 12, 23, 15, 26, 18, 17, 19, 23, 16, 24, 22]))\u001b[0m\n",
      "\u001b[34mtensor([2, 2, 0, 1, 0, 2, 0, 1, 1, 1, 0, 0, 2, 2, 2, 0, 2, 1, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0, 2, 0, 0, 0, 2, 0])\u001b[0m\n",
      "\u001b[34m['[CLS]', 'describes', 'something', 'that', 'is', 'very', 'difficult', 'or', 'cannot', 'happen', 'that', 'you', 'can', 't', 'do', 'it', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34mUsing device:  cuda:0\u001b[0m\n",
      "\u001b[34m-----start-------\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.7356 || 10iter: 0.8888 sec. || Accuracy: 0.65625\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.5773 || 10iter: 0.8876 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.6373 || 10iter: 0.8878 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.7671 || 10iter: 0.8883 sec. || Accuracy: 0.59375\u001b[0m\n",
      "\u001b[34mEpoch 1/10 | train |  Loss: 0.6948 Acc: 0.7157\u001b[0m\n",
      "\u001b[34mEpoch 1/10 |  val  |  Loss: 0.6052 Acc: 0.7685\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.5895 || 10iter: 0.8929 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.5475 || 10iter: 0.8883 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.5849 || 10iter: 0.8882 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.3433 || 10iter: 0.8875 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mEpoch 2/10 | train |  Loss: 0.5364 Acc: 0.7866\u001b[0m\n",
      "\u001b[34mEpoch 2/10 |  val  |  Loss: 0.5922 Acc: 0.7716\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.5717 || 10iter: 0.8904 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.4771 || 10iter: 0.8877 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.5718 || 10iter: 0.8906 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.3934 || 10iter: 0.8884 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mEpoch 3/10 | train |  Loss: 0.5045 Acc: 0.7982\u001b[0m\n",
      "\u001b[34mEpoch 3/10 |  val  |  Loss: 0.5961 Acc: 0.7623\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.3795 || 10iter: 0.8914 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.5859 || 10iter: 0.8902 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.5748 || 10iter: 0.8895 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.4333 || 10iter: 0.8887 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mEpoch 4/10 | train |  Loss: 0.4790 Acc: 0.8066\u001b[0m\n",
      "\u001b[34mEpoch 4/10 |  val  |  Loss: 0.6182 Acc: 0.7562\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.6024 || 10iter: 0.8916 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.4567 || 10iter: 0.8890 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.2935 || 10iter: 0.8901 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.2787 || 10iter: 0.8900 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mEpoch 5/10 | train |  Loss: 0.4732 Acc: 0.8066\u001b[0m\n",
      "\u001b[34mEpoch 5/10 |  val  |  Loss: 0.6739 Acc: 0.7500\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.4833 || 10iter: 0.8922 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.4823 || 10iter: 0.8895 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.4864 || 10iter: 0.8879 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.3260 || 10iter: 0.8894 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mEpoch 6/10 | train |  Loss: 0.4563 Acc: 0.8066\u001b[0m\n",
      "\u001b[34mEpoch 6/10 |  val  |  Loss: 0.6605 Acc: 0.7623\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.5025 || 10iter: 0.8909 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.4359 || 10iter: 0.8907 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.3430 || 10iter: 0.8887 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.6504 || 10iter: 0.8893 sec. || Accuracy: 0.6875\u001b[0m\n",
      "\u001b[34mEpoch 7/10 | train |  Loss: 0.4265 Acc: 0.8297\u001b[0m\n",
      "\u001b[34mEpoch 7/10 |  val  |  Loss: 0.6211 Acc: 0.7778\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.2786 || 10iter: 0.8911 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.6781 || 10iter: 0.8898 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.3459 || 10iter: 0.8918 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.3975 || 10iter: 0.8922 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mEpoch 8/10 | train |  Loss: 0.3923 Acc: 0.8552\u001b[0m\n",
      "\u001b[34mEpoch 8/10 |  val  |  Loss: 0.6133 Acc: 0.7716\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.4687 || 10iter: 0.8922 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.4869 || 10iter: 0.8994 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.4742 || 10iter: 0.8934 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.3503 || 10iter: 0.8908 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mEpoch 9/10 | train |  Loss: 0.3914 Acc: 0.8428\u001b[0m\n",
      "\u001b[34mEpoch 9/10 |  val  |  Loss: 0.6655 Acc: 0.7500\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.5396 || 10iter: 0.8937 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.3009 || 10iter: 0.8900 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.4176 || 10iter: 0.8942 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.6400 || 10iter: 0.8908 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mEpoch 10/10 | train |  Loss: 0.3773 Acc: 0.8498\u001b[0m\n",
      "\u001b[34mEpoch 10/10 |  val  |  Loss: 0.6894 Acc: 0.7685\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/17 [00:00<?, ?it/s]#015 12%|█▏        | 2/17 [00:00<00:01, 12.38it/s]#015 24%|██▎       | 4/17 [00:00<00:01, 12.38it/s]#015 35%|███▌      | 6/17 [00:00<00:00, 12.38it/s]#015 47%|████▋     | 8/17 [00:00<00:00, 12.37it/s]#015 59%|█████▉    | 10/17 [00:00<00:00, 12.34it/s]#015 71%|███████   | 12/17 [00:00<00:00, 12.34it/s]#015 82%|████████▏ | 14/17 [00:01<00:00, 12.34it/s]#015 94%|█████████▍| 16/17 [00:01<00:00, 12.35it/s]#015100%|██████████| 17/17 [00:01<00:00, 12.43it/s]\u001b[0m\n",
      "\u001b[34mTest Data 540 Accuracy: 0.8241\u001b[0m\n",
      "\u001b[34mRecall                      0.8241\u001b[0m\n",
      "\u001b[34mPrecision                   0.8333\u001b[0m\n",
      "\u001b[34mF1                          0.8250\u001b[0m\n",
      "\u001b[34mKappa                       0.7323\u001b[0m\n",
      "\u001b[34mQuadratic Weighted Kappa    0.7954\u001b[0m\n",
      "\u001b[34mdtype: float64\u001b[0m\n",
      "\u001b[34mConfusion Matrix:\n",
      "     0    1    2\u001b[0m\n",
      "\u001b[34m0  176   40   11\u001b[0m\n",
      "\u001b[34m1   14  155   14\u001b[0m\n",
      "\u001b[34m2    3   13  114\u001b[0m\n",
      "\u001b[34m----------------\u001b[0m\n",
      "\u001b[34mRANDOM SET:  3\u001b[0m\n",
      "\u001b[34mConcat Value Len: 1620\u001b[0m\n",
      "\u001b[34m(tensor([[ 101, 2009, 2965,  ...,    0,    0,    0],\n",
      "        [ 101, 1037, 2486,  ...,    0,    0,    0],\n",
      "        [ 101, 1037, 2711,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5577, 2242,  ...,    0,    0,    0],\n",
      "        [ 101, 2009, 2965,  ...,    0,    0,    0],\n",
      "        [ 101, 2000, 2689,  ...,    0,    0,    0]]), tensor([13, 15, 19, 23, 22, 24, 11, 17, 22, 22, 27, 19, 24, 19, 33, 19, 12, 12,\n",
      "        15, 19, 19, 22, 19, 18, 20, 21, 23, 25, 17, 19, 19, 16]))\u001b[0m\n",
      "\u001b[34mtensor([1, 2, 0, 1, 1, 1, 0, 2, 1, 1, 2, 0, 0, 1, 2, 1, 1, 0, 1, 1, 2, 1, 1, 2,\n",
      "        2, 1, 2, 1, 2, 2, 2, 0])\u001b[0m\n",
      "\u001b[34m['[CLS]', 'a', 'force', 'pushing', 'against', 'something', '.', 'like', 'someone', 'is', 'going', 'hard', 'on', 'you', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34mUsing device:  cuda:0\u001b[0m\n",
      "\u001b[34m-----start-------\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.7674 || 10iter: 0.8923 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.4401 || 10iter: 0.8917 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.5815 || 10iter: 0.8929 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.5911 || 10iter: 0.8942 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mEpoch 1/10 | train |  Loss: 0.6336 Acc: 0.7392\u001b[0m\n",
      "\u001b[34mEpoch 1/10 |  val  |  Loss: 0.6456 Acc: 0.7654\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.3486 || 10iter: 0.8952 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.3750 || 10iter: 0.8940 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.4691 || 10iter: 0.8928 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.4672 || 10iter: 0.8924 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mEpoch 2/10 | train |  Loss: 0.4587 Acc: 0.8272\u001b[0m\n",
      "\u001b[34mEpoch 2/10 |  val  |  Loss: 0.7230 Acc: 0.7160\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.3138 || 10iter: 0.8973 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.3622 || 10iter: 0.8961 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.5124 || 10iter: 0.8925 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.4522 || 10iter: 0.8948 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mEpoch 3/10 | train |  Loss: 0.4292 Acc: 0.8395\u001b[0m\n",
      "\u001b[34mEpoch 3/10 |  val  |  Loss: 0.6206 Acc: 0.7840\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.2640 || 10iter: 0.8950 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.4318 || 10iter: 0.8935 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.2363 || 10iter: 0.8929 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.4527 || 10iter: 0.8907 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mEpoch 4/10 | train |  Loss: 0.4137 Acc: 0.8395\u001b[0m\n",
      "\u001b[34mEpoch 4/10 |  val  |  Loss: 0.6294 Acc: 0.7870\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.3977 || 10iter: 0.8929 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.2230 || 10iter: 0.8933 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.5569 || 10iter: 0.8929 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.3027 || 10iter: 0.8923 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mEpoch 5/10 | train |  Loss: 0.3905 Acc: 0.8418\u001b[0m\n",
      "\u001b[34mEpoch 5/10 |  val  |  Loss: 0.6183 Acc: 0.7901\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.3031 || 10iter: 0.8942 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.2421 || 10iter: 0.8911 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.3770 || 10iter: 0.8946 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.4056 || 10iter: 0.8929 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mEpoch 6/10 | train |  Loss: 0.3807 Acc: 0.8488\u001b[0m\n",
      "\u001b[34mEpoch 6/10 |  val  |  Loss: 0.6765 Acc: 0.7623\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.4184 || 10iter: 0.8962 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.5049 || 10iter: 0.8939 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1967 || 10iter: 0.8928 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.5683 || 10iter: 0.8913 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mEpoch 7/10 | train |  Loss: 0.3474 Acc: 0.8665\u001b[0m\n",
      "\u001b[34mEpoch 7/10 |  val  |  Loss: 0.7423 Acc: 0.7531\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.5918 || 10iter: 0.8985 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.3332 || 10iter: 0.8925 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.4349 || 10iter: 0.8925 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.4238 || 10iter: 0.8918 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mEpoch 8/10 | train |  Loss: 0.3548 Acc: 0.8611\u001b[0m\n",
      "\u001b[34mEpoch 8/10 |  val  |  Loss: 0.6725 Acc: 0.8025\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.3237 || 10iter: 0.8960 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.2475 || 10iter: 0.8951 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.2274 || 10iter: 0.9007 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.5170 || 10iter: 0.9035 sec. || Accuracy: 0.65625\u001b[0m\n",
      "\u001b[34mEpoch 9/10 | train |  Loss: 0.3050 Acc: 0.8781\u001b[0m\n",
      "\u001b[34mEpoch 9/10 |  val  |  Loss: 0.6554 Acc: 0.8056\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.4145 || 10iter: 0.8974 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.2014 || 10iter: 0.8955 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.2900 || 10iter: 0.8914 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.2648 || 10iter: 0.8922 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mEpoch 10/10 | train |  Loss: 0.3109 Acc: 0.8873\u001b[0m\n",
      "\u001b[34mEpoch 10/10 |  val  |  Loss: 0.7354 Acc: 0.7809\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/17 [00:00<?, ?it/s]#015 12%|█▏        | 2/17 [00:00<00:01, 12.38it/s]#015 24%|██▎       | 4/17 [00:00<00:01, 12.37it/s]#015 35%|███▌      | 6/17 [00:00<00:00, 12.34it/s]#015 47%|████▋     | 8/17 [00:00<00:00, 12.33it/s]#015 59%|█████▉    | 10/17 [00:00<00:00, 12.29it/s]#015 71%|███████   | 12/17 [00:00<00:00, 12.30it/s]#015 82%|████████▏ | 14/17 [00:01<00:00, 12.30it/s]#015 94%|█████████▍| 16/17 [00:01<00:00, 12.28it/s]#015100%|██████████| 17/17 [00:01<00:00, 12.34it/s]\u001b[0m\n",
      "\u001b[34mTest Data 542 Accuracy: 0.8413\u001b[0m\n",
      "\u001b[34mRecall                      0.8413\u001b[0m\n",
      "\u001b[34mPrecision                   0.8497\u001b[0m\n",
      "\u001b[34mF1                          0.8419\u001b[0m\n",
      "\u001b[34mKappa                       0.7579\u001b[0m\n",
      "\u001b[34mQuadratic Weighted Kappa    0.7808\u001b[0m\n",
      "\u001b[34mdtype: float64\u001b[0m\n",
      "\u001b[34mConfusion Matrix:\n",
      "     0    1    2\u001b[0m\n",
      "\u001b[34m0  194   26   19\u001b[0m\n",
      "\u001b[34m1   14  145   19\u001b[0m\n",
      "\u001b[34m2    4    4  117\u001b[0m\n",
      "\u001b[34m----------------\u001b[0m\n",
      "\u001b[34mALL DATA (Macro Average):\n",
      "         Recall  Precision        F1     Kappa  Quadratic Weighted Kappa\u001b[0m\n",
      "\u001b[34mcount  4.000000   4.000000  4.000000  4.000000                  4.000000\u001b[0m\n",
      "\u001b[34mmean   0.772850   0.787125  0.772875  0.655350                  0.703075\u001b[0m\n",
      "\u001b[34mstd    0.076382   0.068319  0.076698  0.113235                  0.106954\u001b[0m\n",
      "\u001b[34mmin    0.674100   0.700800  0.674700  0.511200                  0.566600\u001b[0m\n",
      "\u001b[34m25%    0.732450   0.748725  0.731100  0.592800                  0.643775\u001b[0m\n",
      "\u001b[34m50%    0.788000   0.799000  0.787450  0.676150                  0.725150\u001b[0m\n",
      "\u001b[34m75%    0.828400   0.837400  0.829225  0.738700                  0.784450\u001b[0m\n",
      "\u001b[34mmax    0.841300   0.849700  0.841900  0.757900                  0.795400\u001b[0m\n",
      "\u001b[34m----------------\u001b[0m\n",
      "\u001b[34mALL DATA (Micro Average):\u001b[0m\n",
      "\u001b[34mRecall                      0.7729\u001b[0m\n",
      "\u001b[34mPrecision                   0.7861\u001b[0m\n",
      "\u001b[34mF1                          0.7732\u001b[0m\n",
      "\u001b[34mKappa                       0.6556\u001b[0m\n",
      "\u001b[34mQuadratic Weighted Kappa    0.7033\u001b[0m\n",
      "\u001b[34mdtype: float64\u001b[0m\n",
      "\u001b[34mConfusion Matrix:\n",
      "     0    1    2\u001b[0m\n",
      "\u001b[34m0  648  188   84\u001b[0m\n",
      "\u001b[34m1   72  592   83\u001b[0m\n",
      "\u001b[34m2   19   45  431\u001b[0m\n",
      "\u001b[34mTraining complete.\u001b[0m\n",
      "\n",
      "2021-08-17 02:44:30 Uploading - Uploading generated training model\n",
      "2021-08-17 02:47:30 Completed - Training job completed\n",
      "Training seconds: 640\n",
      "Billable seconds: 640\n"
     ]
    }
   ],
   "source": [
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "\n",
    "# Makoto.Sano@Mack-the-Psych.com\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/sagemaker-vdok3-bert-cv-def-wo-dknr:latest'.format(account, region)\n",
    "vdok3bert = sage.estimator.Estimator(image,\n",
    "                       role, 1, 'ml.p3.2xlarge',\n",
    "                       output_path=\"s3://{}/output\".format(sess.default_bucket()),\n",
    "                       sagemaker_session=sess)\n",
    "vdok3bert.fit(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "predictor = vdok3bert.deploy(1, 'ml.p3.2xlarge', serializer=csv_serializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score_Class,Definition-Score\n",
      "1,0\n",
      "1,1\n",
      "1,1\n",
      "2,2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_in = pd.read_csv('data/Head4-Serialized-Def-ELVA.PILOT.POST-TEST.csv')\n",
    "np_in = np.vstack((np.array(df_in.columns), df_in.to_numpy()))\n",
    "print(predictor.predict(np_in).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "sess.delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_output_folder = \"batch-transform-output\"\n",
    "output_path=\"s3://{}/{}\".format(sess.default_bucket(), transform_output_folder)\n",
    "\n",
    "transformer = vdok3bert.transformer(instance_count=1,\n",
    "                               instance_type='ml.p3.2xlarge',\n",
    "                               output_path=output_path,\n",
    "                               assemble_with='Line',\n",
    "                               accept='text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................\u001b[34mStarting the inference server with 8 workers.\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:04:36 +0000] [41] [INFO] Starting gunicorn 20.1.0\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:04:36 +0000] [41] [INFO] Listening at: unix:/tmp/gunicorn.sock (41)\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:04:36 +0000] [41] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:04:36 +0000] [45] [INFO] Booting worker with pid: 45\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:04:36 +0000] [46] [INFO] Booting worker with pid: 46\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:04:36 +0000] [54] [INFO] Booting worker with pid: 54\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:04:36 +0000] [55] [INFO] Booting worker with pid: 55\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:04:36 +0000] [56] [INFO] Booting worker with pid: 56\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:04:36 +0000] [57] [INFO] Booting worker with pid: 57\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:04:36 +0000] [65] [INFO] Booting worker with pid: 65\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:04:37 +0000] [87] [INFO] Booting worker with pid: 87\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34mbert.embeddings.word_embeddings.weight→embeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.position_embeddings.weight→embeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.token_type_embeddings.weight→embeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.gamma→embeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.beta→embeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.weight→encoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.bias→encoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.weight→encoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.bias→encoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.weight→encoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.bias→encoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.weight→encoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.bias→encoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.gamma→encoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.beta→encoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.weight→encoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.bias→encoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.weight→encoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.bias→encoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.gamma→encoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.beta→encoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.weight→encoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.bias→encoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.weight→encoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.bias→encoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.weight→encoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.bias→encoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.weight→encoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.bias→encoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.gamma→encoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.beta→encoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.weight→encoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.bias→encoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.weight→encoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.bias→encoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.gamma→encoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.beta→encoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.weight→encoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.bias→encoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.weight→encoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.bias→encoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.weight→encoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.bias→encoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.weight→encoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.bias→encoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.gamma→encoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.beta→encoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.weight→encoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.bias→encoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.weight→encoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.bias→encoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.gamma→encoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.beta→encoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.weight→encoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.bias→encoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.weight→encoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.bias→encoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.weight→encoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.bias→encoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.weight→encoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.bias→encoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.gamma→encoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.beta→encoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.weight→encoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.bias→encoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.weight→encoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.bias→encoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.gamma→encoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.beta→encoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.weight→encoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.bias→encoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.weight→encoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.bias→encoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.weight→encoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.bias→encoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.weight→encoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.bias→encoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.gamma→encoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.beta→encoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.weight→encoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.bias→encoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.weight→encoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.bias→encoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.gamma→encoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.beta→encoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.weight→encoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.bias→encoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.weight→encoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.bias→encoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.weight→encoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.bias→encoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.weight→encoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.bias→encoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.gamma→encoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.beta→encoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.weight→encoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.bias→encoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.weight→encoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.bias→encoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.gamma→encoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.beta→encoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.weight→encoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.bias→encoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.weight→encoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.bias→encoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.weight→encoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.bias→encoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.weight→encoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.bias→encoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.gamma→encoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.beta→encoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.weight→encoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.bias→encoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.weight→encoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.bias→encoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.gamma→encoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.beta→encoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.weight→encoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.bias→encoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.weight→encoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.bias→encoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.weight→encoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.bias→encoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.weight→encoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.bias→encoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.gamma→encoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.beta→encoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.weight→encoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.bias→encoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.weight→encoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.bias→encoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.gamma→encoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.beta→encoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.weight→encoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.bias→encoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.weight→encoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.bias→encoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.weight→encoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.bias→encoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.weight→encoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.bias→encoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.gamma→encoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.beta→encoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.weight→encoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.bias→encoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.weight→encoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.bias→encoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.gamma→encoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.beta→encoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.weight→encoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.bias→encoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.weight→encoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.bias→encoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.weight→encoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.bias→encoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.weight→encoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.bias→encoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.gamma→encoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.beta→encoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.weight→encoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.bias→encoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.weight→encoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.bias→encoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.gamma→encoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.beta→encoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.weight→encoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.bias→encoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.weight→encoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.bias→encoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.weight→encoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.bias→encoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.weight→encoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.bias→encoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.gamma→encoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.beta→encoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.weight→encoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.bias→encoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.weight→encoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.bias→encoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.gamma→encoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.beta→encoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.weight→encoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.bias→encoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.weight→encoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.bias→encoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.weight→encoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.bias→encoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.weight→encoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.bias→encoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.gamma→encoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.beta→encoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.weight→encoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.bias→encoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.weight→encoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.bias→encoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.gamma→encoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.beta→encoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.weight→pooler.dense.weight\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.bias→pooler.dense.bias\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Aug/2021:03:04:56 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Aug/2021:03:04:56 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 4 records\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [17/Aug/2021:03:04:56 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [17/Aug/2021:03:04:56 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 4 records\u001b[0m\n",
      "\u001b[34mbert.embeddings.word_embeddings.weight→embeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.position_embeddings.weight→embeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.token_type_embeddings.weight→embeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.gamma→embeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.beta→embeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.weight→encoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.bias→encoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.weight→encoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.bias→encoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.weight→encoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.bias→encoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.weight→encoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.bias→encoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.gamma→encoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.beta→encoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.weight→encoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.bias→encoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.weight→encoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.bias→encoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.gamma→encoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.beta→encoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.weight→encoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.bias→encoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.weight→encoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.bias→encoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.embeddings.word_embeddings.weight→embeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[35mbert.embeddings.position_embeddings.weight→embeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[35mbert.embeddings.token_type_embeddings.weight→embeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[35mbert.embeddings.LayerNorm.gamma→embeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.embeddings.LayerNorm.beta→embeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.query.weight→encoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.query.bias→encoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.key.weight→encoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.key.bias→encoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.value.weight→encoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.value.bias→encoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.dense.weight→encoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.dense.bias→encoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.LayerNorm.gamma→encoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.LayerNorm.beta→encoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.intermediate.dense.weight→encoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.intermediate.dense.bias→encoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.dense.weight→encoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.dense.bias→encoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.LayerNorm.gamma→encoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.LayerNorm.beta→encoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.query.weight→encoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.query.bias→encoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.key.weight→encoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.key.bias→encoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.weight→encoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.bias→encoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.weight→encoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.bias→encoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.gamma→encoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.beta→encoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.weight→encoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.bias→encoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.weight→encoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.bias→encoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.gamma→encoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.beta→encoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.weight→encoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.bias→encoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.weight→encoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.bias→encoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.weight→encoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.bias→encoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.weight→encoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.bias→encoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.gamma→encoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.beta→encoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.weight→encoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.bias→encoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.weight→encoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.bias→encoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.gamma→encoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.beta→encoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.weight→encoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.bias→encoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.weight→encoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.bias→encoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.weight→encoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.bias→encoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.weight→encoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.value.weight→encoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.value.bias→encoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.dense.weight→encoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.dense.bias→encoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.LayerNorm.gamma→encoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.LayerNorm.beta→encoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.intermediate.dense.weight→encoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.intermediate.dense.bias→encoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.dense.weight→encoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.dense.bias→encoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.LayerNorm.gamma→encoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.LayerNorm.beta→encoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.query.weight→encoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.query.bias→encoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.key.weight→encoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.key.bias→encoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.value.weight→encoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.value.bias→encoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.dense.weight→encoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.dense.bias→encoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.LayerNorm.gamma→encoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.LayerNorm.beta→encoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.intermediate.dense.weight→encoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.intermediate.dense.bias→encoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.dense.weight→encoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.dense.bias→encoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.LayerNorm.gamma→encoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.LayerNorm.beta→encoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.query.weight→encoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.query.bias→encoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.key.weight→encoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.key.bias→encoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.value.weight→encoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.value.bias→encoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.dense.weight→encoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.bias→encoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.gamma→encoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.beta→encoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.weight→encoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.bias→encoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.weight→encoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.bias→encoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.gamma→encoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.beta→encoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.weight→encoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.bias→encoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.weight→encoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.bias→encoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.weight→encoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.bias→encoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.weight→encoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.bias→encoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.gamma→encoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.beta→encoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.weight→encoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.bias→encoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.weight→encoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.bias→encoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.gamma→encoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.beta→encoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.weight→encoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.bias→encoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.weight→encoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.bias→encoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.weight→encoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.bias→encoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.weight→encoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.bias→encoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.gamma→encoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.beta→encoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.weight→encoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.dense.bias→encoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.LayerNorm.gamma→encoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.LayerNorm.beta→encoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.intermediate.dense.weight→encoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.intermediate.dense.bias→encoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.dense.weight→encoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.dense.bias→encoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.LayerNorm.gamma→encoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.LayerNorm.beta→encoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.query.weight→encoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.query.bias→encoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.key.weight→encoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.key.bias→encoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.value.weight→encoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.value.bias→encoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.dense.weight→encoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.dense.bias→encoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.LayerNorm.gamma→encoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.LayerNorm.beta→encoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.intermediate.dense.weight→encoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.intermediate.dense.bias→encoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.dense.weight→encoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.dense.bias→encoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.LayerNorm.gamma→encoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.LayerNorm.beta→encoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.query.weight→encoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.query.bias→encoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.key.weight→encoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.key.bias→encoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.value.weight→encoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.value.bias→encoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.dense.weight→encoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.dense.bias→encoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.LayerNorm.gamma→encoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.LayerNorm.beta→encoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.intermediate.dense.weight→encoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.bias→encoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.weight→encoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.bias→encoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.gamma→encoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.beta→encoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.weight→encoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.bias→encoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.weight→encoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.bias→encoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.weight→encoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.bias→encoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.weight→encoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.bias→encoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.gamma→encoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.beta→encoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.weight→encoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.bias→encoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.weight→encoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.bias→encoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.gamma→encoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.beta→encoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.weight→encoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.bias→encoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.weight→encoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.bias→encoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.weight→encoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.bias→encoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.weight→encoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.bias→encoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.gamma→encoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.beta→encoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.intermediate.dense.bias→encoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.dense.weight→encoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.dense.bias→encoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.LayerNorm.gamma→encoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.LayerNorm.beta→encoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.query.weight→encoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.query.bias→encoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.key.weight→encoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.key.bias→encoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.value.weight→encoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.value.bias→encoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.dense.weight→encoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.dense.bias→encoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.LayerNorm.gamma→encoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.LayerNorm.beta→encoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.intermediate.dense.weight→encoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.intermediate.dense.bias→encoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.dense.weight→encoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.dense.bias→encoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.LayerNorm.gamma→encoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.LayerNorm.beta→encoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.query.weight→encoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.query.bias→encoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.key.weight→encoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.key.bias→encoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.value.weight→encoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.value.bias→encoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.dense.weight→encoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.dense.bias→encoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.LayerNorm.gamma→encoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.LayerNorm.beta→encoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.weight→encoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.bias→encoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.weight→encoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.bias→encoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.gamma→encoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.beta→encoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.weight→encoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.bias→encoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.weight→encoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.bias→encoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.weight→encoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.bias→encoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.weight→encoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.bias→encoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.gamma→encoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.beta→encoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.weight→encoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.bias→encoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.weight→encoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.bias→encoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.gamma→encoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.beta→encoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.weight→encoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.bias→encoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.weight→encoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.bias→encoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.weight→encoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.bias→encoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.weight→encoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.bias→encoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.gamma→encoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.beta→encoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.weight→encoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.bias→encoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.intermediate.dense.weight→encoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.intermediate.dense.bias→encoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.dense.weight→encoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.dense.bias→encoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.LayerNorm.gamma→encoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.LayerNorm.beta→encoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.query.weight→encoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.query.bias→encoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.key.weight→encoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.key.bias→encoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.value.weight→encoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.value.bias→encoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.dense.weight→encoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.dense.bias→encoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.LayerNorm.gamma→encoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.LayerNorm.beta→encoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.intermediate.dense.weight→encoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.intermediate.dense.bias→encoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.dense.weight→encoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.dense.bias→encoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.LayerNorm.gamma→encoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.LayerNorm.beta→encoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.query.weight→encoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.query.bias→encoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.key.weight→encoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.key.bias→encoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.value.weight→encoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.value.bias→encoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.dense.weight→encoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.dense.bias→encoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.LayerNorm.gamma→encoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.LayerNorm.beta→encoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.intermediate.dense.weight→encoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.intermediate.dense.bias→encoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.weight→encoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.bias→encoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.gamma→encoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.beta→encoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.weight→encoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.bias→encoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.weight→encoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.bias→encoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.weight→encoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.bias→encoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.weight→encoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.bias→encoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.gamma→encoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.beta→encoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.weight→encoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.bias→encoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.weight→encoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.bias→encoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.gamma→encoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.beta→encoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.weight→encoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.bias→encoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.weight→encoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.bias→encoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.weight→encoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.bias→encoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.weight→encoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.bias→encoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.gamma→encoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.beta→encoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.weight→encoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.bias→encoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.weight→encoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.bias→encoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.gamma→encoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.dense.weight→encoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.dense.bias→encoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.LayerNorm.gamma→encoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.LayerNorm.beta→encoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.query.weight→encoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.query.bias→encoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.key.weight→encoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.key.bias→encoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.value.weight→encoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.value.bias→encoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.dense.weight→encoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.dense.bias→encoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.LayerNorm.gamma→encoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.LayerNorm.beta→encoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.intermediate.dense.weight→encoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.intermediate.dense.bias→encoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.dense.weight→encoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.dense.bias→encoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.LayerNorm.gamma→encoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.LayerNorm.beta→encoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.query.weight→encoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.query.bias→encoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.key.weight→encoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.key.bias→encoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.value.weight→encoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.value.bias→encoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.dense.weight→encoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.dense.bias→encoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.LayerNorm.gamma→encoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.LayerNorm.beta→encoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.intermediate.dense.weight→encoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.intermediate.dense.bias→encoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.dense.weight→encoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.dense.bias→encoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.LayerNorm.gamma→encoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.beta→encoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.weight→pooler.dense.weight\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.bias→pooler.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.LayerNorm.beta→encoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.pooler.dense.weight→pooler.dense.weight\u001b[0m\n",
      "\u001b[35mbert.pooler.dense.bias→pooler.dense.bias\u001b[0m\n",
      "\u001b[32m2021-08-17T03:04:56.125:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/1 [00:00<?, ?it/s]#015100%|██████████| 1/1 [00:00<00:00, 35.55it/s]\u001b[0m\n",
      "\u001b[34mTest Data 4 Accuracy: 0.7500\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Aug/2021:03:05:06 +0000] \"POST /invocations HTTP/1.1\" 200 45 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m#015  0%|          | 0/1 [00:00<?, ?it/s]#015100%|██████████| 1/1 [00:00<00:00, 35.55it/s]\u001b[0m\n",
      "\u001b[35mTest Data 4 Accuracy: 0.7500\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [17/Aug/2021:03:05:06 +0000] \"POST /invocations HTTP/1.1\" 200 45 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\n",
      "\u001b[34mStarting the inference server with 8 workers.\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:04:36 +0000] [41] [INFO] Starting gunicorn 20.1.0\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:04:36 +0000] [41] [INFO] Listening at: unix:/tmp/gunicorn.sock (41)\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:04:36 +0000] [41] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:04:36 +0000] [45] [INFO] Booting worker with pid: 45\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:04:36 +0000] [46] [INFO] Booting worker with pid: 46\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:04:36 +0000] [54] [INFO] Booting worker with pid: 54\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:04:36 +0000] [55] [INFO] Booting worker with pid: 55\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:04:36 +0000] [56] [INFO] Booting worker with pid: 56\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:04:36 +0000] [57] [INFO] Booting worker with pid: 57\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:04:36 +0000] [65] [INFO] Booting worker with pid: 65\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:04:37 +0000] [87] [INFO] Booting worker with pid: 87\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35mStarting the inference server with 8 workers.\u001b[0m\n",
      "\u001b[35m[2021-08-17 03:04:36 +0000] [41] [INFO] Starting gunicorn 20.1.0\u001b[0m\n",
      "\u001b[35m[2021-08-17 03:04:36 +0000] [41] [INFO] Listening at: unix:/tmp/gunicorn.sock (41)\u001b[0m\n",
      "\u001b[35m[2021-08-17 03:04:36 +0000] [41] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2021-08-17 03:04:36 +0000] [45] [INFO] Booting worker with pid: 45\u001b[0m\n",
      "\u001b[35m[2021-08-17 03:04:36 +0000] [46] [INFO] Booting worker with pid: 46\u001b[0m\n",
      "\u001b[35m[2021-08-17 03:04:36 +0000] [54] [INFO] Booting worker with pid: 54\u001b[0m\n",
      "\u001b[35m[2021-08-17 03:04:36 +0000] [55] [INFO] Booting worker with pid: 55\u001b[0m\n",
      "\u001b[35m[2021-08-17 03:04:36 +0000] [56] [INFO] Booting worker with pid: 56\u001b[0m\n",
      "\u001b[35m[2021-08-17 03:04:36 +0000] [57] [INFO] Booting worker with pid: 57\u001b[0m\n",
      "\u001b[35m[2021-08-17 03:04:36 +0000] [65] [INFO] Booting worker with pid: 65\u001b[0m\n",
      "\u001b[35m[2021-08-17 03:04:37 +0000] [87] [INFO] Booting worker with pid: 87\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34mbert.embeddings.word_embeddings.weight→embeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.position_embeddings.weight→embeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.token_type_embeddings.weight→embeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.gamma→embeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.beta→embeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.weight→encoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.bias→encoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.weight→encoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.bias→encoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.weight→encoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.bias→encoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.weight→encoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.bias→encoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.gamma→encoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.beta→encoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.weight→encoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.bias→encoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.weight→encoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.bias→encoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.gamma→encoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.embeddings.word_embeddings.weight→embeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[35mbert.embeddings.position_embeddings.weight→embeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[35mbert.embeddings.token_type_embeddings.weight→embeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[35mbert.embeddings.LayerNorm.gamma→embeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.embeddings.LayerNorm.beta→embeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.query.weight→encoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.query.bias→encoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.key.weight→encoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.key.bias→encoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.value.weight→encoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.value.bias→encoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.dense.weight→encoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.dense.bias→encoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.LayerNorm.gamma→encoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.LayerNorm.beta→encoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.intermediate.dense.weight→encoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.intermediate.dense.bias→encoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.dense.weight→encoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.dense.bias→encoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.LayerNorm.gamma→encoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.beta→encoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.weight→encoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.bias→encoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.weight→encoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.bias→encoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.weight→encoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.bias→encoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.weight→encoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.bias→encoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.gamma→encoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.beta→encoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.weight→encoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.bias→encoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.weight→encoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.bias→encoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.gamma→encoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.beta→encoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.weight→encoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.bias→encoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.weight→encoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.bias→encoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.weight→encoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.bias→encoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.weight→encoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.LayerNorm.beta→encoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.query.weight→encoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.query.bias→encoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.key.weight→encoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.key.bias→encoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.value.weight→encoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.value.bias→encoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.dense.weight→encoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.dense.bias→encoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.LayerNorm.gamma→encoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.LayerNorm.beta→encoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.intermediate.dense.weight→encoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.intermediate.dense.bias→encoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.dense.weight→encoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.dense.bias→encoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.LayerNorm.gamma→encoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.LayerNorm.beta→encoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.query.weight→encoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.query.bias→encoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.key.weight→encoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.key.bias→encoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.value.weight→encoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.value.bias→encoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.dense.weight→encoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.bias→encoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.gamma→encoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.beta→encoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.weight→encoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.bias→encoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.weight→encoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.bias→encoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.gamma→encoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.beta→encoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.weight→encoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.bias→encoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.weight→encoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.bias→encoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.weight→encoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.bias→encoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.weight→encoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.bias→encoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.gamma→encoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.beta→encoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.weight→encoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.bias→encoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.weight→encoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.bias→encoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.gamma→encoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.beta→encoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.weight→encoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.bias→encoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.dense.bias→encoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.LayerNorm.gamma→encoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.LayerNorm.beta→encoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.intermediate.dense.weight→encoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.intermediate.dense.bias→encoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.dense.weight→encoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.dense.bias→encoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.LayerNorm.gamma→encoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.LayerNorm.beta→encoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.query.weight→encoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.query.bias→encoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.key.weight→encoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.key.bias→encoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.value.weight→encoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.value.bias→encoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.dense.weight→encoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.dense.bias→encoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.LayerNorm.gamma→encoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.LayerNorm.beta→encoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.intermediate.dense.weight→encoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.intermediate.dense.bias→encoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.dense.weight→encoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.dense.bias→encoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.LayerNorm.gamma→encoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.LayerNorm.beta→encoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.query.weight→encoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.query.bias→encoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.weight→encoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.bias→encoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.weight→encoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.bias→encoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.weight→encoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.bias→encoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.gamma→encoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.beta→encoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.weight→encoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.bias→encoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.weight→encoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.bias→encoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.gamma→encoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.beta→encoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.weight→encoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.bias→encoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.weight→encoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.bias→encoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.weight→encoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.bias→encoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.weight→encoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.bias→encoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.gamma→encoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.beta→encoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.weight→encoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.bias→encoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.weight→encoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.bias→encoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.gamma→encoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.beta→encoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.weight→encoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.bias→encoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.weight→encoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.bias→encoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.key.weight→encoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.key.bias→encoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.value.weight→encoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.value.bias→encoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.dense.weight→encoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.dense.bias→encoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.LayerNorm.gamma→encoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.LayerNorm.beta→encoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.intermediate.dense.weight→encoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.intermediate.dense.bias→encoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.dense.weight→encoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.dense.bias→encoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.LayerNorm.gamma→encoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.LayerNorm.beta→encoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.query.weight→encoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.query.bias→encoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.key.weight→encoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.key.bias→encoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.value.weight→encoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.value.bias→encoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.dense.weight→encoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.dense.bias→encoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.LayerNorm.gamma→encoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.LayerNorm.beta→encoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.intermediate.dense.weight→encoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.intermediate.dense.bias→encoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.dense.weight→encoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.dense.bias→encoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.LayerNorm.gamma→encoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.LayerNorm.beta→encoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.query.weight→encoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.query.bias→encoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.key.weight→encoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.key.bias→encoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.weight→encoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.bias→encoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.weight→encoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.bias→encoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.gamma→encoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.beta→encoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.weight→encoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.bias→encoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.weight→encoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.bias→encoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.gamma→encoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.beta→encoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.weight→encoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.bias→encoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.weight→encoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.bias→encoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.weight→encoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.bias→encoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.weight→encoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.bias→encoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.gamma→encoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.beta→encoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.weight→encoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.bias→encoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.weight→encoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.bias→encoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.gamma→encoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.value.weight→encoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.value.bias→encoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.dense.weight→encoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.dense.bias→encoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.LayerNorm.gamma→encoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.LayerNorm.beta→encoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.intermediate.dense.weight→encoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.intermediate.dense.bias→encoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.dense.weight→encoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.dense.bias→encoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.LayerNorm.gamma→encoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.LayerNorm.beta→encoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.query.weight→encoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.query.bias→encoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.key.weight→encoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.key.bias→encoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.value.weight→encoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.value.bias→encoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.dense.weight→encoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.dense.bias→encoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.LayerNorm.gamma→encoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.LayerNorm.beta→encoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.intermediate.dense.weight→encoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.intermediate.dense.bias→encoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.dense.weight→encoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.dense.bias→encoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.LayerNorm.gamma→encoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.beta→encoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.weight→encoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.bias→encoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.weight→encoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.bias→encoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.weight→encoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.bias→encoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.weight→encoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.bias→encoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.gamma→encoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.beta→encoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.weight→encoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.bias→encoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.weight→encoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.bias→encoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.gamma→encoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.beta→encoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.weight→encoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.bias→encoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.weight→encoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.bias→encoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.weight→encoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.bias→encoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.weight→encoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.bias→encoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.gamma→encoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.beta→encoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.weight→encoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.bias→encoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.weight→encoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.bias→encoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.gamma→encoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.beta→encoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.weight→encoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.bias→encoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.LayerNorm.beta→encoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.query.weight→encoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.query.bias→encoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.key.weight→encoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.key.bias→encoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.value.weight→encoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.value.bias→encoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.dense.weight→encoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.dense.bias→encoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.LayerNorm.gamma→encoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.LayerNorm.beta→encoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.intermediate.dense.weight→encoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.intermediate.dense.bias→encoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.dense.weight→encoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.dense.bias→encoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.LayerNorm.gamma→encoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.LayerNorm.beta→encoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.query.weight→encoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.query.bias→encoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.key.weight→encoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.key.bias→encoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.value.weight→encoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.value.bias→encoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.dense.weight→encoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.dense.bias→encoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.LayerNorm.gamma→encoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.LayerNorm.beta→encoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.intermediate.dense.weight→encoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.intermediate.dense.bias→encoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.dense.weight→encoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.dense.bias→encoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.LayerNorm.gamma→encoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.LayerNorm.beta→encoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.query.weight→encoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.query.bias→encoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.weight→encoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.bias→encoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.weight→encoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.bias→encoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.weight→encoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.bias→encoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.gamma→encoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.beta→encoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.weight→encoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.bias→encoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.weight→encoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.bias→encoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.gamma→encoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.beta→encoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.weight→encoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.bias→encoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.weight→encoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.bias→encoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.weight→encoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.bias→encoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.weight→encoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.bias→encoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.gamma→encoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.beta→encoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.weight→encoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.bias→encoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.weight→encoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.bias→encoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.gamma→encoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.beta→encoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.weight→pooler.dense.weight\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.bias→pooler.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.key.weight→encoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.key.bias→encoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.value.weight→encoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.value.bias→encoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.dense.weight→encoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.dense.bias→encoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.LayerNorm.gamma→encoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.LayerNorm.beta→encoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.intermediate.dense.weight→encoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.intermediate.dense.bias→encoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.dense.weight→encoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.dense.bias→encoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.LayerNorm.gamma→encoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.LayerNorm.beta→encoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.query.weight→encoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.query.bias→encoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.key.weight→encoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.key.bias→encoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.value.weight→encoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.value.bias→encoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.dense.weight→encoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.dense.bias→encoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.LayerNorm.gamma→encoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.LayerNorm.beta→encoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.intermediate.dense.weight→encoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.intermediate.dense.bias→encoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.dense.weight→encoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.dense.bias→encoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.LayerNorm.gamma→encoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.LayerNorm.beta→encoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.pooler.dense.weight→pooler.dense.weight\u001b[0m\n",
      "\u001b[35mbert.pooler.dense.bias→pooler.dense.bias\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Aug/2021:03:04:56 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Aug/2021:03:04:56 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 4 records\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [17/Aug/2021:03:04:56 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [17/Aug/2021:03:04:56 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 4 records\u001b[0m\n",
      "\u001b[34mbert.embeddings.word_embeddings.weight→embeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.position_embeddings.weight→embeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.token_type_embeddings.weight→embeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.gamma→embeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.beta→embeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.weight→encoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.bias→encoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.weight→encoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.bias→encoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.weight→encoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.bias→encoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.weight→encoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.bias→encoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.gamma→encoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.beta→encoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.weight→encoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.bias→encoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.weight→encoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.bias→encoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.gamma→encoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.beta→encoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.weight→encoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.bias→encoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.weight→encoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.bias→encoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.embeddings.word_embeddings.weight→embeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[35mbert.embeddings.position_embeddings.weight→embeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[35mbert.embeddings.token_type_embeddings.weight→embeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[35mbert.embeddings.LayerNorm.gamma→embeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.embeddings.LayerNorm.beta→embeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.query.weight→encoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.query.bias→encoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.key.weight→encoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.key.bias→encoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.value.weight→encoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.value.bias→encoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.dense.weight→encoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.dense.bias→encoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.LayerNorm.gamma→encoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.LayerNorm.beta→encoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.intermediate.dense.weight→encoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.intermediate.dense.bias→encoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.dense.weight→encoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.dense.bias→encoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.LayerNorm.gamma→encoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.LayerNorm.beta→encoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.query.weight→encoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.query.bias→encoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.key.weight→encoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.key.bias→encoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.weight→encoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.bias→encoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.weight→encoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.bias→encoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.gamma→encoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.beta→encoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.weight→encoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.bias→encoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.weight→encoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.bias→encoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.gamma→encoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.beta→encoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.weight→encoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.bias→encoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.weight→encoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.bias→encoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.weight→encoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.bias→encoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.weight→encoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.bias→encoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.gamma→encoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.beta→encoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.weight→encoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.bias→encoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.weight→encoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.bias→encoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.gamma→encoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.beta→encoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.weight→encoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.bias→encoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.weight→encoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.bias→encoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.weight→encoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.bias→encoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.weight→encoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.value.weight→encoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.value.bias→encoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.dense.weight→encoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.dense.bias→encoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.LayerNorm.gamma→encoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.LayerNorm.beta→encoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.intermediate.dense.weight→encoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.intermediate.dense.bias→encoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.dense.weight→encoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.dense.bias→encoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.LayerNorm.gamma→encoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.LayerNorm.beta→encoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.query.weight→encoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.query.bias→encoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.key.weight→encoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.key.bias→encoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.value.weight→encoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.value.bias→encoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.dense.weight→encoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.dense.bias→encoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.LayerNorm.gamma→encoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.LayerNorm.beta→encoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.intermediate.dense.weight→encoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.intermediate.dense.bias→encoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.dense.weight→encoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.dense.bias→encoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.LayerNorm.gamma→encoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.LayerNorm.beta→encoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.query.weight→encoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.query.bias→encoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.key.weight→encoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.key.bias→encoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.value.weight→encoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.value.bias→encoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.dense.weight→encoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.bias→encoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.gamma→encoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.beta→encoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.weight→encoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.bias→encoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.weight→encoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.bias→encoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.gamma→encoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.beta→encoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.weight→encoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.bias→encoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.weight→encoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.bias→encoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.weight→encoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.bias→encoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.weight→encoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.bias→encoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.gamma→encoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.beta→encoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.weight→encoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.bias→encoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.weight→encoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.bias→encoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.gamma→encoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.beta→encoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.weight→encoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.bias→encoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.weight→encoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.bias→encoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.weight→encoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.bias→encoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.weight→encoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.bias→encoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.gamma→encoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.beta→encoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.weight→encoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.dense.bias→encoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.LayerNorm.gamma→encoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.LayerNorm.beta→encoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.intermediate.dense.weight→encoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.intermediate.dense.bias→encoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.dense.weight→encoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.dense.bias→encoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.LayerNorm.gamma→encoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.LayerNorm.beta→encoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.query.weight→encoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.query.bias→encoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.key.weight→encoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.key.bias→encoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.value.weight→encoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.value.bias→encoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.dense.weight→encoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.dense.bias→encoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.LayerNorm.gamma→encoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.LayerNorm.beta→encoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.intermediate.dense.weight→encoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.intermediate.dense.bias→encoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.dense.weight→encoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.dense.bias→encoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.LayerNorm.gamma→encoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.LayerNorm.beta→encoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.query.weight→encoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.query.bias→encoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.key.weight→encoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.key.bias→encoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.value.weight→encoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.value.bias→encoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.dense.weight→encoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.dense.bias→encoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.LayerNorm.gamma→encoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.LayerNorm.beta→encoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.intermediate.dense.weight→encoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.bias→encoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.weight→encoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.bias→encoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.gamma→encoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.beta→encoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.weight→encoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.bias→encoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.weight→encoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.bias→encoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.weight→encoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.bias→encoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.weight→encoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.bias→encoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.gamma→encoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.beta→encoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.weight→encoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.bias→encoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.weight→encoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.bias→encoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.gamma→encoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.beta→encoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.weight→encoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.bias→encoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.weight→encoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.bias→encoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.weight→encoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.bias→encoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.weight→encoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.bias→encoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.gamma→encoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.beta→encoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.intermediate.dense.bias→encoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.dense.weight→encoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.dense.bias→encoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.LayerNorm.gamma→encoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.LayerNorm.beta→encoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.query.weight→encoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.query.bias→encoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.key.weight→encoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.key.bias→encoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.value.weight→encoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.value.bias→encoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.dense.weight→encoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.dense.bias→encoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.LayerNorm.gamma→encoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.LayerNorm.beta→encoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.intermediate.dense.weight→encoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.intermediate.dense.bias→encoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.dense.weight→encoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.dense.bias→encoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.LayerNorm.gamma→encoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.LayerNorm.beta→encoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.query.weight→encoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.query.bias→encoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.key.weight→encoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.key.bias→encoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.value.weight→encoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.value.bias→encoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.dense.weight→encoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.dense.bias→encoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.LayerNorm.gamma→encoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.LayerNorm.beta→encoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.weight→encoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.bias→encoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.weight→encoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.bias→encoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.gamma→encoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.beta→encoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.weight→encoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.bias→encoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.weight→encoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.bias→encoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.weight→encoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.bias→encoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.weight→encoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.bias→encoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.gamma→encoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.beta→encoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.weight→encoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.bias→encoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.weight→encoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.bias→encoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.gamma→encoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.beta→encoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.weight→encoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.bias→encoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.weight→encoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.bias→encoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.weight→encoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.bias→encoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.weight→encoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.bias→encoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.gamma→encoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.beta→encoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.weight→encoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.bias→encoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.intermediate.dense.weight→encoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.intermediate.dense.bias→encoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.dense.weight→encoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.dense.bias→encoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.LayerNorm.gamma→encoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.LayerNorm.beta→encoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.query.weight→encoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.query.bias→encoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.key.weight→encoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.key.bias→encoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.value.weight→encoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.value.bias→encoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.dense.weight→encoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.dense.bias→encoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.LayerNorm.gamma→encoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.LayerNorm.beta→encoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.intermediate.dense.weight→encoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.intermediate.dense.bias→encoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.dense.weight→encoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.dense.bias→encoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.LayerNorm.gamma→encoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.LayerNorm.beta→encoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.query.weight→encoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.query.bias→encoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.key.weight→encoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.key.bias→encoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.value.weight→encoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.value.bias→encoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.dense.weight→encoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.dense.bias→encoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.LayerNorm.gamma→encoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.LayerNorm.beta→encoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.intermediate.dense.weight→encoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.intermediate.dense.bias→encoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.weight→encoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.bias→encoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.gamma→encoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.beta→encoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.weight→encoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.bias→encoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.weight→encoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.bias→encoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.weight→encoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.bias→encoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.weight→encoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.bias→encoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.gamma→encoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.beta→encoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.weight→encoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.bias→encoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.weight→encoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.bias→encoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.gamma→encoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.beta→encoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.weight→encoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.bias→encoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.weight→encoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.bias→encoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.weight→encoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.bias→encoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.weight→encoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.bias→encoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.gamma→encoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.beta→encoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.weight→encoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.bias→encoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.weight→encoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.bias→encoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.gamma→encoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.dense.weight→encoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.dense.bias→encoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.LayerNorm.gamma→encoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.LayerNorm.beta→encoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.query.weight→encoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.query.bias→encoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.key.weight→encoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.key.bias→encoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.value.weight→encoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.value.bias→encoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.dense.weight→encoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.dense.bias→encoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.LayerNorm.gamma→encoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.LayerNorm.beta→encoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.intermediate.dense.weight→encoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.intermediate.dense.bias→encoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.dense.weight→encoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.dense.bias→encoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.LayerNorm.gamma→encoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.LayerNorm.beta→encoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.query.weight→encoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.query.bias→encoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.key.weight→encoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.key.bias→encoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.value.weight→encoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.value.bias→encoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.dense.weight→encoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.dense.bias→encoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.LayerNorm.gamma→encoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.LayerNorm.beta→encoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.intermediate.dense.weight→encoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.intermediate.dense.bias→encoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.dense.weight→encoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.dense.bias→encoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.LayerNorm.gamma→encoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.beta→encoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.weight→pooler.dense.weight\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.bias→pooler.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.LayerNorm.beta→encoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.pooler.dense.weight→pooler.dense.weight\u001b[0m\n",
      "\u001b[35mbert.pooler.dense.bias→pooler.dense.bias\u001b[0m\n",
      "\u001b[32m2021-08-17T03:04:56.125:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/1 [00:00<?, ?it/s]#015100%|██████████| 1/1 [00:00<00:00, 35.55it/s]\u001b[0m\n",
      "\u001b[34mTest Data 4 Accuracy: 0.7500\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Aug/2021:03:05:06 +0000] \"POST /invocations HTTP/1.1\" 200 45 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m#015  0%|          | 0/1 [00:00<?, ?it/s]#015100%|██████████| 1/1 [00:00<00:00, 35.55it/s]\u001b[0m\n",
      "\u001b[35mTest Data 4 Accuracy: 0.7500\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [17/Aug/2021:03:05:06 +0000] \"POST /invocations HTTP/1.1\" 200 45 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "Transform results: \n",
      "Score_Class,Definition-Score\n",
      "1,0\n",
      "1,1\n",
      "1,1\n",
      "2,2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformer.transform(data_location + '/Head4-Serialized-Def-ELVA.PILOT.POST-TEST.csv', content_type='text/csv', split_type='Line')\n",
    "transformer.wait()\n",
    "\n",
    "s3_client = sess.boto_session.client('s3')\n",
    "s3_client.download_file(sess.default_bucket(), \"{}/Head4-Serialized-Def-ELVA.PILOT.POST-TEST.csv.out\".format(transform_output_folder), '/tmp/Head4-Serialized-Def-ELVA.PILOT.POST-TEST.csv.out')\n",
    "with open('/tmp/Head4-Serialized-Def-ELVA.PILOT.POST-TEST.csv.out') as f:\n",
    "    results = f.readlines()   \n",
    "print(\"Transform results: \\n{}\".format(''.join(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
