{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Sending build context to Docker daemon  40.45kB\n",
      "Step 1/32 : FROM nvidia/cuda:10.0-cudnn7-devel-ubuntu16.04\n",
      "10.0-cudnn7-devel-ubuntu16.04: Pulling from nvidia/cuda\n",
      "528184910841: Pulling fs layer\n",
      "8a9df81d603d: Pulling fs layer\n",
      "636d9303bf66: Pulling fs layer\n",
      "672b5bdcef61: Pulling fs layer\n",
      "9061ebd9855f: Pulling fs layer\n",
      "4829f3972b02: Pulling fs layer\n",
      "c473884057c7: Pulling fs layer\n",
      "8383fa66049c: Pulling fs layer\n",
      "02a3bdb75881: Pulling fs layer\n",
      "95c482736993: Pulling fs layer\n",
      "4834d61defc0: Pulling fs layer\n",
      "72bd608d1baa: Pulling fs layer\n",
      "6b5a3a075e9d: Pulling fs layer\n",
      "8383fa66049c: Waiting\n",
      "672b5bdcef61: Waiting\n",
      "9061ebd9855f: Waiting\n",
      "4829f3972b02: Waiting\n",
      "02a3bdb75881: Waiting\n",
      "95c482736993: Waiting\n",
      "4834d61defc0: Waiting\n",
      "72bd608d1baa: Waiting\n",
      "c473884057c7: Waiting\n",
      "6b5a3a075e9d: Waiting\n",
      "8a9df81d603d: Verifying Checksum\n",
      "8a9df81d603d: Download complete\n",
      "636d9303bf66: Verifying Checksum\n",
      "636d9303bf66: Download complete\n",
      "672b5bdcef61: Download complete\n",
      "9061ebd9855f: Verifying Checksum\n",
      "9061ebd9855f: Download complete\n",
      "528184910841: Verifying Checksum\n",
      "528184910841: Download complete\n",
      "c473884057c7: Verifying Checksum\n",
      "c473884057c7: Download complete\n",
      "8383fa66049c: Verifying Checksum\n",
      "8383fa66049c: Download complete\n",
      "4829f3972b02: Verifying Checksum\n",
      "4829f3972b02: Download complete\n",
      "95c482736993: Verifying Checksum\n",
      "95c482736993: Download complete\n",
      "72bd608d1baa: Verifying Checksum\n",
      "72bd608d1baa: Download complete\n",
      "528184910841: Pull complete\n",
      "8a9df81d603d: Pull complete\n",
      "02a3bdb75881: Verifying Checksum\n",
      "02a3bdb75881: Download complete\n",
      "6b5a3a075e9d: Verifying Checksum\n",
      "6b5a3a075e9d: Download complete\n",
      "636d9303bf66: Pull complete\n",
      "4834d61defc0: Verifying Checksum\n",
      "4834d61defc0: Download complete\n",
      "672b5bdcef61: Pull complete\n",
      "9061ebd9855f: Pull complete\n",
      "4829f3972b02: Pull complete\n",
      "c473884057c7: Pull complete\n",
      "8383fa66049c: Pull complete\n",
      "02a3bdb75881: Pull complete\n",
      "95c482736993: Pull complete\n",
      "4834d61defc0: Pull complete\n",
      "72bd608d1baa: Pull complete\n",
      "6b5a3a075e9d: Pull complete\n",
      "Digest: sha256:bb8a5af6a85b9d0bcb5c8afbf02ba36578fe30d25c1f99636809191e8e42199c\n",
      "Status: Downloaded newer image for nvidia/cuda:10.0-cudnn7-devel-ubuntu16.04\n",
      " ---> 225b79605de8\n",
      "Step 2/32 : RUN apt-get -y update && apt-get -y upgrade && apt-get install -y --no-install-recommends          curl          git          unzip          bzip2          libgl1-mesa-glx          wget          nginx          ca-certificates     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Running in 7b0f158f485b\n",
      "Get:1 http://security.ubuntu.com/ubuntu xenial-security InRelease [109 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu xenial InRelease [247 kB]\n",
      "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  InRelease\n",
      "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  InRelease\n",
      "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Release [697 B]\n",
      "Get:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  Release [564 B]\n",
      "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Release.gpg [836 B]\n",
      "Get:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  Release.gpg [833 B]\n",
      "Get:9 http://security.ubuntu.com/ubuntu xenial-security/main amd64 Packages [2051 kB]\n",
      "Ign:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Packages\n",
      "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Packages [619 kB]\n",
      "Get:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  Packages [122 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu xenial-updates InRelease [109 kB]\n",
      "Get:13 http://security.ubuntu.com/ubuntu xenial-security/restricted amd64 Packages [15.9 kB]\n",
      "Get:14 http://security.ubuntu.com/ubuntu xenial-security/universe amd64 Packages [984 kB]\n",
      "Get:15 http://security.ubuntu.com/ubuntu xenial-security/multiverse amd64 Packages [8820 B]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu xenial-backports InRelease [107 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu xenial/main amd64 Packages [1558 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu xenial/restricted amd64 Packages [14.1 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu xenial/universe amd64 Packages [9827 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu xenial/multiverse amd64 Packages [176 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 Packages [2560 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu xenial-updates/restricted amd64 Packages [16.4 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu xenial-updates/universe amd64 Packages [1544 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu xenial-updates/multiverse amd64 Packages [26.2 kB]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu xenial-backports/main amd64 Packages [10.9 kB]\n",
      "Get:26 http://archive.ubuntu.com/ubuntu xenial-backports/universe amd64 Packages [12.7 kB]\n",
      "Fetched 20.1 MB in 3s (5443 kB/s)\n",
      "Reading package lists...\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "Calculating upgrade...\n",
      "The following packages have been kept back:\n",
      "  libcudnn7 libcudnn7-dev libnccl-dev libnccl2\n",
      "0 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "bzip2 is already the newest version (1.0.6-8ubuntu0.2).\n",
      "bzip2 set to manually installed.\n",
      "ca-certificates is already the newest version (20210119~16.04.1).\n",
      "The following additional packages will be installed:\n",
      "  fontconfig-config fonts-dejavu-core git-man libbsd0 libdrm-amdgpu1\n",
      "  libdrm-common libdrm-intel1 libdrm-nouveau2 libdrm-radeon1 libdrm2 libedit2\n",
      "  libelf1 liberror-perl libexpat1 libfontconfig1 libfreetype6 libgd3 libgeoip1\n",
      "  libgl1-mesa-dri libglapi-mesa libicu55 libjbig0 libjpeg-turbo8 libjpeg8\n",
      "  libllvm6.0 libpciaccess0 libpng12-0 libsensors4 libtiff5 libvpx3 libx11-6\n",
      "  libx11-data libx11-xcb1 libxau6 libxcb-dri2-0 libxcb-dri3-0 libxcb-glx0\n",
      "  libxcb-present0 libxcb-sync1 libxcb1 libxdamage1 libxdmcp6 libxext6\n",
      "  libxfixes3 libxml2 libxpm4 libxshmfence1 libxslt1.1 libxxf86vm1 nginx-common\n",
      "  nginx-core ucf\n",
      "Suggested packages:\n",
      "  gettext-base git-daemon-run | git-daemon-sysvinit git-doc git-el git-email\n",
      "  git-gui gitk gitweb git-arch git-cvs git-mediawiki git-svn libgd-tools\n",
      "  geoip-bin pciutils lm-sensors fcgiwrap nginx-doc ssl-cert zip\n",
      "Recommended packages:\n",
      "  less rsync ssh-client geoip-database libtxc-dxtn-s2tc | libtxc-dxtn-s2tc0\n",
      "  | libtxc-dxtn0 xml-core\n",
      "The following NEW packages will be installed:\n",
      "  curl fontconfig-config fonts-dejavu-core git git-man libbsd0 libdrm-amdgpu1\n",
      "  libdrm-common libdrm-intel1 libdrm-nouveau2 libdrm-radeon1 libdrm2 libedit2\n",
      "  libelf1 liberror-perl libexpat1 libfontconfig1 libfreetype6 libgd3 libgeoip1\n",
      "  libgl1-mesa-dri libgl1-mesa-glx libglapi-mesa libicu55 libjbig0\n",
      "  libjpeg-turbo8 libjpeg8 libllvm6.0 libpciaccess0 libpng12-0 libsensors4\n",
      "  libtiff5 libvpx3 libx11-6 libx11-data libx11-xcb1 libxau6 libxcb-dri2-0\n",
      "  libxcb-dri3-0 libxcb-glx0 libxcb-present0 libxcb-sync1 libxcb1 libxdamage1\n",
      "  libxdmcp6 libxext6 libxfixes3 libxml2 libxpm4 libxshmfence1 libxslt1.1\n",
      "  libxxf86vm1 nginx nginx-common nginx-core ucf unzip wget\n",
      "0 upgraded, 58 newly installed, 0 to remove and 4 not upgraded.\n",
      "Need to get 38.3 MB of archives.\n",
      "After this operation, 281 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu xenial/main amd64 libxau6 amd64 1:1.0.8-1 [8376 B]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu xenial/main amd64 libxdmcp6 amd64 1:1.1.2-1.1 [11.0 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu xenial/main amd64 libxcb1 amd64 1.11.1-1ubuntu1 [40.0 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libx11-data all 2:1.6.3-1ubuntu2.2 [114 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libx11-6 amd64 2:1.6.3-1ubuntu2.2 [572 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu xenial/main amd64 libxext6 amd64 2:1.3.3-1 [29.4 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libjpeg-turbo8 amd64 1.4.2-0ubuntu3.4 [111 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu xenial/main amd64 libxdamage1 amd64 1:1.1.4-2 [6946 B]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu xenial/main amd64 libxfixes3 amd64 1:5.0.1-2 [11.1 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu xenial/main amd64 libxshmfence1 amd64 1.2-1 [5042 B]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu xenial/main amd64 libxxf86vm1 amd64 1:1.1.4-1 [10.6 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu xenial/main amd64 libjbig0 amd64 2.1-3.1 [26.6 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libbsd0 amd64 0.8.2-1ubuntu0.1 [42.0 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libexpat1 amd64 2.1.0-7ubuntu0.16.04.5 [71.5 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libpng12-0 amd64 1.2.54-1ubuntu1.1 [116 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu xenial/main amd64 ucf all 3.0036 [52.9 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libdrm-common all 2.4.91-2~16.04.1 [4764 B]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libdrm2 amd64 2.4.91-2~16.04.1 [30.8 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu xenial/main amd64 libedit2 amd64 3.1-20150325-1ubuntu2 [76.5 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libelf1 amd64 0.165-3ubuntu1.2 [43.5 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu xenial/main amd64 libgeoip1 amd64 1.6.9-1 [70.1 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libicu55 amd64 55.1-7ubuntu0.5 [7650 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libxml2 amd64 2.9.3+dfsg1-1ubuntu0.7 [698 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 wget amd64 1.17.1-1ubuntu1.5 [299 kB]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 curl amd64 7.47.0-1ubuntu2.19 [139 kB]\n",
      "Get:26 http://archive.ubuntu.com/ubuntu xenial/main amd64 fonts-dejavu-core all 2.35-1 [1039 kB]\n",
      "Get:27 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 fontconfig-config all 2.11.94-0ubuntu1.1 [49.9 kB]\n",
      "Get:28 http://archive.ubuntu.com/ubuntu xenial/main amd64 liberror-perl all 0.17-1.2 [19.6 kB]\n",
      "Get:29 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 git-man all 1:2.7.4-0ubuntu1.10 [737 kB]\n",
      "Get:30 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 git amd64 1:2.7.4-0ubuntu1.10 [3183 kB]\n",
      "Get:31 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libdrm-amdgpu1 amd64 2.4.91-2~16.04.1 [18.9 kB]\n",
      "Get:32 http://archive.ubuntu.com/ubuntu xenial/main amd64 libpciaccess0 amd64 0.13.4-1 [18.1 kB]\n",
      "Get:33 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libdrm-intel1 amd64 2.4.91-2~16.04.1 [59.9 kB]\n",
      "Get:34 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libdrm-nouveau2 amd64 2.4.91-2~16.04.1 [16.3 kB]\n",
      "Get:35 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libdrm-radeon1 amd64 2.4.91-2~16.04.1 [21.5 kB]\n",
      "Get:36 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libfreetype6 amd64 2.6.1-0.1ubuntu2.5 [316 kB]\n",
      "Get:37 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libfontconfig1 amd64 2.11.94-0ubuntu1.1 [131 kB]\n",
      "Get:38 http://archive.ubuntu.com/ubuntu xenial/main amd64 libjpeg8 amd64 8c-2ubuntu8 [2194 B]\n",
      "Get:39 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libtiff5 amd64 4.0.6-1ubuntu0.8 [149 kB]\n",
      "Get:40 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libvpx3 amd64 1.5.0-2ubuntu1.1 [732 kB]\n",
      "Get:41 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libxpm4 amd64 1:3.5.11-1ubuntu0.16.04.1 [33.8 kB]\n",
      "Get:42 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libgd3 amd64 2.1.1-4ubuntu0.16.04.12 [126 kB]\n",
      "Get:43 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libglapi-mesa amd64 18.0.5-0ubuntu0~16.04.1 [23.4 kB]\n",
      "Get:44 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libllvm6.0 amd64 1:6.0-1ubuntu2~16.04.1 [14.3 MB]\n",
      "Get:45 http://archive.ubuntu.com/ubuntu xenial/main amd64 libsensors4 amd64 1:3.4.0-2 [28.4 kB]\n",
      "Get:46 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libgl1-mesa-dri amd64 18.0.5-0ubuntu0~16.04.1 [6080 kB]\n",
      "Get:47 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libx11-xcb1 amd64 2:1.6.3-1ubuntu2.2 [9296 B]\n",
      "Get:48 http://archive.ubuntu.com/ubuntu xenial/main amd64 libxcb-dri2-0 amd64 1.11.1-1ubuntu1 [6882 B]\n",
      "Get:49 http://archive.ubuntu.com/ubuntu xenial/main amd64 libxcb-dri3-0 amd64 1.11.1-1ubuntu1 [5218 B]\n",
      "Get:50 http://archive.ubuntu.com/ubuntu xenial/main amd64 libxcb-glx0 amd64 1.11.1-1ubuntu1 [20.9 kB]\n",
      "Get:51 http://archive.ubuntu.com/ubuntu xenial/main amd64 libxcb-present0 amd64 1.11.1-1ubuntu1 [5218 B]\n",
      "Get:52 http://archive.ubuntu.com/ubuntu xenial/main amd64 libxcb-sync1 amd64 1.11.1-1ubuntu1 [8324 B]\n",
      "Get:53 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libgl1-mesa-glx amd64 18.0.5-0ubuntu0~16.04.1 [132 kB]\n",
      "Get:54 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libxslt1.1 amd64 1.1.28-2.1ubuntu0.3 [146 kB]\n",
      "Get:55 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 nginx-common all 1.10.3-0ubuntu0.16.04.5 [26.9 kB]\n",
      "Get:56 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 nginx-core amd64 1.10.3-0ubuntu0.16.04.5 [429 kB]\n",
      "Get:57 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 nginx all 1.10.3-0ubuntu0.16.04.5 [3494 B]\n",
      "Get:58 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 unzip amd64 6.0-20ubuntu1.1 [162 kB]\n",
      "\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n",
      "\u001b[0mFetched 38.3 MB in 4s (8013 kB/s)\n",
      "Selecting previously unselected package libxau6:amd64.\n",
      "(Reading database ... 11652 files and directories currently installed.)\n",
      "Preparing to unpack .../libxau6_1%3a1.0.8-1_amd64.deb ...\n",
      "Unpacking libxau6:amd64 (1:1.0.8-1) ...\n",
      "Selecting previously unselected package libxdmcp6:amd64.\n",
      "Preparing to unpack .../libxdmcp6_1%3a1.1.2-1.1_amd64.deb ...\n",
      "Unpacking libxdmcp6:amd64 (1:1.1.2-1.1) ...\n",
      "Selecting previously unselected package libxcb1:amd64.\n",
      "Preparing to unpack .../libxcb1_1.11.1-1ubuntu1_amd64.deb ...\n",
      "Unpacking libxcb1:amd64 (1.11.1-1ubuntu1) ...\n",
      "Selecting previously unselected package libx11-data.\n",
      "Preparing to unpack .../libx11-data_2%3a1.6.3-1ubuntu2.2_all.deb ...\n",
      "Unpacking libx11-data (2:1.6.3-1ubuntu2.2) ...\n",
      "Selecting previously unselected package libx11-6:amd64.\n",
      "Preparing to unpack .../libx11-6_2%3a1.6.3-1ubuntu2.2_amd64.deb ...\n",
      "Unpacking libx11-6:amd64 (2:1.6.3-1ubuntu2.2) ...\n",
      "Selecting previously unselected package libxext6:amd64.\n",
      "Preparing to unpack .../libxext6_2%3a1.3.3-1_amd64.deb ...\n",
      "Unpacking libxext6:amd64 (2:1.3.3-1) ...\n",
      "Selecting previously unselected package libjpeg-turbo8:amd64.\n",
      "Preparing to unpack .../libjpeg-turbo8_1.4.2-0ubuntu3.4_amd64.deb ...\n",
      "Unpacking libjpeg-turbo8:amd64 (1.4.2-0ubuntu3.4) ...\n",
      "Selecting previously unselected package libxdamage1:amd64.\n",
      "Preparing to unpack .../libxdamage1_1%3a1.1.4-2_amd64.deb ...\n",
      "Unpacking libxdamage1:amd64 (1:1.1.4-2) ...\n",
      "Selecting previously unselected package libxfixes3:amd64.\n",
      "Preparing to unpack .../libxfixes3_1%3a5.0.1-2_amd64.deb ...\n",
      "Unpacking libxfixes3:amd64 (1:5.0.1-2) ...\n",
      "Selecting previously unselected package libxshmfence1:amd64.\n",
      "Preparing to unpack .../libxshmfence1_1.2-1_amd64.deb ...\n",
      "Unpacking libxshmfence1:amd64 (1.2-1) ...\n",
      "Selecting previously unselected package libxxf86vm1:amd64.\n",
      "Preparing to unpack .../libxxf86vm1_1%3a1.1.4-1_amd64.deb ...\n",
      "Unpacking libxxf86vm1:amd64 (1:1.1.4-1) ...\n",
      "Selecting previously unselected package libjbig0:amd64.\n",
      "Preparing to unpack .../libjbig0_2.1-3.1_amd64.deb ...\n",
      "Unpacking libjbig0:amd64 (2.1-3.1) ...\n",
      "Selecting previously unselected package libbsd0:amd64.\n",
      "Preparing to unpack .../libbsd0_0.8.2-1ubuntu0.1_amd64.deb ...\n",
      "Unpacking libbsd0:amd64 (0.8.2-1ubuntu0.1) ...\n",
      "Selecting previously unselected package libexpat1:amd64.\n",
      "Preparing to unpack .../libexpat1_2.1.0-7ubuntu0.16.04.5_amd64.deb ...\n",
      "Unpacking libexpat1:amd64 (2.1.0-7ubuntu0.16.04.5) ...\n",
      "Selecting previously unselected package libpng12-0:amd64.\n",
      "Preparing to unpack .../libpng12-0_1.2.54-1ubuntu1.1_amd64.deb ...\n",
      "Unpacking libpng12-0:amd64 (1.2.54-1ubuntu1.1) ...\n",
      "Selecting previously unselected package ucf.\n",
      "Preparing to unpack .../archives/ucf_3.0036_all.deb ...\n",
      "Moving old data out of the way\n",
      "Unpacking ucf (3.0036) ...\n",
      "Selecting previously unselected package libdrm-common.\n",
      "Preparing to unpack .../libdrm-common_2.4.91-2~16.04.1_all.deb ...\n",
      "Unpacking libdrm-common (2.4.91-2~16.04.1) ...\n",
      "Selecting previously unselected package libdrm2:amd64.\n",
      "Preparing to unpack .../libdrm2_2.4.91-2~16.04.1_amd64.deb ...\n",
      "Unpacking libdrm2:amd64 (2.4.91-2~16.04.1) ...\n",
      "Selecting previously unselected package libedit2:amd64.\n",
      "Preparing to unpack .../libedit2_3.1-20150325-1ubuntu2_amd64.deb ...\n",
      "Unpacking libedit2:amd64 (3.1-20150325-1ubuntu2) ...\n",
      "Selecting previously unselected package libelf1:amd64.\n",
      "Preparing to unpack .../libelf1_0.165-3ubuntu1.2_amd64.deb ...\n",
      "Unpacking libelf1:amd64 (0.165-3ubuntu1.2) ...\n",
      "Selecting previously unselected package libgeoip1:amd64.\n",
      "Preparing to unpack .../libgeoip1_1.6.9-1_amd64.deb ...\n",
      "Unpacking libgeoip1:amd64 (1.6.9-1) ...\n",
      "Selecting previously unselected package libicu55:amd64.\n",
      "Preparing to unpack .../libicu55_55.1-7ubuntu0.5_amd64.deb ...\n",
      "Unpacking libicu55:amd64 (55.1-7ubuntu0.5) ...\n",
      "Selecting previously unselected package libxml2:amd64.\n",
      "Preparing to unpack .../libxml2_2.9.3+dfsg1-1ubuntu0.7_amd64.deb ...\n",
      "Unpacking libxml2:amd64 (2.9.3+dfsg1-1ubuntu0.7) ...\n",
      "Selecting previously unselected package wget.\n",
      "Preparing to unpack .../wget_1.17.1-1ubuntu1.5_amd64.deb ...\n",
      "Unpacking wget (1.17.1-1ubuntu1.5) ...\n",
      "Selecting previously unselected package curl.\n",
      "Preparing to unpack .../curl_7.47.0-1ubuntu2.19_amd64.deb ...\n",
      "Unpacking curl (7.47.0-1ubuntu2.19) ...\n",
      "Selecting previously unselected package fonts-dejavu-core.\n",
      "Preparing to unpack .../fonts-dejavu-core_2.35-1_all.deb ...\n",
      "Unpacking fonts-dejavu-core (2.35-1) ...\n",
      "Selecting previously unselected package fontconfig-config.\n",
      "Preparing to unpack .../fontconfig-config_2.11.94-0ubuntu1.1_all.deb ...\n",
      "Unpacking fontconfig-config (2.11.94-0ubuntu1.1) ...\n",
      "Selecting previously unselected package liberror-perl.\n",
      "Preparing to unpack .../liberror-perl_0.17-1.2_all.deb ...\n",
      "Unpacking liberror-perl (0.17-1.2) ...\n",
      "Selecting previously unselected package git-man.\n",
      "Preparing to unpack .../git-man_1%3a2.7.4-0ubuntu1.10_all.deb ...\n",
      "Unpacking git-man (1:2.7.4-0ubuntu1.10) ...\n",
      "Selecting previously unselected package git.\n",
      "Preparing to unpack .../git_1%3a2.7.4-0ubuntu1.10_amd64.deb ...\n",
      "Unpacking git (1:2.7.4-0ubuntu1.10) ...\n",
      "Selecting previously unselected package libdrm-amdgpu1:amd64.\n",
      "Preparing to unpack .../libdrm-amdgpu1_2.4.91-2~16.04.1_amd64.deb ...\n",
      "Unpacking libdrm-amdgpu1:amd64 (2.4.91-2~16.04.1) ...\n",
      "Selecting previously unselected package libpciaccess0:amd64.\n",
      "Preparing to unpack .../libpciaccess0_0.13.4-1_amd64.deb ...\n",
      "Unpacking libpciaccess0:amd64 (0.13.4-1) ...\n",
      "Selecting previously unselected package libdrm-intel1:amd64.\n",
      "Preparing to unpack .../libdrm-intel1_2.4.91-2~16.04.1_amd64.deb ...\n",
      "Unpacking libdrm-intel1:amd64 (2.4.91-2~16.04.1) ...\n",
      "Selecting previously unselected package libdrm-nouveau2:amd64.\n",
      "Preparing to unpack .../libdrm-nouveau2_2.4.91-2~16.04.1_amd64.deb ...\n",
      "Unpacking libdrm-nouveau2:amd64 (2.4.91-2~16.04.1) ...\n",
      "Selecting previously unselected package libdrm-radeon1:amd64.\n",
      "Preparing to unpack .../libdrm-radeon1_2.4.91-2~16.04.1_amd64.deb ...\n",
      "Unpacking libdrm-radeon1:amd64 (2.4.91-2~16.04.1) ...\n",
      "Selecting previously unselected package libfreetype6:amd64.\n",
      "Preparing to unpack .../libfreetype6_2.6.1-0.1ubuntu2.5_amd64.deb ...\n",
      "Unpacking libfreetype6:amd64 (2.6.1-0.1ubuntu2.5) ...\n",
      "Selecting previously unselected package libfontconfig1:amd64.\n",
      "Preparing to unpack .../libfontconfig1_2.11.94-0ubuntu1.1_amd64.deb ...\n",
      "Unpacking libfontconfig1:amd64 (2.11.94-0ubuntu1.1) ...\n",
      "Selecting previously unselected package libjpeg8:amd64.\n",
      "Preparing to unpack .../libjpeg8_8c-2ubuntu8_amd64.deb ...\n",
      "Unpacking libjpeg8:amd64 (8c-2ubuntu8) ...\n",
      "Selecting previously unselected package libtiff5:amd64.\n",
      "Preparing to unpack .../libtiff5_4.0.6-1ubuntu0.8_amd64.deb ...\n",
      "Unpacking libtiff5:amd64 (4.0.6-1ubuntu0.8) ...\n",
      "Selecting previously unselected package libvpx3:amd64.\n",
      "Preparing to unpack .../libvpx3_1.5.0-2ubuntu1.1_amd64.deb ...\n",
      "Unpacking libvpx3:amd64 (1.5.0-2ubuntu1.1) ...\n",
      "Selecting previously unselected package libxpm4:amd64.\n",
      "Preparing to unpack .../libxpm4_1%3a3.5.11-1ubuntu0.16.04.1_amd64.deb ...\n",
      "Unpacking libxpm4:amd64 (1:3.5.11-1ubuntu0.16.04.1) ...\n",
      "Selecting previously unselected package libgd3:amd64.\n",
      "Preparing to unpack .../libgd3_2.1.1-4ubuntu0.16.04.12_amd64.deb ...\n",
      "Unpacking libgd3:amd64 (2.1.1-4ubuntu0.16.04.12) ...\n",
      "Selecting previously unselected package libglapi-mesa:amd64.\n",
      "Preparing to unpack .../libglapi-mesa_18.0.5-0ubuntu0~16.04.1_amd64.deb ...\n",
      "Unpacking libglapi-mesa:amd64 (18.0.5-0ubuntu0~16.04.1) ...\n",
      "Selecting previously unselected package libllvm6.0:amd64.\n",
      "Preparing to unpack .../libllvm6.0_1%3a6.0-1ubuntu2~16.04.1_amd64.deb ...\n",
      "Unpacking libllvm6.0:amd64 (1:6.0-1ubuntu2~16.04.1) ...\n",
      "Selecting previously unselected package libsensors4:amd64.\n",
      "Preparing to unpack .../libsensors4_1%3a3.4.0-2_amd64.deb ...\n",
      "Unpacking libsensors4:amd64 (1:3.4.0-2) ...\n",
      "Selecting previously unselected package libgl1-mesa-dri:amd64.\n",
      "Preparing to unpack .../libgl1-mesa-dri_18.0.5-0ubuntu0~16.04.1_amd64.deb ...\n",
      "Unpacking libgl1-mesa-dri:amd64 (18.0.5-0ubuntu0~16.04.1) ...\n",
      "Selecting previously unselected package libx11-xcb1:amd64.\n",
      "Preparing to unpack .../libx11-xcb1_2%3a1.6.3-1ubuntu2.2_amd64.deb ...\n",
      "Unpacking libx11-xcb1:amd64 (2:1.6.3-1ubuntu2.2) ...\n",
      "Selecting previously unselected package libxcb-dri2-0:amd64.\n",
      "Preparing to unpack .../libxcb-dri2-0_1.11.1-1ubuntu1_amd64.deb ...\n",
      "Unpacking libxcb-dri2-0:amd64 (1.11.1-1ubuntu1) ...\n",
      "Selecting previously unselected package libxcb-dri3-0:amd64.\n",
      "Preparing to unpack .../libxcb-dri3-0_1.11.1-1ubuntu1_amd64.deb ...\n",
      "Unpacking libxcb-dri3-0:amd64 (1.11.1-1ubuntu1) ...\n",
      "Selecting previously unselected package libxcb-glx0:amd64.\n",
      "Preparing to unpack .../libxcb-glx0_1.11.1-1ubuntu1_amd64.deb ...\n",
      "Unpacking libxcb-glx0:amd64 (1.11.1-1ubuntu1) ...\n",
      "Selecting previously unselected package libxcb-present0:amd64.\n",
      "Preparing to unpack .../libxcb-present0_1.11.1-1ubuntu1_amd64.deb ...\n",
      "Unpacking libxcb-present0:amd64 (1.11.1-1ubuntu1) ...\n",
      "Selecting previously unselected package libxcb-sync1:amd64.\n",
      "Preparing to unpack .../libxcb-sync1_1.11.1-1ubuntu1_amd64.deb ...\n",
      "Unpacking libxcb-sync1:amd64 (1.11.1-1ubuntu1) ...\n",
      "Selecting previously unselected package libgl1-mesa-glx:amd64.\n",
      "Preparing to unpack .../libgl1-mesa-glx_18.0.5-0ubuntu0~16.04.1_amd64.deb ...\n",
      "Unpacking libgl1-mesa-glx:amd64 (18.0.5-0ubuntu0~16.04.1) ...\n",
      "Selecting previously unselected package libxslt1.1:amd64.\n",
      "Preparing to unpack .../libxslt1.1_1.1.28-2.1ubuntu0.3_amd64.deb ...\n",
      "Unpacking libxslt1.1:amd64 (1.1.28-2.1ubuntu0.3) ...\n",
      "Selecting previously unselected package nginx-common.\n",
      "Preparing to unpack .../nginx-common_1.10.3-0ubuntu0.16.04.5_all.deb ...\n",
      "Unpacking nginx-common (1.10.3-0ubuntu0.16.04.5) ...\n",
      "Selecting previously unselected package nginx-core.\n",
      "Preparing to unpack .../nginx-core_1.10.3-0ubuntu0.16.04.5_amd64.deb ...\n",
      "Unpacking nginx-core (1.10.3-0ubuntu0.16.04.5) ...\n",
      "Selecting previously unselected package nginx.\n",
      "Preparing to unpack .../nginx_1.10.3-0ubuntu0.16.04.5_all.deb ...\n",
      "Unpacking nginx (1.10.3-0ubuntu0.16.04.5) ...\n",
      "Selecting previously unselected package unzip.\n",
      "Preparing to unpack .../unzip_6.0-20ubuntu1.1_amd64.deb ...\n",
      "Unpacking unzip (6.0-20ubuntu1.1) ...\n",
      "Processing triggers for libc-bin (2.23-0ubuntu11.3) ...\n",
      "Processing triggers for systemd (229-4ubuntu21.31) ...\n",
      "Setting up libxau6:amd64 (1:1.0.8-1) ...\n",
      "Setting up libxdmcp6:amd64 (1:1.1.2-1.1) ...\n",
      "Setting up libxcb1:amd64 (1.11.1-1ubuntu1) ...\n",
      "Setting up libx11-data (2:1.6.3-1ubuntu2.2) ...\n",
      "Setting up libx11-6:amd64 (2:1.6.3-1ubuntu2.2) ...\n",
      "Setting up libxext6:amd64 (2:1.3.3-1) ...\n",
      "Setting up libjpeg-turbo8:amd64 (1.4.2-0ubuntu3.4) ...\n",
      "Setting up libxdamage1:amd64 (1:1.1.4-2) ...\n",
      "Setting up libxfixes3:amd64 (1:5.0.1-2) ...\n",
      "Setting up libxshmfence1:amd64 (1.2-1) ...\n",
      "Setting up libxxf86vm1:amd64 (1:1.1.4-1) ...\n",
      "Setting up libjbig0:amd64 (2.1-3.1) ...\n",
      "Setting up libbsd0:amd64 (0.8.2-1ubuntu0.1) ...\n",
      "Setting up libexpat1:amd64 (2.1.0-7ubuntu0.16.04.5) ...\n",
      "Setting up libpng12-0:amd64 (1.2.54-1ubuntu1.1) ...\n",
      "Setting up ucf (3.0036) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\n",
      "debconf: falling back to frontend: Readline\n",
      "Setting up libdrm-common (2.4.91-2~16.04.1) ...\n",
      "Setting up libdrm2:amd64 (2.4.91-2~16.04.1) ...\n",
      "Setting up libedit2:amd64 (3.1-20150325-1ubuntu2) ...\n",
      "Setting up libelf1:amd64 (0.165-3ubuntu1.2) ...\n",
      "Setting up libgeoip1:amd64 (1.6.9-1) ...\n",
      "Setting up libicu55:amd64 (55.1-7ubuntu0.5) ...\n",
      "Setting up libxml2:amd64 (2.9.3+dfsg1-1ubuntu0.7) ...\n",
      "Setting up wget (1.17.1-1ubuntu1.5) ...\n",
      "Setting up curl (7.47.0-1ubuntu2.19) ...\n",
      "Setting up fonts-dejavu-core (2.35-1) ...\n",
      "Setting up fontconfig-config (2.11.94-0ubuntu1.1) ...\n",
      "Setting up liberror-perl (0.17-1.2) ...\n",
      "Setting up git-man (1:2.7.4-0ubuntu1.10) ...\n",
      "Setting up git (1:2.7.4-0ubuntu1.10) ...\n",
      "Setting up libdrm-amdgpu1:amd64 (2.4.91-2~16.04.1) ...\n",
      "Setting up libpciaccess0:amd64 (0.13.4-1) ...\n",
      "Setting up libdrm-intel1:amd64 (2.4.91-2~16.04.1) ...\n",
      "Setting up libdrm-nouveau2:amd64 (2.4.91-2~16.04.1) ...\n",
      "Setting up libdrm-radeon1:amd64 (2.4.91-2~16.04.1) ...\n",
      "Setting up libfreetype6:amd64 (2.6.1-0.1ubuntu2.5) ...\n",
      "Setting up libfontconfig1:amd64 (2.11.94-0ubuntu1.1) ...\n",
      "Setting up libjpeg8:amd64 (8c-2ubuntu8) ...\n",
      "Setting up libtiff5:amd64 (4.0.6-1ubuntu0.8) ...\n",
      "Setting up libvpx3:amd64 (1.5.0-2ubuntu1.1) ...\n",
      "Setting up libxpm4:amd64 (1:3.5.11-1ubuntu0.16.04.1) ...\n",
      "Setting up libgd3:amd64 (2.1.1-4ubuntu0.16.04.12) ...\n",
      "Setting up libglapi-mesa:amd64 (18.0.5-0ubuntu0~16.04.1) ...\n",
      "Setting up libllvm6.0:amd64 (1:6.0-1ubuntu2~16.04.1) ...\n",
      "Setting up libsensors4:amd64 (1:3.4.0-2) ...\n",
      "Setting up libgl1-mesa-dri:amd64 (18.0.5-0ubuntu0~16.04.1) ...\n",
      "Setting up libx11-xcb1:amd64 (2:1.6.3-1ubuntu2.2) ...\n",
      "Setting up libxcb-dri2-0:amd64 (1.11.1-1ubuntu1) ...\n",
      "Setting up libxcb-dri3-0:amd64 (1.11.1-1ubuntu1) ...\n",
      "Setting up libxcb-glx0:amd64 (1.11.1-1ubuntu1) ...\n",
      "Setting up libxcb-present0:amd64 (1.11.1-1ubuntu1) ...\n",
      "Setting up libxcb-sync1:amd64 (1.11.1-1ubuntu1) ...\n",
      "Setting up libgl1-mesa-glx:amd64 (18.0.5-0ubuntu0~16.04.1) ...\n",
      "update-alternatives: using /usr/lib/x86_64-linux-gnu/mesa/ld.so.conf to provide /etc/ld.so.conf.d/x86_64-linux-gnu_GL.conf (x86_64-linux-gnu_gl_conf) in auto mode\n",
      "Setting up libxslt1.1:amd64 (1.1.28-2.1ubuntu0.3) ...\n",
      "Setting up nginx-common (1.10.3-0ubuntu0.16.04.5) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\n",
      "debconf: falling back to frontend: Readline\n",
      "Setting up nginx-core (1.10.3-0ubuntu0.16.04.5) ...\n",
      "invoke-rc.d: could not determine current runlevel\n",
      "invoke-rc.d: policy-rc.d denied execution of start.\n",
      "Setting up nginx (1.10.3-0ubuntu0.16.04.5) ...\n",
      "Setting up unzip (6.0-20ubuntu1.1) ...\n",
      "Processing triggers for libc-bin (2.23-0ubuntu11.3) ...\n",
      "Processing triggers for systemd (229-4ubuntu21.31) ...\n",
      "Removing intermediate container 7b0f158f485b\n",
      " ---> f81dac796496\n",
      "Step 3/32 : RUN git clone https://github.com/pyenv/pyenv.git .pyenv\n",
      " ---> Running in 3c41c9d93eb8\n",
      "\u001b[91mCloning into '.pyenv'...\n",
      "\u001b[0mRemoving intermediate container 3c41c9d93eb8\n",
      " ---> 29b7049525ea\n",
      "Step 4/32 : WORKDIR /\n",
      " ---> Running in ebd9f2b5b8a2\n",
      "Removing intermediate container ebd9f2b5b8a2\n",
      " ---> 1794dc1050f9\n",
      "Step 5/32 : ENV HOME  /\n",
      " ---> Running in c973c1281932\n",
      "Removing intermediate container c973c1281932\n",
      " ---> 710d1b71c6eb\n",
      "Step 6/32 : ENV PYENV_ROOT /.pyenv\n",
      " ---> Running in 71068f7848cb\n",
      "Removing intermediate container 71068f7848cb\n",
      " ---> a30013e47bf5\n",
      "Step 7/32 : ENV PATH $PYENV_ROOT/shims:$PYENV_ROOT/bin:$PATH\n",
      " ---> Running in 9eed67989eae\n",
      "Removing intermediate container 9eed67989eae\n",
      " ---> a48564c82db3\n",
      "Step 8/32 : RUN pyenv install anaconda3-5.0.0\n",
      " ---> Running in c622260e3c67\n",
      "\u001b[91mDownloading Anaconda3-5.0.0.1-Linux-x86_64.sh...\n",
      "\u001b[0m\u001b[91m-> https://repo.continuum.io/archive/Anaconda3-5.0.0.1-Linux-x86_64.sh\n",
      "\u001b[0m\u001b[91mInstalling Anaconda3-5.0.0.1-Linux-x86_64...\n",
      "\u001b[0m\u001b[91mInstalled Anaconda3-5.0.0.1-Linux-x86_64 to /.pyenv/versions/anaconda3-5.0.0\n",
      "\n",
      "\u001b[0mRemoving intermediate container c622260e3c67\n",
      " ---> c3ed4ddab997\n",
      "Step 9/32 : RUN pyenv global anaconda3-5.0.0\n",
      " ---> Running in e23c4497cb65\n",
      "Removing intermediate container e23c4497cb65\n",
      " ---> 65c508120e0b\n",
      "Step 10/32 : RUN pyenv rehash\n",
      " ---> Running in 991b9a77adf6\n",
      "Removing intermediate container 991b9a77adf6\n",
      " ---> 66bdb3840a4d\n",
      "Step 11/32 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Running in 53810c8a748f\n",
      "Removing intermediate container 53810c8a748f\n",
      " ---> 6047104a257b\n",
      "Step 12/32 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Running in 2e28cad91981\n",
      "Removing intermediate container 2e28cad91981\n",
      " ---> d8cb40faabaf\n",
      "Step 13/32 : ENV PATH=\"/opt/program:${PATH}\"\n",
      " ---> Running in 33a04c89690f\n",
      "Removing intermediate container 33a04c89690f\n",
      " ---> 51bceb4a60c8\n",
      "Step 14/32 : ENV PYTHONIOENCODING=utf-8\n",
      " ---> Running in 33c45eeb67f3\n",
      "Removing intermediate container 33c45eeb67f3\n",
      " ---> c8a745d7115b\n",
      "Step 15/32 : WORKDIR /opt/program\n",
      " ---> Running in 32bc98901170\n",
      "Removing intermediate container 32bc98901170\n",
      " ---> 6de9a03efd99\n",
      "Step 16/32 : RUN git clone https://github.com/mack-the-psych/plimac3.git\n",
      " ---> Running in d3ccddfb4c6a\n",
      "\u001b[91mCloning into 'plimac3'...\n",
      "\u001b[0mRemoving intermediate container d3ccddfb4c6a\n",
      " ---> 8c10524ee2be\n",
      "Step 17/32 : RUN echo \"/opt/program/plimac3/Lib\" > /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/plimac-custom.pth\n",
      " ---> Running in 10bd3ccb8c2f\n",
      "Removing intermediate container 10bd3ccb8c2f\n",
      " ---> 1f685b3e7033\n",
      "Step 18/32 : RUN echo \"/opt/program/plimac3/Tools\" >> /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/plimac-custom.pth\n",
      " ---> Running in 97ddeec5766a\n",
      "Removing intermediate container 97ddeec5766a\n",
      " ---> e870aaa642ef\n",
      "Step 19/32 : RUN conda install -c anaconda setuptools\n",
      " ---> Running in d5fb00dd42e5\n",
      "Fetching package metadata .............\n",
      "Solving package specifications: .\n",
      "\n",
      "Package plan for installation in environment /.pyenv/versions/anaconda3-5.0.0:\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    conda-package-handling: 1.7.2-py36h03888b9_0  anaconda\n",
      "    tqdm:                   4.50.2-py_0           anaconda\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "    conda:                  4.3.27-py36h2866c0b_0          --> 4.9.0-py36_0          anaconda\n",
      "    libgcc-ng:              7.2.0-hcbc56d2_1               --> 9.1.0-hdf63c60_0      anaconda\n",
      "    pycosat:                0.6.2-py36h1a0ea17_1           --> 0.6.3-py36h7b6447c_0  anaconda\n",
      "    setuptools:             36.5.0-py36he42e2e1_0          --> 50.3.0-py36hb0f4dca_1 anaconda\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "    conda-env:              2.6.0-h36134e3_1               --> 2.6.0-1               anaconda\n",
      "\n",
      "Proceed ([y]/n)? \n",
      "conda-env-2.6. 100% |###############################| Time: 0:00:00   3.61 MB/s\n",
      "libgcc-ng-9.1. 100% |###############################| Time: 0:00:00  49.45 MB/s\n",
      "pycosat-0.6.3- 100% |###############################| Time: 0:00:00  22.21 MB/s\n",
      "tqdm-4.50.2-py 100% |###############################| Time: 0:00:00  41.74 MB/s\n",
      "conda-package- 100% |###############################| Time: 0:00:00  58.52 MB/s\n",
      "setuptools-50. 100% |###############################| Time: 0:00:00  58.33 MB/s\n",
      "conda-4.9.0-py 100% |###############################| Time: 0:00:00  57.01 MB/s\n",
      "Removing intermediate container d5fb00dd42e5\n",
      " ---> 06877fef41d7\n",
      "Step 20/32 : RUN pip install --upgrade pip &&     pip install tensorflow-gpu==1.14.0 --user &&     pip install ml_metrics==0.1.4 &&     pip install --upgrade scipy==1.1.0 &&     conda clean --all &&     conda install pytorch==1.0.0 torchvision==0.2.1 cuda100 -c pytorch &&     pip install torchtext==0.4.0 &&     pip install attrdict==2.0.1 &&     pip uninstall --yes numpy &&     pip install numpy==1.16.4 &&     pip uninstall --yes gast &&     pip install gast==0.2.2 &&     pip install -U gevent==1.4.0 --ignore-installed &&     pip install gunicorn\n",
      " ---> Running in 0fc0d06baf1c\n",
      "Collecting pip\n",
      "  Downloading https://files.pythonhosted.org/packages/ca/31/b88ef447d595963c01060998cb329251648acf4a067721b0452c45527eb8/pip-21.2.4-py3-none-any.whl (1.6MB)\n",
      "Installing collected packages: pip\n",
      "  Found existing installation: pip 9.0.1\n",
      "    Uninstalling pip-9.0.1:\n",
      "      Successfully uninstalled pip-9.0.1\n",
      "Successfully installed pip-21.2.4\n",
      "Collecting tensorflow-gpu==1.14.0\n",
      "  Downloading tensorflow_gpu-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (377.0 MB)\n",
      "Collecting gast>=0.2.0\n",
      "  Downloading gast-0.5.2-py3-none-any.whl (10 kB)\n",
      "Collecting numpy<2.0,>=1.14.5\n",
      "  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n",
      "Collecting absl-py>=0.7.0\n",
      "  Downloading absl_py-0.13.0-py3-none-any.whl (132 kB)\n",
      "Collecting wrapt>=1.11.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting protobuf>=3.6.1\n",
      "  Downloading protobuf-3.17.3-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "Requirement already satisfied: six>=1.10.0 in /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0) (1.10.0)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.39.0-cp36-cp36m-manylinux2014_x86_64.whl (4.3 MB)\n",
      "Collecting tensorboard<1.15.0,>=1.14.0\n",
      "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
      "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages (from tensorflow-gpu==1.14.0) (0.29.0)\n",
      "Collecting keras-applications>=1.0.6\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "Collecting astor>=0.6.0\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting keras-preprocessing>=1.0.5\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting google-pasta>=0.1.6\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: h5py in /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (2.7.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (50.3.0.post20201006)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (0.12.2)\n",
      "Collecting importlib-metadata\n",
      "  Downloading importlib_metadata-4.6.4-py3-none-any.whl (17 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.5.0-py3-none-any.whl (5.7 kB)\n",
      "Collecting typing-extensions>=3.6.4\n",
      "  Downloading typing_extensions-3.10.0.0-py3-none-any.whl (26 kB)\n",
      "Building wheels for collected packages: termcolor, wrapt\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=5680 sha256=074ce6afacebafc84f78c8a83e2ff53d92e08107ea10d020ab10efd4b3a07ffd\n",
      "  Stored in directory: /.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=68137 sha256=c96a084c4e4a19e250312a0f4857f316f83b0b0ef051bfb6fa2b579269ce6967\n",
      "  Stored in directory: /.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\n",
      "Successfully built termcolor wrapt\n",
      "Installing collected packages: zipp, typing-extensions, numpy, importlib-metadata, protobuf, markdown, grpcio, absl-py, wrapt, termcolor, tensorflow-estimator, tensorboard, keras-preprocessing, keras-applications, google-pasta, gast, astor, tensorflow-gpu\n",
      "\u001b[91m  WARNING: The scripts f2py, f2py3 and f2py3.6 are installed in '/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\u001b[0m\u001b[91m  WARNING: The script markdown_py is installed in '/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\u001b[0m\u001b[91m  WARNING: The script tensorboard is installed in '/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\u001b[0m\u001b[91m  WARNING: The scripts freeze_graph, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\u001b[0mSuccessfully installed absl-py-0.13.0 astor-0.8.1 gast-0.5.2 google-pasta-0.2.0 grpcio-1.39.0 importlib-metadata-4.6.4 keras-applications-1.0.8 keras-preprocessing-1.1.2 markdown-3.3.4 numpy-1.19.5 protobuf-3.17.3 tensorboard-1.14.0 tensorflow-estimator-1.14.0 tensorflow-gpu-1.14.0 termcolor-1.1.0 typing-extensions-3.10.0.0 wrapt-1.12.1 zipp-3.5.0\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mCollecting ml_metrics==0.1.4\n",
      "  Downloading ml_metrics-0.1.4.tar.gz (5.0 kB)\n",
      "Requirement already satisfied: numpy in /.local/lib/python3.6/site-packages (from ml_metrics==0.1.4) (1.19.5)\n",
      "Requirement already satisfied: pandas in /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages (from ml_metrics==0.1.4) (0.20.3)\n",
      "Requirement already satisfied: python-dateutil>=2 in /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages (from pandas->ml_metrics==0.1.4) (2.6.1)\n",
      "Requirement already satisfied: pytz>=2011k in /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages (from pandas->ml_metrics==0.1.4) (2017.2)\n",
      "Requirement already satisfied: six>=1.5 in /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages (from python-dateutil>=2->pandas->ml_metrics==0.1.4) (1.10.0)\n",
      "Building wheels for collected packages: ml-metrics\n",
      "  Building wheel for ml-metrics (setup.py): started\n",
      "  Building wheel for ml-metrics (setup.py): finished with status 'done'\n",
      "  Created wheel for ml-metrics: filename=ml_metrics-0.1.4-py3-none-any.whl size=8543 sha256=9ded0a80dd2dbf61026609262f8030e3cfbe6b5874747ff22d0342d7a9d0b6ce\n",
      "  Stored in directory: /.cache/pip/wheels/18/ae/7a/7b60c579f0de920aa060c609cc17472ea20c7cfe657ee8cf5c\n",
      "Successfully built ml-metrics\n",
      "Installing collected packages: ml-metrics\n",
      "Successfully installed ml-metrics-0.1.4\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mCollecting scipy==1.1.0\n",
      "  Downloading scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2 MB)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /.local/lib/python3.6/site-packages (from scipy==1.1.0) (1.19.5)\n",
      "Installing collected packages: scipy\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 0.19.1\n",
      "    Uninstalling scipy-0.19.1:\n",
      "      Successfully uninstalled scipy-0.19.1\n",
      "Successfully installed scipy-1.1.0\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mCache location: /.pyenv/versions/anaconda3-5.0.0/pkgs\n",
      "Will remove the following tarballs:\n",
      "\n",
      "/.pyenv/versions/anaconda3-5.0.0/pkgs\n",
      "-------------------------------------\n",
      "pango-1.40.11-hedb6d6b_0.tar.bz2             526 KB\n",
      "msgpack-python-0.4.8-py36hec4c5d1_0.tar.bz2      90 KB\n",
      "openpyxl-2.4.8-py36h41dd2a8_1.tar.bz2        295 KB\n",
      "backports-1.0-py36hfa02d7e_1.tar.bz2           3 KB\n",
      "pyopenssl-17.2.0-py36h5cc804b_0.tar.bz2       78 KB\n",
      "mkl-2018.0.0-hb491cac_4.tar.bz2            174.4 MB\n",
      "networkx-1.11-py36hfb3574a_0.tar.bz2         1.5 MB\n",
      "conda-4.3.27-py36h2866c0b_0.tar.bz2          511 KB\n",
      "dask-core-0.15.2-py36h0f988a8_0.tar.bz2      893 KB\n",
      "gst-plugins-base-1.12.2-he3457e5_0.tar.bz2     4.9 MB\n",
      "ruamel_yaml-0.11.14-py36ha2fb22d_2.tar.bz2     210 KB\n",
      "jupyter_core-4.3.0-py36h357a921_0.tar.bz2      60 KB\n",
      "simplegeneric-0.8.1-py36h2cb9092_0.tar.bz2       9 KB\n",
      "docutils-0.14-py36hb0f60f5_0.tar.bz2         688 KB\n",
      "contextlib2-0.5.5-py36h6c84a62_0.tar.bz2      15 KB\n",
      "numba-0.35.0-np113py36_10.tar.bz2            2.6 MB\n",
      "mistune-0.7.4-py36hbab8784_0.tar.bz2          52 KB\n",
      "jupyterlab-0.27.0-py36h86377d0_2.tar.bz2     3.1 MB\n",
      "jpeg-9b-habf39ab_1.tar.bz2                   247 KB\n",
      "jupyter_console-5.2.0-py36he59e554_1.tar.bz2      35 KB\n",
      "libgfortran-ng-7.2.0-h6fcbd8e_1.tar.bz2      349 KB\n",
      "ply-3.10-py36hed35086_0.tar.bz2               79 KB\n",
      "pixman-0.34.0-ha72d70b_1.tar.bz2             597 KB\n",
      "ca-certificates-2017.08.26-h1d4fec5_0.tar.bz2     263 KB\n",
      "traitlets-4.3.2-py36h674d592_0.tar.bz2       131 KB\n",
      "qt-5.6.2-h974d657_12.tar.bz2                44.5 MB\n",
      "markupsafe-1.0-py36hd9260cd_1.tar.bz2         24 KB\n",
      "unicodecsv-0.14.1-py36ha668878_0.tar.bz2      25 KB\n",
      "pycodestyle-2.3.1-py36hf609f19_0.tar.bz2      55 KB\n",
      "urllib3-1.22-py36hbe7ace6_0.tar.bz2          155 KB\n",
      "tornado-4.5.2-py36h1283b2a_0.tar.bz2         616 KB\n",
      "werkzeug-0.12.2-py36hc703753_0.tar.bz2       413 KB\n",
      "heapdict-1.0.0-py36h79797d7_0.tar.bz2          7 KB\n",
      "singledispatch-3.4.0.3-py36h7a266c3_0.tar.bz2      15 KB\n",
      "conda-build-3.0.23-py36h1da9bb0_0.tar.bz2     372 KB\n",
      "bottleneck-1.2.1-py36haac1ea0_0.tar.bz2      127 KB\n",
      "qtpy-1.3.1-py36h3691cc8_0.tar.bz2             41 KB\n",
      "pysocks-1.6.7-py36hd97a5b1_1.tar.bz2          22 KB\n",
      "statsmodels-0.8.0-py36h8533d0b_0.tar.bz2     6.4 MB\n",
      "patchelf-0.9-hf79760b_2.tar.bz2               69 KB\n",
      "multipledispatch-0.4.9-py36h41da3fb_0.tar.bz2      15 KB\n",
      "scikit-learn-0.19.0-py36h97ac459_2.tar.bz2     5.2 MB\n",
      "libtool-2.4.6-hd50d1a6_0.tar.bz2             515 KB\n",
      "glob2-0.5-py36h2c1b292_1.tar.bz2              16 KB\n",
      "decorator-4.1.2-py36hd076ac8_0.tar.bz2        15 KB\n",
      "ipykernel-4.6.1-py36hbf841aa_0.tar.bz2       139 KB\n",
      "pillow-4.2.1-py36h9119f52_0.tar.bz2          548 KB\n",
      "wheel-0.29.0-py36he7f4e38_1.tar.bz2           88 KB\n",
      "toolz-0.8.2-py36h81f2dff_0.tar.bz2            91 KB\n",
      "openssl-1.0.2l-h9d1a558_3.tar.bz2            3.4 MB\n",
      "qtawesome-0.4.4-py36h609ed8c_0.tar.bz2       159 KB\n",
      "datashape-0.5.4-py36h3ad6b5c_0.tar.bz2        99 KB\n",
      "dask-0.15.2-py36h9b48dc4_0.tar.bz2             3 KB\n",
      "zeromq-4.2.2-hb0b69da_1.tar.bz2              662 KB\n",
      "ncurses-6.0-h06874d7_1.tar.bz2               907 KB\n",
      "pcre-8.41-hc71a17e_0.tar.bz2                 250 KB\n",
      "jdcal-1.3-py36h4c697fb_0.tar.bz2              11 KB\n",
      "requests-2.18.4-py36he2e5f8d_1.tar.bz2        92 KB\n",
      "curl-7.55.1-hcb0b314_2.tar.bz2               626 KB\n",
      "cycler-0.10.0-py36h93f1223_0.tar.bz2          13 KB\n",
      "nbconvert-5.3.1-py36hb41ffb7_0.tar.bz2       398 KB\n",
      "anaconda-project-0.8.0-py36h29abdf5_0.tar.bz2     209 KB\n",
      "mkl-service-1.1.2-py36h17a0993_4.tar.bz2      10 KB\n",
      "spyder-3.2.3-py36he38cbf7_1.tar.bz2          2.5 MB\n",
      "cloudpickle-0.4.0-py36h30f8c20_0.tar.bz2      24 KB\n",
      "cffi-1.10.0-py36had8d393_1.tar.bz2           206 KB\n",
      "notebook-5.0.0-py36h0b20546_2.tar.bz2        5.7 MB\n",
      "libpng-1.6.32-hda9c8bc_2.tar.bz2             335 KB\n",
      "beautifulsoup4-4.6.0-py36h49b8c8c_1.tar.bz2     133 KB\n",
      "libedit-3.1-heed3624_0.tar.bz2               171 KB\n",
      "python-dateutil-2.6.1-py36h88d3b88_1.tar.bz2     237 KB\n",
      "partd-0.3.8-py36h36fd896_0.tar.bz2            31 KB\n",
      "olefile-0.44-py36h79f9f78_0.tar.bz2           52 KB\n",
      "ipython-6.1.0-py36hc72a948_1.tar.bz2        1023 KB\n",
      "matplotlib-2.0.2-py36h2acb4ad_1.tar.bz2      6.6 MB\n",
      "sortedcontainers-1.5.7-py36hdf89491_0.tar.bz2      45 KB\n",
      "entrypoints-0.2.3-py36h1aec115_2.tar.bz2       9 KB\n",
      "greenlet-0.4.12-py36h2d503a6_0.tar.bz2        19 KB\n",
      "xlwt-1.3.0-py36h7b00a1f_0.tar.bz2            162 KB\n",
      "pathlib2-2.3.0-py36h49efa8e_0.tar.bz2         32 KB\n",
      "testpath-0.3.1-py36h8cadb63_0.tar.bz2         89 KB\n",
      "zlib-1.2.11-hfbfcf68_1.tar.bz2               101 KB\n",
      "libtiff-4.0.8-h90200ff_9.tar.bz2             579 KB\n",
      "get_terminal_size-1.0.0-haa9412d_0.tar.bz2       3 KB\n",
      "mpc-1.0.3-hf803216_4.tar.bz2                  94 KB\n",
      "cython-0.26.1-py36h21c49d0_0.tar.bz2         3.0 MB\n",
      "pycurl-7.43.0-py36h5e72054_3.tar.bz2          55 KB\n",
      "imageio-2.2.0-py36he555465_0.tar.bz2         3.2 MB\n",
      "scipy-0.19.1-py36h9976243_3.tar.bz2         17.4 MB\n",
      "numexpr-2.6.2-py36hdd3393f_1.tar.bz2         180 KB\n",
      "graphite2-1.3.10-hc526e54_0.tar.bz2          125 KB\n",
      "conda-env-2.6.0-h36134e3_1.tar.bz2             2 KB\n",
      "flask-0.12.2-py36hb24657c_0.tar.bz2          104 KB\n",
      "anaconda-5.0.0.1-py36hfb0b618_1.tar.bz2       13 KB\n",
      "typing-3.6.2-py36h7da032a_0.tar.bz2           44 KB\n",
      "anaconda-navigator-1.6.8-py36h672ccc7_0.tar.bz2     4.0 MB\n",
      "sqlalchemy-1.1.13-py36hfb5efd7_0.tar.bz2     1.5 MB\n",
      "py-1.4.34-py36h0712aa3_1.tar.bz2             134 KB\n",
      "pandas-0.20.3-py36h842e28d_2.tar.bz2         9.9 MB\n",
      "gevent-1.2.2-py36h2fe25dc_0.tar.bz2          773 KB\n",
      "numpydoc-0.7.0-py36h18f165f_0.tar.bz2         38 KB\n",
      "yaml-0.1.7-h96e3832_1.tar.bz2                 84 KB\n",
      "idna-2.6-py36h82fb2a8_1.tar.bz2              122 KB\n",
      "jedi-0.10.2-py36h552def0_0.tar.bz2           248 KB\n",
      "wcwidth-0.1.7-py36hdf4376a_0.tar.bz2          25 KB\n",
      "dbus-1.10.22-h3b5a359_0.tar.bz2              544 KB\n",
      "bleach-2.0.0-py36h688b259_0.tar.bz2           26 KB\n",
      "_ipyw_jlab_nb_ext_conf-0.1.0-py36he11e457_0.tar.bz2       4 KB\n",
      "libsodium-1.0.13-h31c71d8_2.tar.bz2          369 KB\n",
      "snowballstemmer-1.2.1-py36h6febd40_0.tar.bz2      85 KB\n",
      "html5lib-0.999999999-py36h2cfc398_0.tar.bz2     178 KB\n",
      "libffi-3.2.1-h4deb6c0_3.tar.bz2               43 KB\n",
      "fontconfig-2.12.4-h88586e7_1.tar.bz2         282 KB\n",
      "sphinxcontrib-1.0-py36h6d0f590_1.tar.bz2       3 KB\n",
      "colorama-0.3.9-py36h489cec4_0.tar.bz2         23 KB\n",
      "pytables-3.4.2-py36hdce54c9_1.tar.bz2        2.4 MB\n",
      "pycrypto-2.6.1-py36h6998063_1.tar.bz2        471 KB\n",
      "gmp-6.1.2-hb3b607b_0.tar.bz2                 744 KB\n",
      "asn1crypto-0.22.0-py36h265ca7c_1.tar.bz2     149 KB\n",
      "gstreamer-1.12.2-h4f93127_0.tar.bz2          3.6 MB\n",
      "distributed-1.18.3-py36h73cd4ae_0.tar.bz2     646 KB\n",
      "mccabe-0.6.1-py36h5ad9710_1.tar.bz2           13 KB\n",
      "cytoolz-0.8.2-py36h708bfd4_0.tar.bz2         364 KB\n",
      "pexpect-4.2.1-py36h3b9d41b_0.tar.bz2          71 KB\n",
      "h5py-2.7.0-py36he81ebca_1.tar.bz2            1.1 MB\n",
      "sphinx-1.6.3-py36he5f0bdb_0.tar.bz2          1.6 MB\n",
      "terminado-0.6-py36ha25a19f_0.tar.bz2          21 KB\n",
      "lzo-2.10-hc0eb8fc_0.tar.bz2                  312 KB\n",
      "pandocfilters-1.4.2-py36ha6701b7_1.tar.bz2      12 KB\n",
      "pycosat-0.6.2-py36h1a0ea17_1.tar.bz2         104 KB\n",
      "mpmath-0.19-py36h8cc018b_2.tar.bz2           886 KB\n",
      "webencodings-0.5.1-py36h800622e_1.tar.bz2      19 KB\n",
      "mpfr-3.1.5-h12ff648_1.tar.bz2                443 KB\n",
      "pygments-2.2.0-py36h0d3125c_0.tar.bz2        1.3 MB\n",
      "pip-9.0.1-py36h30f8307_2.tar.bz2             1.7 MB\n",
      "bitarray-0.8.1-py36h5834eb8_0.tar.bz2         60 KB\n",
      "backports.shutil_get_terminal_size-1.0.0-py36hfea85ff_2.tar.bz2       8 KB\n",
      "nose-1.3.7-py36hcdf7029_2.tar.bz2            214 KB\n",
      "wrapt-1.10.11-py36h28b7045_0.tar.bz2          45 KB\n",
      "cairo-1.14.10-h58b644b_4.tar.bz2             1.4 MB\n",
      "odo-0.5.1-py36h90ed295_0.tar.bz2             193 KB\n",
      "astroid-1.5.3-py36hbdb9df2_0.tar.bz2         373 KB\n",
      "harfbuzz-1.5.0-h2545bd6_0.tar.bz2            674 KB\n",
      "jsonschema-2.6.0-py36h006f8b5_0.tar.bz2       62 KB\n",
      "xlrd-1.1.0-py36h1db9f0c_1.tar.bz2            194 KB\n",
      "pytest-3.2.1-py36h11ad3bb_1.tar.bz2          282 KB\n",
      "icu-58.2-h211956c_0.tar.bz2                 22.5 MB\n",
      "pylint-1.7.2-py36h484ab97_0.tar.bz2          690 KB\n",
      "libxslt-1.1.29-hcf9102b_5.tar.bz2            533 KB\n",
      "sphinxcontrib-websupport-1.0.1-py36hb5cb234_1.tar.bz2      36 KB\n",
      "pywavelets-0.5.2-py36he602eb0_0.tar.bz2      4.0 MB\n",
      "fastcache-1.0.2-py36h5b0c431_0.tar.bz2        29 KB\n",
      "libstdcxx-ng-7.2.0-h24385c6_1.tar.bz2        2.5 MB\n",
      "hdf5-1.10.1-hb0523eb_0.tar.bz2               5.3 MB\n",
      "flask-cors-3.0.3-py36h2d857d3_0.tar.bz2       20 KB\n",
      "pandoc-1.19.2.1-hea2e7c5_1.tar.bz2          17.8 MB\n",
      "readline-7.0-hac23ff0_3.tar.bz2              387 KB\n",
      "anaconda-client-1.6.5-py36h19c0dcd_0.tar.bz2     132 KB\n",
      "pycparser-2.18-py36hf9f622e_1.tar.bz2        169 KB\n",
      "intel-openmp-2018.0.0-h15fc484_7.tar.bz2     617 KB\n",
      "llvmlite-0.20.0-py36_0.tar.bz2              11.2 MB\n",
      "python-3.6.2-hdfe5801_15.tar.bz2            27.0 MB\n",
      "jbig-2.1-hdba287a_0.tar.bz2                   41 KB\n",
      "ipywidgets-7.0.0-py36h7b55c3a_0.tar.bz2       91 KB\n",
      "sqlite-3.20.1-h6d8b0f3_1.tar.bz2             1.5 MB\n",
      "sympy-1.1.1-py36hc6d1c1c_0.tar.bz2           7.0 MB\n",
      "pyzmq-16.0.2-py36h3b0cf96_2.tar.bz2          419 KB\n",
      "clyent-1.2.2-py36h7e57e65_1.tar.bz2           18 KB\n",
      "bokeh-0.12.7-py36h169c5fd_1.tar.bz2          4.3 MB\n",
      "gmpy2-2.0.8-py36h55090d7_1.tar.bz2           165 KB\n",
      "freetype-2.8-h52ed37b_0.tar.bz2              803 KB\n",
      "pytz-2017.2-py36hc2ccc2a_1.tar.bz2           189 KB\n",
      "cryptography-2.0.3-py36ha225213_1.tar.bz2     591 KB\n",
      "locket-0.2.0-py36h787c0ad_1.tar.bz2            8 KB\n",
      "setuptools-36.5.0-py36he42e2e1_0.tar.bz2     512 KB\n",
      "pyqt-5.6.0-py36h0386399_5.tar.bz2            5.5 MB\n",
      "bkcharts-0.2-py36h735825a_0.tar.bz2          127 KB\n",
      "jupyter_client-5.1.0-py36h614e9ea_0.tar.bz2     117 KB\n",
      "conda-verify-2.0.0-py36h98955d8_0.tar.bz2      20 KB\n",
      "unixodbc-2.3.4-hc36303a_1.tar.bz2            316 KB\n",
      "ipython_genutils-0.2.0-py36hb52b0d5_0.tar.bz2      39 KB\n",
      "seaborn-0.8.0-py36h197244f_0.tar.bz2         333 KB\n",
      "astropy-2.0.2-py36ha51211e_4.tar.bz2         6.9 MB\n",
      "alabaster-0.7.10-py36h306e16b_0.tar.bz2       15 KB\n",
      "qtconsole-4.3.1-py36h8f73b5b_0.tar.bz2       150 KB\n",
      "expat-2.2.4-hc00ebd1_1.tar.bz2               185 KB\n",
      "six-1.10.0-py36hcac75e4_1.tar.bz2             20 KB\n",
      "pyflakes-1.5.0-py36h5510808_1.tar.bz2         83 KB\n",
      "click-6.7-py36h5253387_0.tar.bz2             104 KB\n",
      "filelock-2.0.12-py36hacfa1f5_0.tar.bz2        11 KB\n",
      "zict-0.1.2-py36ha0d441b_0.tar.bz2             18 KB\n",
      "sip-4.18.1-py36h51ed4ed_2.tar.bz2            277 KB\n",
      "lxml-3.8.0-py36h6c6e760_0.tar.bz2            1.1 MB\n",
      "pep8-1.7.0-py36h26ade29_0.tar.bz2             51 KB\n",
      "pyyaml-3.12-py36hafb9ca4_1.tar.bz2           159 KB\n",
      "libxcb-1.12-he6ee5dd_2.tar.bz2               445 KB\n",
      "libgcc-ng-7.2.0-hcbc56d2_1.tar.bz2           6.1 MB\n",
      "nbformat-4.4.0-py36h31c9010_0.tar.bz2        137 KB\n",
      "psutil-5.2.2-py36h74c8701_0.tar.bz2          249 KB\n",
      "lazy-object-proxy-1.3.1-py36h10fcdad_0.tar.bz2      29 KB\n",
      "chardet-3.0.4-py36h0f667ec_1.tar.bz2         190 KB\n",
      "xz-5.2.3-h2bcbf08_1.tar.bz2                  356 KB\n",
      "widgetsnbextension-3.0.2-py36hd01bb71_1.tar.bz2     2.0 MB\n",
      "blaze-0.11.3-py36h4e06776_0.tar.bz2          605 KB\n",
      "scikit-image-0.13.0-py36had3c07a_1.tar.bz2    23.0 MB\n",
      "pickleshare-0.7.4-py36h63277f8_0.tar.bz2      11 KB\n",
      "sortedcollections-0.5.3-py36h3c761f9_0.tar.bz2      14 KB\n",
      "babel-2.5.0-py36h7d14adf_0.tar.bz2           4.7 MB\n",
      "libxml2-2.9.4-h6b072ca_5.tar.bz2             2.0 MB\n",
      "libssh2-1.8.0-h8c220ad_2.tar.bz2             243 KB\n",
      "isort-4.2.15-py36had401c0_0.tar.bz2           57 KB\n",
      "pyodbc-4.0.17-py36h999153c_0.tar.bz2          57 KB\n",
      "boto-2.48.0-py36h6e4cd66_1.tar.bz2           1.5 MB\n",
      "xlsxwriter-0.9.8-py36hf41c223_0.tar.bz2      198 KB\n",
      "tk-8.6.7-h5979e9b_1.tar.bz2                  3.2 MB\n",
      "pkginfo-1.4.1-py36h215d178_1.tar.bz2          39 KB\n",
      "rope-0.10.5-py36h1f8c17e_0.tar.bz2           279 KB\n",
      "itsdangerous-0.24-py36h93cc618_1.tar.bz2      20 KB\n",
      "glib-2.53.6-hc861d11_1.tar.bz2               8.4 MB\n",
      "prompt_toolkit-1.0.15-py36h17d85b1_0.tar.bz2     339 KB\n",
      "imagesize-0.7.1-py36h52d8127_0.tar.bz2         6 KB\n",
      "navigator-updater-0.1.0-py36h14770f7_0.tar.bz2     1.2 MB\n",
      "et_xmlfile-1.0.1-py36hd6bccc3_0.tar.bz2       20 KB\n",
      "jupyter-1.0.0-py36h9896ce5_0.tar.bz2           4 KB\n",
      "certifi-2017.7.27.1-py36h8b7b77e_0.tar.bz2     205 KB\n",
      "jinja2-2.9.6-py36h489bce4_1.tar.bz2          362 KB\n",
      "numpy-1.13.1-py36h5bc529a_2.tar.bz2          3.9 MB\n",
      "pyparsing-2.2.0-py36hee85983_1.tar.bz2        96 KB\n",
      "ptyprocess-0.5.2-py36h69acd42_0.tar.bz2       22 KB\n",
      "jupyterlab_launcher-0.4.0-py36h4d8058d_0.tar.bz2      17 KB\n",
      "packaging-16.8-py36ha668100_1.tar.bz2         31 KB\n",
      "nltk-3.2.4-py36h1a0979f_0.tar.bz2            2.0 MB\n",
      "path.py-10.3.1-py36he0c6f6d_0.tar.bz2         51 KB\n",
      "tblib-1.3.2-py36h34cf8b6_0.tar.bz2            16 KB\n",
      "patsy-0.4.1-py36ha3be15e_0.tar.bz2           323 KB\n",
      "libgcc-ng-9.1.0-hdf63c60_0.tar.bz2           8.1 MB\n",
      "tqdm-4.50.2-py_0.tar.bz2                      55 KB\n",
      "setuptools-50.3.0-py36hb0f4dca_1.tar.bz2     891 KB\n",
      "pycosat-0.6.3-py36h7b6447c_0.tar.bz2         107 KB\n",
      "conda-package-handling-1.7.2-py36h03888b9_0.tar.bz2     967 KB\n",
      "conda-4.9.0-py36_0.tar.bz2                   3.1 MB\n",
      "conda-env-2.6.0-1.tar.bz2                      3 KB\n",
      "\n",
      "---------------------------------------------------\n",
      "Total:                                     536.3 MB\n",
      "\n",
      "Proceed ([y]/n)? \n",
      "Removed pango-1.40.11-hedb6d6b_0.tar.bz2\n",
      "Removed msgpack-python-0.4.8-py36hec4c5d1_0.tar.bz2\n",
      "Removed openpyxl-2.4.8-py36h41dd2a8_1.tar.bz2\n",
      "Removed backports-1.0-py36hfa02d7e_1.tar.bz2\n",
      "Removed pyopenssl-17.2.0-py36h5cc804b_0.tar.bz2\n",
      "Removed mkl-2018.0.0-hb491cac_4.tar.bz2\n",
      "Removed networkx-1.11-py36hfb3574a_0.tar.bz2\n",
      "Removed conda-4.3.27-py36h2866c0b_0.tar.bz2\n",
      "Removed dask-core-0.15.2-py36h0f988a8_0.tar.bz2\n",
      "Removed gst-plugins-base-1.12.2-he3457e5_0.tar.bz2\n",
      "Removed ruamel_yaml-0.11.14-py36ha2fb22d_2.tar.bz2\n",
      "Removed jupyter_core-4.3.0-py36h357a921_0.tar.bz2\n",
      "Removed simplegeneric-0.8.1-py36h2cb9092_0.tar.bz2\n",
      "Removed docutils-0.14-py36hb0f60f5_0.tar.bz2\n",
      "Removed contextlib2-0.5.5-py36h6c84a62_0.tar.bz2\n",
      "Removed numba-0.35.0-np113py36_10.tar.bz2\n",
      "Removed mistune-0.7.4-py36hbab8784_0.tar.bz2\n",
      "Removed jupyterlab-0.27.0-py36h86377d0_2.tar.bz2\n",
      "Removed jpeg-9b-habf39ab_1.tar.bz2\n",
      "Removed jupyter_console-5.2.0-py36he59e554_1.tar.bz2\n",
      "Removed libgfortran-ng-7.2.0-h6fcbd8e_1.tar.bz2\n",
      "Removed ply-3.10-py36hed35086_0.tar.bz2\n",
      "Removed pixman-0.34.0-ha72d70b_1.tar.bz2\n",
      "Removed ca-certificates-2017.08.26-h1d4fec5_0.tar.bz2\n",
      "Removed traitlets-4.3.2-py36h674d592_0.tar.bz2\n",
      "Removed qt-5.6.2-h974d657_12.tar.bz2\n",
      "Removed markupsafe-1.0-py36hd9260cd_1.tar.bz2\n",
      "Removed unicodecsv-0.14.1-py36ha668878_0.tar.bz2\n",
      "Removed pycodestyle-2.3.1-py36hf609f19_0.tar.bz2\n",
      "Removed urllib3-1.22-py36hbe7ace6_0.tar.bz2\n",
      "Removed tornado-4.5.2-py36h1283b2a_0.tar.bz2\n",
      "Removed werkzeug-0.12.2-py36hc703753_0.tar.bz2\n",
      "Removed heapdict-1.0.0-py36h79797d7_0.tar.bz2\n",
      "Removed singledispatch-3.4.0.3-py36h7a266c3_0.tar.bz2\n",
      "Removed conda-build-3.0.23-py36h1da9bb0_0.tar.bz2\n",
      "Removed bottleneck-1.2.1-py36haac1ea0_0.tar.bz2\n",
      "Removed qtpy-1.3.1-py36h3691cc8_0.tar.bz2\n",
      "Removed pysocks-1.6.7-py36hd97a5b1_1.tar.bz2\n",
      "Removed statsmodels-0.8.0-py36h8533d0b_0.tar.bz2\n",
      "Removed patchelf-0.9-hf79760b_2.tar.bz2\n",
      "Removed multipledispatch-0.4.9-py36h41da3fb_0.tar.bz2\n",
      "Removed scikit-learn-0.19.0-py36h97ac459_2.tar.bz2\n",
      "Removed libtool-2.4.6-hd50d1a6_0.tar.bz2\n",
      "Removed glob2-0.5-py36h2c1b292_1.tar.bz2\n",
      "Removed decorator-4.1.2-py36hd076ac8_0.tar.bz2\n",
      "Removed ipykernel-4.6.1-py36hbf841aa_0.tar.bz2\n",
      "Removed pillow-4.2.1-py36h9119f52_0.tar.bz2\n",
      "Removed wheel-0.29.0-py36he7f4e38_1.tar.bz2\n",
      "Removed toolz-0.8.2-py36h81f2dff_0.tar.bz2\n",
      "Removed openssl-1.0.2l-h9d1a558_3.tar.bz2\n",
      "Removed qtawesome-0.4.4-py36h609ed8c_0.tar.bz2\n",
      "Removed datashape-0.5.4-py36h3ad6b5c_0.tar.bz2\n",
      "Removed dask-0.15.2-py36h9b48dc4_0.tar.bz2\n",
      "Removed zeromq-4.2.2-hb0b69da_1.tar.bz2\n",
      "Removed ncurses-6.0-h06874d7_1.tar.bz2\n",
      "Removed pcre-8.41-hc71a17e_0.tar.bz2\n",
      "Removed jdcal-1.3-py36h4c697fb_0.tar.bz2\n",
      "Removed requests-2.18.4-py36he2e5f8d_1.tar.bz2\n",
      "Removed curl-7.55.1-hcb0b314_2.tar.bz2\n",
      "Removed cycler-0.10.0-py36h93f1223_0.tar.bz2\n",
      "Removed nbconvert-5.3.1-py36hb41ffb7_0.tar.bz2\n",
      "Removed anaconda-project-0.8.0-py36h29abdf5_0.tar.bz2\n",
      "Removed mkl-service-1.1.2-py36h17a0993_4.tar.bz2\n",
      "Removed spyder-3.2.3-py36he38cbf7_1.tar.bz2\n",
      "Removed cloudpickle-0.4.0-py36h30f8c20_0.tar.bz2\n",
      "Removed cffi-1.10.0-py36had8d393_1.tar.bz2\n",
      "Removed notebook-5.0.0-py36h0b20546_2.tar.bz2\n",
      "Removed libpng-1.6.32-hda9c8bc_2.tar.bz2\n",
      "Removed beautifulsoup4-4.6.0-py36h49b8c8c_1.tar.bz2\n",
      "Removed libedit-3.1-heed3624_0.tar.bz2\n",
      "Removed python-dateutil-2.6.1-py36h88d3b88_1.tar.bz2\n",
      "Removed partd-0.3.8-py36h36fd896_0.tar.bz2\n",
      "Removed olefile-0.44-py36h79f9f78_0.tar.bz2\n",
      "Removed ipython-6.1.0-py36hc72a948_1.tar.bz2\n",
      "Removed matplotlib-2.0.2-py36h2acb4ad_1.tar.bz2\n",
      "Removed sortedcontainers-1.5.7-py36hdf89491_0.tar.bz2\n",
      "Removed entrypoints-0.2.3-py36h1aec115_2.tar.bz2\n",
      "Removed greenlet-0.4.12-py36h2d503a6_0.tar.bz2\n",
      "Removed xlwt-1.3.0-py36h7b00a1f_0.tar.bz2\n",
      "Removed pathlib2-2.3.0-py36h49efa8e_0.tar.bz2\n",
      "Removed testpath-0.3.1-py36h8cadb63_0.tar.bz2\n",
      "Removed zlib-1.2.11-hfbfcf68_1.tar.bz2\n",
      "Removed libtiff-4.0.8-h90200ff_9.tar.bz2\n",
      "Removed get_terminal_size-1.0.0-haa9412d_0.tar.bz2\n",
      "Removed mpc-1.0.3-hf803216_4.tar.bz2\n",
      "Removed cython-0.26.1-py36h21c49d0_0.tar.bz2\n",
      "Removed pycurl-7.43.0-py36h5e72054_3.tar.bz2\n",
      "Removed imageio-2.2.0-py36he555465_0.tar.bz2\n",
      "Removed scipy-0.19.1-py36h9976243_3.tar.bz2\n",
      "Removed numexpr-2.6.2-py36hdd3393f_1.tar.bz2\n",
      "Removed graphite2-1.3.10-hc526e54_0.tar.bz2\n",
      "Removed conda-env-2.6.0-h36134e3_1.tar.bz2\n",
      "Removed flask-0.12.2-py36hb24657c_0.tar.bz2\n",
      "Removed anaconda-5.0.0.1-py36hfb0b618_1.tar.bz2\n",
      "Removed typing-3.6.2-py36h7da032a_0.tar.bz2\n",
      "Removed anaconda-navigator-1.6.8-py36h672ccc7_0.tar.bz2\n",
      "Removed sqlalchemy-1.1.13-py36hfb5efd7_0.tar.bz2\n",
      "Removed py-1.4.34-py36h0712aa3_1.tar.bz2\n",
      "Removed pandas-0.20.3-py36h842e28d_2.tar.bz2\n",
      "Removed gevent-1.2.2-py36h2fe25dc_0.tar.bz2\n",
      "Removed numpydoc-0.7.0-py36h18f165f_0.tar.bz2\n",
      "Removed yaml-0.1.7-h96e3832_1.tar.bz2\n",
      "Removed idna-2.6-py36h82fb2a8_1.tar.bz2\n",
      "Removed jedi-0.10.2-py36h552def0_0.tar.bz2\n",
      "Removed wcwidth-0.1.7-py36hdf4376a_0.tar.bz2\n",
      "Removed dbus-1.10.22-h3b5a359_0.tar.bz2\n",
      "Removed bleach-2.0.0-py36h688b259_0.tar.bz2\n",
      "Removed _ipyw_jlab_nb_ext_conf-0.1.0-py36he11e457_0.tar.bz2\n",
      "Removed libsodium-1.0.13-h31c71d8_2.tar.bz2\n",
      "Removed snowballstemmer-1.2.1-py36h6febd40_0.tar.bz2\n",
      "Removed html5lib-0.999999999-py36h2cfc398_0.tar.bz2\n",
      "Removed libffi-3.2.1-h4deb6c0_3.tar.bz2\n",
      "Removed fontconfig-2.12.4-h88586e7_1.tar.bz2\n",
      "Removed sphinxcontrib-1.0-py36h6d0f590_1.tar.bz2\n",
      "Removed colorama-0.3.9-py36h489cec4_0.tar.bz2\n",
      "Removed pytables-3.4.2-py36hdce54c9_1.tar.bz2\n",
      "Removed pycrypto-2.6.1-py36h6998063_1.tar.bz2\n",
      "Removed gmp-6.1.2-hb3b607b_0.tar.bz2\n",
      "Removed asn1crypto-0.22.0-py36h265ca7c_1.tar.bz2\n",
      "Removed gstreamer-1.12.2-h4f93127_0.tar.bz2\n",
      "Removed distributed-1.18.3-py36h73cd4ae_0.tar.bz2\n",
      "Removed mccabe-0.6.1-py36h5ad9710_1.tar.bz2\n",
      "Removed cytoolz-0.8.2-py36h708bfd4_0.tar.bz2\n",
      "Removed pexpect-4.2.1-py36h3b9d41b_0.tar.bz2\n",
      "Removed h5py-2.7.0-py36he81ebca_1.tar.bz2\n",
      "Removed sphinx-1.6.3-py36he5f0bdb_0.tar.bz2\n",
      "Removed terminado-0.6-py36ha25a19f_0.tar.bz2\n",
      "Removed lzo-2.10-hc0eb8fc_0.tar.bz2\n",
      "Removed pandocfilters-1.4.2-py36ha6701b7_1.tar.bz2\n",
      "Removed pycosat-0.6.2-py36h1a0ea17_1.tar.bz2\n",
      "Removed mpmath-0.19-py36h8cc018b_2.tar.bz2\n",
      "Removed webencodings-0.5.1-py36h800622e_1.tar.bz2\n",
      "Removed mpfr-3.1.5-h12ff648_1.tar.bz2\n",
      "Removed pygments-2.2.0-py36h0d3125c_0.tar.bz2\n",
      "Removed pip-9.0.1-py36h30f8307_2.tar.bz2\n",
      "Removed bitarray-0.8.1-py36h5834eb8_0.tar.bz2\n",
      "Removed backports.shutil_get_terminal_size-1.0.0-py36hfea85ff_2.tar.bz2\n",
      "Removed nose-1.3.7-py36hcdf7029_2.tar.bz2\n",
      "Removed wrapt-1.10.11-py36h28b7045_0.tar.bz2\n",
      "Removed cairo-1.14.10-h58b644b_4.tar.bz2\n",
      "Removed odo-0.5.1-py36h90ed295_0.tar.bz2\n",
      "Removed astroid-1.5.3-py36hbdb9df2_0.tar.bz2\n",
      "Removed harfbuzz-1.5.0-h2545bd6_0.tar.bz2\n",
      "Removed jsonschema-2.6.0-py36h006f8b5_0.tar.bz2\n",
      "Removed xlrd-1.1.0-py36h1db9f0c_1.tar.bz2\n",
      "Removed pytest-3.2.1-py36h11ad3bb_1.tar.bz2\n",
      "Removed icu-58.2-h211956c_0.tar.bz2\n",
      "Removed pylint-1.7.2-py36h484ab97_0.tar.bz2\n",
      "Removed libxslt-1.1.29-hcf9102b_5.tar.bz2\n",
      "Removed sphinxcontrib-websupport-1.0.1-py36hb5cb234_1.tar.bz2\n",
      "Removed pywavelets-0.5.2-py36he602eb0_0.tar.bz2\n",
      "Removed fastcache-1.0.2-py36h5b0c431_0.tar.bz2\n",
      "Removed libstdcxx-ng-7.2.0-h24385c6_1.tar.bz2\n",
      "Removed hdf5-1.10.1-hb0523eb_0.tar.bz2\n",
      "Removed flask-cors-3.0.3-py36h2d857d3_0.tar.bz2\n",
      "Removed pandoc-1.19.2.1-hea2e7c5_1.tar.bz2\n",
      "Removed readline-7.0-hac23ff0_3.tar.bz2\n",
      "Removed anaconda-client-1.6.5-py36h19c0dcd_0.tar.bz2\n",
      "Removed pycparser-2.18-py36hf9f622e_1.tar.bz2\n",
      "Removed intel-openmp-2018.0.0-h15fc484_7.tar.bz2\n",
      "Removed llvmlite-0.20.0-py36_0.tar.bz2\n",
      "Removed python-3.6.2-hdfe5801_15.tar.bz2\n",
      "Removed jbig-2.1-hdba287a_0.tar.bz2\n",
      "Removed ipywidgets-7.0.0-py36h7b55c3a_0.tar.bz2\n",
      "Removed sqlite-3.20.1-h6d8b0f3_1.tar.bz2\n",
      "Removed sympy-1.1.1-py36hc6d1c1c_0.tar.bz2\n",
      "Removed pyzmq-16.0.2-py36h3b0cf96_2.tar.bz2\n",
      "Removed clyent-1.2.2-py36h7e57e65_1.tar.bz2\n",
      "Removed bokeh-0.12.7-py36h169c5fd_1.tar.bz2\n",
      "Removed gmpy2-2.0.8-py36h55090d7_1.tar.bz2\n",
      "Removed freetype-2.8-h52ed37b_0.tar.bz2\n",
      "Removed pytz-2017.2-py36hc2ccc2a_1.tar.bz2\n",
      "Removed cryptography-2.0.3-py36ha225213_1.tar.bz2\n",
      "Removed locket-0.2.0-py36h787c0ad_1.tar.bz2\n",
      "Removed setuptools-36.5.0-py36he42e2e1_0.tar.bz2\n",
      "Removed pyqt-5.6.0-py36h0386399_5.tar.bz2\n",
      "Removed bkcharts-0.2-py36h735825a_0.tar.bz2\n",
      "Removed jupyter_client-5.1.0-py36h614e9ea_0.tar.bz2\n",
      "Removed conda-verify-2.0.0-py36h98955d8_0.tar.bz2\n",
      "Removed unixodbc-2.3.4-hc36303a_1.tar.bz2\n",
      "Removed ipython_genutils-0.2.0-py36hb52b0d5_0.tar.bz2\n",
      "Removed seaborn-0.8.0-py36h197244f_0.tar.bz2\n",
      "Removed astropy-2.0.2-py36ha51211e_4.tar.bz2\n",
      "Removed alabaster-0.7.10-py36h306e16b_0.tar.bz2\n",
      "Removed qtconsole-4.3.1-py36h8f73b5b_0.tar.bz2\n",
      "Removed expat-2.2.4-hc00ebd1_1.tar.bz2\n",
      "Removed six-1.10.0-py36hcac75e4_1.tar.bz2\n",
      "Removed pyflakes-1.5.0-py36h5510808_1.tar.bz2\n",
      "Removed click-6.7-py36h5253387_0.tar.bz2\n",
      "Removed filelock-2.0.12-py36hacfa1f5_0.tar.bz2\n",
      "Removed zict-0.1.2-py36ha0d441b_0.tar.bz2\n",
      "Removed sip-4.18.1-py36h51ed4ed_2.tar.bz2\n",
      "Removed lxml-3.8.0-py36h6c6e760_0.tar.bz2\n",
      "Removed pep8-1.7.0-py36h26ade29_0.tar.bz2\n",
      "Removed pyyaml-3.12-py36hafb9ca4_1.tar.bz2\n",
      "Removed libxcb-1.12-he6ee5dd_2.tar.bz2\n",
      "Removed libgcc-ng-7.2.0-hcbc56d2_1.tar.bz2\n",
      "Removed nbformat-4.4.0-py36h31c9010_0.tar.bz2\n",
      "Removed psutil-5.2.2-py36h74c8701_0.tar.bz2\n",
      "Removed lazy-object-proxy-1.3.1-py36h10fcdad_0.tar.bz2\n",
      "Removed chardet-3.0.4-py36h0f667ec_1.tar.bz2\n",
      "Removed xz-5.2.3-h2bcbf08_1.tar.bz2\n",
      "Removed widgetsnbextension-3.0.2-py36hd01bb71_1.tar.bz2\n",
      "Removed blaze-0.11.3-py36h4e06776_0.tar.bz2\n",
      "Removed scikit-image-0.13.0-py36had3c07a_1.tar.bz2\n",
      "Removed pickleshare-0.7.4-py36h63277f8_0.tar.bz2\n",
      "Removed sortedcollections-0.5.3-py36h3c761f9_0.tar.bz2\n",
      "Removed babel-2.5.0-py36h7d14adf_0.tar.bz2\n",
      "Removed libxml2-2.9.4-h6b072ca_5.tar.bz2\n",
      "Removed libssh2-1.8.0-h8c220ad_2.tar.bz2\n",
      "Removed isort-4.2.15-py36had401c0_0.tar.bz2\n",
      "Removed pyodbc-4.0.17-py36h999153c_0.tar.bz2\n",
      "Removed boto-2.48.0-py36h6e4cd66_1.tar.bz2\n",
      "Removed xlsxwriter-0.9.8-py36hf41c223_0.tar.bz2\n",
      "Removed tk-8.6.7-h5979e9b_1.tar.bz2\n",
      "Removed pkginfo-1.4.1-py36h215d178_1.tar.bz2\n",
      "Removed rope-0.10.5-py36h1f8c17e_0.tar.bz2\n",
      "Removed itsdangerous-0.24-py36h93cc618_1.tar.bz2\n",
      "Removed glib-2.53.6-hc861d11_1.tar.bz2\n",
      "Removed prompt_toolkit-1.0.15-py36h17d85b1_0.tar.bz2\n",
      "Removed imagesize-0.7.1-py36h52d8127_0.tar.bz2\n",
      "Removed navigator-updater-0.1.0-py36h14770f7_0.tar.bz2\n",
      "Removed et_xmlfile-1.0.1-py36hd6bccc3_0.tar.bz2\n",
      "Removed jupyter-1.0.0-py36h9896ce5_0.tar.bz2\n",
      "Removed certifi-2017.7.27.1-py36h8b7b77e_0.tar.bz2\n",
      "Removed jinja2-2.9.6-py36h489bce4_1.tar.bz2\n",
      "Removed numpy-1.13.1-py36h5bc529a_2.tar.bz2\n",
      "Removed pyparsing-2.2.0-py36hee85983_1.tar.bz2\n",
      "Removed ptyprocess-0.5.2-py36h69acd42_0.tar.bz2\n",
      "Removed jupyterlab_launcher-0.4.0-py36h4d8058d_0.tar.bz2\n",
      "Removed packaging-16.8-py36ha668100_1.tar.bz2\n",
      "Removed nltk-3.2.4-py36h1a0979f_0.tar.bz2\n",
      "Removed path.py-10.3.1-py36he0c6f6d_0.tar.bz2\n",
      "Removed tblib-1.3.2-py36h34cf8b6_0.tar.bz2\n",
      "Removed patsy-0.4.1-py36ha3be15e_0.tar.bz2\n",
      "Removed libgcc-ng-9.1.0-hdf63c60_0.tar.bz2\n",
      "Removed tqdm-4.50.2-py_0.tar.bz2\n",
      "Removed setuptools-50.3.0-py36hb0f4dca_1.tar.bz2\n",
      "Removed pycosat-0.6.3-py36h7b6447c_0.tar.bz2\n",
      "Removed conda-package-handling-1.7.2-py36h03888b9_0.tar.bz2\n",
      "Removed conda-4.9.0-py36_0.tar.bz2\n",
      "Removed conda-env-2.6.0-1.tar.bz2\n",
      "Cache location: /.pyenv/versions/anaconda3-5.0.0/pkgs\n",
      "Will remove the following packages:\n",
      "/.pyenv/versions/anaconda3-5.0.0/pkgs\n",
      "-------------------------------------\n",
      "\n",
      "get_terminal_size-1.0.0-haa9412d_0             6 KB\n",
      "dask-0.15.2-py36h9b48dc4_0                     8 KB\n",
      "jupyter-1.0.0-py36h9896ce5_0                   9 KB\n",
      "conda-env-2.6.0-h36134e3_1                     4 KB\n",
      "anaconda-5.0.0.1-py36hfb0b618_1               75 KB\n",
      "conda-env-2.6.0-1                              6 KB\n",
      "\n",
      "---------------------------------------------------\n",
      "Total:                                       108 KB\n",
      "\n",
      "Proceed ([y]/n)? \n",
      "removing get_terminal_size-1.0.0-haa9412d_0\n",
      "removing dask-0.15.2-py36h9b48dc4_0\n",
      "removing jupyter-1.0.0-py36h9896ce5_0\n",
      "removing conda-env-2.6.0-h36134e3_1\n",
      "removing anaconda-5.0.0.1-py36hfb0b618_1\n",
      "removing conda-env-2.6.0-1\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... \u001b[91m\n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - https://repo.continuum.io/pkgs/main/linux-64/anaconda-5.0.0.1-py36hfb0b618_1.tar.bz2/linux-64::anaconda==5.0.0.1=py36hfb0b618_1\n",
      "\u001b[0m\n",
      "Warning: >10 possible package resolutions (only showing differing packages):\n",
      "  - https://repo.continuum.io/pkgs/main/linux-64/alabaster-0.7.10-py36h306e16b_0.tar.bz2/linux-64::alabaster-0.7.10-py36h306e16b_0, https://repo.continuum.io/pkgs/main/linux-64/boto-2.48.0-py36h6e4cd66_1.tar.bz2/linux-64::boto-2.48.0-py36h6e4cd66_1, https://repo.continuum.io/pkgs/main/linux-64/get_terminal_size-1.0.0-haa9412d_0.tar.bz2/linux-64::get_terminal_size-1.0.0-haa9412d_0, https://repo.continuum.io/pkgs/main/linux-64/intel-openmp-2018.0.0-h15fc484_7.tar.bz2/linux-64::intel-openmp-2018.0.0-h15fc484_7\n",
      "  - defaults/linux-64::intel-openmp-2018.0.0-h15fc484_7, https://repo.continuum.io/pkgs/main/linux-64/alabaster-0.7.10-py36h306e16b_0.tar.bz2/linux-64::alabaster-0.7.10-py36h306e16b_0, https://repo.continuum.io/pkgs/main/linux-64/boto-2.48.0-py36h6e4cd66_1.tar.bz2/linux-64::boto-2.48.0-py36h6e4cd66_1, https://repo.continuum.io/pkgs/main/linux-64/get_terminal_size-1.0.0-haa9412d_0.tar.bz2/linux-64::get_terminal_size-1.0.0-haa9412d_0\n",
      "  - defaults/linux-64::get_terminal_size-1.0.0-haa9412d_0, https://repo.continuum.io/pkgs/main/linux-64/alabaster-0.7.10-py36h306e16b_0.tar.bz2/linux-64::alabaster-0.7.10-py36h306e16b_0, https://repo.continuum.io/pkgs/main/linux-64/boto-2.48.0-py36h6e4cd66_1.tar.bz2/linux-64::boto-2.48.0-py36h6e4cd66_1, https://repo.continuum.io/pkgs/main/linux-64/intel-openmp-2018.0.0-h15fc484_7.tar.bz2/linux-64::intel-openmp-2018.0.0-h15fc484_7\n",
      "  - defaults/linux-64::get_terminal_size-1.0.0-haa9412d_0, defaults/linux-64::intel-openmp-2018.0.0-h15fc484_7, https://repo.continuum.io/pkgs/main/linux-64/alabaster-0.7.10-py36h306e16b_0.tar.bz2/linux-64::alabaster-0.7.10-py36h306e16b_0, https://repo.continuum.io/pkgs/main/linux-64/boto-2.48.0-py36h6e4cd66_1.tar.bz2/linux-64::boto-2.48.0-py36h6e4cd66_1\n",
      "  - defaults/linux-64::alabaster-0.7.10-py36h306e16b_0, defaults/linux-64::get_terminal_size-1.0.0-haa9412d_0, https://repo.continuum.io/pkgs/main/linux-64/boto-2.48.0-py36h6e4cd66_1.tar.bz2/linux-64::boto-2.48.0-py36h6e4cd66_1, https://repo.continuum.io/pkgs/main/linux-64/intel-openmp-2018.0.0-h15fc484_7.tar.bz2/linux-64::intel-openmp-2018.0.0-h15fc484_7\n",
      "  - defaults/linux-64::alabaster-0.7.10-py36h306e16b_0, defaults/linux-64::get_terminal_size-1.0.0-haa9412d_0, defaults/linux-64::intel-openmp-2018.0.0-h15fc484_7, https://repo.continuum.io/pkgs/main/linux-64/boto-2.48.0-py36h6e4cd66_1.tar.bz2/linux-64::boto-2.48.0-py36h6e4cd66_1\n",
      "  - defaults/linux-64::alabaster-0.7.10-py36h306e16b_0, https://repo.continuum.io/pkgs/main/linux-64/boto-2.48.0-py36h6e4cd66_1.tar.bz2/linux-64::boto-2.48.0-py36h6e4cd66_1, https://repo.continuum.io/pkgs/main/linux-64/get_terminal_size-1.0.0-haa9412d_0.tar.bz2/linux-64::get_terminal_size-1.0.0-haa9412d_0, https://repo.continuum.io/pkgs/main/linux-64/intel-openmp-2018.0.0-h15fc484_7.tar.bz2/linux-64::intel-openmp-2018.0.0-h15fc484_7\n",
      "  - defaults/linux-64::alabaster-0.7.10-py36h306e16b_0, defaults/linux-64::intel-openmp-2018.0.0-h15fc484_7, https://repo.continuum.io/pkgs/main/linux-64/boto-2.48.0-py36h6e4cd66_1.tar.bz2/linux-64::boto-2.48.0-py36h6e4cd66_1, https://repo.continuum.io/pkgs/main/linux-64/get_terminal_size-1.0.0-haa9412d_0.tar.bz2/linux-64::get_terminal_size-1.0.0-haa9412d_0\n",
      "  - defaults/linux-64::alabaster-0.7.10-py36h306e16b_0, defaults/linux-64::boto-2.48.0-py36h6e4cd66_1, https://repo.continuum.io/pkgs/main/linux-64/get_terminal_size-1.0.0-haa9412d_0.tar.bz2/linux-64::get_terminal_size-1.0.0-haa9412d_0, https://repo.continuum.io/pkgs/main/linux-64/intel-openmp-2018.0.0-h15fc484_7.tar.bz2/linux-64::intel-openmp-2018.0.0-h15fc484_7\n",
      "  - defaults/linux-64::boto-2.48.0-py36h6e4cd66_1, https://repo.continuum.io/pkgs/main/linux-64/alabaster-0.7.10-py36h306e16b_0.tar.bz2/linux-64::alabaster-0.7.10-py36h306e16b_0, https://repo.continuum.io/pkgs/main/linux-64/get_terminal_size-1.0.0-haa9412d_0.tar.bz2/linux-64::get_terminal_size-1.0.0-haa9412d_0, https://repo.continuum.io/pkgs/main/linux-64/intel-openmp-2018.0.0-h15fc484_7.tar.bz2/linux-64::intel-openmp-2018.0.0-h15fc484_7\n",
      "  ... and othersdone\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /.pyenv/versions/anaconda3-5.0.0\n",
      "\n",
      "  added / updated specs:\n",
      "    - cuda100\n",
      "    - pytorch==1.0.0\n",
      "    - torchvision==0.2.1\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _anaconda_depends-5.1.0    |           py36_2           5 KB\n",
      "    anaconda-custom            |           py36_1           3 KB\n",
      "    attrs-21.2.0               |     pyhd3eb1b0_0          44 KB\n",
      "    bzip2-1.0.8                |       h7b6447c_0         105 KB\n",
      "    ca-certificates-2021.7.5   |       h06a4308_1         119 KB\n",
      "    certifi-2021.5.30          |   py36h06a4308_0         141 KB\n",
      "    conda-4.10.3               |   py36h06a4308_0         3.1 MB\n",
      "    cuda100-1.0                |                0           2 KB  pytorch\n",
      "    importlib-metadata-3.10.0  |   py36h06a4308_0          33 KB\n",
      "    importlib_metadata-3.10.0  |       hd3eb1b0_0          11 KB\n",
      "    libcurl-7.61.1             |       heec0ca6_0         496 KB\n",
      "    ninja-1.8.2                |   py36h6bb024c_1         1.3 MB\n",
      "    openssl-1.0.2u             |       h7b6447c_0         3.1 MB\n",
      "    parso-0.8.2                |     pyhd3eb1b0_0          68 KB\n",
      "    pluggy-0.13.1              |   py36h06a4308_0          32 KB\n",
      "    pytorch-1.0.0              |py3.6_cuda10.0.130_cudnn7.4.1_1       657.4 MB  pytorch\n",
      "    send2trash-1.5.0           |     pyhd3eb1b0_1          14 KB\n",
      "    torchvision-0.2.1          |             py_2          37 KB  pytorch\n",
      "    typing_extensions-3.10.0.0 |     pyh06a4308_0          28 KB\n",
      "    zipp-3.5.0                 |     pyhd3eb1b0_0          12 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       666.1 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _anaconda_depends  pkgs/main/linux-64::_anaconda_depends-5.1.0-py36_2\n",
      "  attrs              pkgs/main/noarch::attrs-21.2.0-pyhd3eb1b0_0\n",
      "  bzip2              pkgs/main/linux-64::bzip2-1.0.8-h7b6447c_0\n",
      "  cuda100            pytorch/linux-64::cuda100-1.0-0\n",
      "  importlib-metadata pkgs/main/linux-64::importlib-metadata-3.10.0-py36h06a4308_0\n",
      "  importlib_metadata pkgs/main/noarch::importlib_metadata-3.10.0-hd3eb1b0_0\n",
      "  libcurl            pkgs/main/linux-64::libcurl-7.61.1-heec0ca6_0\n",
      "  ninja              pkgs/main/linux-64::ninja-1.8.2-py36h6bb024c_1\n",
      "  parso              pkgs/main/noarch::parso-0.8.2-pyhd3eb1b0_0\n",
      "  pluggy             pkgs/main/linux-64::pluggy-0.13.1-py36h06a4308_0\n",
      "  pytorch            pytorch/linux-64::pytorch-1.0.0-py3.6_cuda10.0.130_cudnn7.4.1_1\n",
      "  send2trash         pkgs/main/noarch::send2trash-1.5.0-pyhd3eb1b0_1\n",
      "  torchvision        pytorch/noarch::torchvision-0.2.1-py_2\n",
      "  typing_extensions  pkgs/main/noarch::typing_extensions-3.10.0.0-pyh06a4308_0\n",
      "  zipp               pkgs/main/noarch::zipp-3.5.0-pyhd3eb1b0_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                     2017.08.26-h1d4fec5_0 --> 2021.7.5-h06a4308_1\n",
      "  certifi                        2017.7.27.1-py36h8b7b77e_0 --> 2021.5.30-py36h06a4308_0\n",
      "  conda                        anaconda::conda-4.9.0-py36_0 --> pkgs/main::conda-4.10.3-py36h06a4308_0\n",
      "  openssl                                 1.0.2l-h9d1a558_3 --> 1.0.2u-h7b6447c_0\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  anaconda                           5.0.0.1-py36hfb0b618_1 --> custom-py36_1\n",
      "\n",
      "\n",
      "Proceed ([y]/n)? \n",
      "\n",
      "Downloading and Extracting Packages\n",
      "anaconda-custom      | 3 KB      | ########## | 100% \n",
      "parso-0.8.2          | 68 KB     | ########## | 100% \n",
      "importlib-metadata-3 | 33 KB     | ########## | 100% \n",
      "openssl-1.0.2u       | 3.1 MB    | ########## | 100% \n",
      "bzip2-1.0.8          | 105 KB    | ########## | 100% \n",
      "certifi-2021.5.30    | 141 KB    | ########## | 100% \n",
      "send2trash-1.5.0     | 14 KB     | ########## | 100% \n",
      "typing_extensions-3. | 28 KB     | ########## | 100% \n",
      "conda-4.10.3         | 3.1 MB    | ########## | 100% \n",
      "ninja-1.8.2          | 1.3 MB    | ########## | 100% \n",
      "_anaconda_depends-5. | 5 KB      | ########## | 100% \n",
      "pytorch-1.0.0        | 657.4 MB  | ########## | 100% \n",
      "ca-certificates-2021 | 119 KB    | ########## | 100% \n",
      "pluggy-0.13.1        | 32 KB     | ########## | 100% \n",
      "cuda100-1.0          | 2 KB      | ########## | 100% \n",
      "importlib_metadata-3 | 11 KB     | ########## | 100% \n",
      "zipp-3.5.0           | 12 KB     | ########## | 100% \n",
      "libcurl-7.61.1       | 496 KB    | ########## | 100% \n",
      "torchvision-0.2.1    | 37 KB     | ########## | 100% \n",
      "attrs-21.2.0         | 44 KB     | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Collecting torchtext==0.4.0\n",
      "  Downloading torchtext-0.4.0-py3-none-any.whl (53 kB)\n",
      "Requirement already satisfied: numpy in /.local/lib/python3.6/site-packages (from torchtext==0.4.0) (1.19.5)\n",
      "Requirement already satisfied: tqdm in /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages (from torchtext==0.4.0) (4.50.2)\n",
      "Requirement already satisfied: requests in /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages (from torchtext==0.4.0) (2.18.4)\n",
      "Requirement already satisfied: six in /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages (from torchtext==0.4.0) (1.10.0)\n",
      "Requirement already satisfied: torch in /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages (from torchtext==0.4.0) (1.0.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages (from requests->torchtext==0.4.0) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages (from requests->torchtext==0.4.0) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages (from requests->torchtext==0.4.0) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages (from requests->torchtext==0.4.0) (2021.5.30)\n",
      "Installing collected packages: torchtext\n",
      "Successfully installed torchtext-0.4.0\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mCollecting attrdict==2.0.1\n",
      "  Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
      "Requirement already satisfied: six in /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages (from attrdict==2.0.1) (1.10.0)\n",
      "Installing collected packages: attrdict\n",
      "Successfully installed attrdict-2.0.1\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mFound existing installation: numpy 1.19.5\n",
      "Uninstalling numpy-1.19.5:\n",
      "  Successfully uninstalled numpy-1.19.5\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mCollecting numpy==1.16.4\n",
      "  Downloading numpy-1.16.4-cp36-cp36m-manylinux1_x86_64.whl (17.3 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.13.1\n",
      "    Uninstalling numpy-1.13.1:\n",
      "      Successfully uninstalled numpy-1.13.1\n",
      "Successfully installed numpy-1.16.4\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mFound existing installation: gast 0.5.2\n",
      "Uninstalling gast-0.5.2:\n",
      "  Successfully uninstalled gast-0.5.2\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mCollecting gast==0.2.2\n",
      "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
      "Building wheels for collected packages: gast\n",
      "  Building wheel for gast (setup.py): started\n",
      "  Building wheel for gast (setup.py): finished with status 'done'\n",
      "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7636 sha256=23c50c2306a75d55c2f2e9c37736bd219db7394326fdbb4da6adefb83d3c4768\n",
      "  Stored in directory: /.cache/pip/wheels/19/a7/b9/0740c7a3a7d1d348f04823339274b90de25fbcd217b2ee1fbe\n",
      "Successfully built gast\n",
      "Installing collected packages: gast\n",
      "Successfully installed gast-0.2.2\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mCollecting gevent==1.4.0\n",
      "  Downloading gevent-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (5.5 MB)\n",
      "Collecting greenlet>=0.4.14\n",
      "  Downloading greenlet-1.1.1-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (140 kB)\n",
      "Installing collected packages: greenlet, gevent\n",
      "Successfully installed gevent-1.4.0 greenlet-1.1.1\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mCollecting gunicorn\n",
      "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "Requirement already satisfied: setuptools>=3.0 in /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages (from gunicorn) (50.3.0.post20201006)\n",
      "Installing collected packages: gunicorn\n",
      "Successfully installed gunicorn-20.1.0\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 0fc0d06baf1c\n",
      " ---> 5d94a0ac1fc5\n",
      "Step 21/32 : WORKDIR /opt/program\n",
      " ---> Running in e8dcadf42ba5\n",
      "Removing intermediate container e8dcadf42ba5\n",
      " ---> 9c91bc6c5f5f\n",
      "Step 22/32 : RUN git clone https://github.com/mack-the-psych/vdok3.git\n",
      " ---> Running in c27934380410\n",
      "\u001b[91mCloning into 'vdok3'...\n",
      "\u001b[0mRemoving intermediate container c27934380410\n",
      " ---> 9e1d3284468b\n",
      "Step 23/32 : RUN echo \"/opt/program/vdok3/prep\" > /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/vdok3-custom.pth\n",
      " ---> Running in 6698a864b6d8\n",
      "Removing intermediate container 6698a864b6d8\n",
      " ---> b9ef5d6f32ed\n",
      "Step 24/32 : RUN echo \"/opt/program/vdok3/extract\" >> /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/vdok3-custom.pth\n",
      " ---> Running in b33ecb50311a\n",
      "Removing intermediate container b33ecb50311a\n",
      " ---> ed3b292d0e77\n",
      "Step 25/32 : RUN echo \"/opt/program/vdok3/process\" >> /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/vdok3-custom.pth\n",
      " ---> Running in 702b80f1556a\n",
      "Removing intermediate container 702b80f1556a\n",
      " ---> 0da41942eca6\n",
      "Step 26/32 : RUN echo \"/opt/program/vdok3/reorganize\" >> /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/vdok3-custom.pth\n",
      " ---> Running in f92434d88d83\n",
      "Removing intermediate container f92434d88d83\n",
      " ---> ce0aab64eaf8\n",
      "Step 27/32 : RUN echo \"/opt/program/vdok3/train\" >> /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/vdok3-custom.pth\n",
      " ---> Running in 0011ff4eab47\n",
      "Removing intermediate container 0011ff4eab47\n",
      " ---> 3b7fa4f87f53\n",
      "Step 28/32 : RUN echo \"/opt/program/vdok3/train/pytorch_advanced/nlp_sentiment_bert\" >> /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/vdok3-custom.pth\n",
      " ---> Running in a24654c6e2ab\n",
      "Removing intermediate container a24654c6e2ab\n",
      " ---> 0da9f8e55dcf\n",
      "Step 29/32 : WORKDIR /opt/program/vdok3/train/pytorch_advanced/nlp_sentiment_bert\n",
      " ---> Running in 48217353005f\n",
      "Removing intermediate container 48217353005f\n",
      " ---> 85c4183b3e50\n",
      "Step 30/32 : RUN python make_folders_and_data_downloads.py\n",
      " ---> Running in 8fc9dfea2ac0\n",
      "Removing intermediate container 8fc9dfea2ac0\n",
      " ---> 2125e32b7b14\n",
      "Step 31/32 : COPY vdok3_sage /opt/program\n",
      " ---> c98ffad8dc2c\n",
      "Step 32/32 : WORKDIR /opt/program\n",
      " ---> Running in e4d3a3dc9f64\n",
      "Removing intermediate container e4d3a3dc9f64\n",
      " ---> 7d8ab090f8e3\n",
      "Successfully built 7d8ab090f8e3\n",
      "Successfully tagged sagemaker-vdok3-bert-cv-def:latest\n",
      "The push refers to repository [822408253028.dkr.ecr.us-west-2.amazonaws.com/sagemaker-vdok3-bert-cv-def]\n",
      "4c7f538fbd20: Preparing\n",
      "eb94f24f5ad7: Preparing\n",
      "be23f8a4ed08: Preparing\n",
      "2333bf2d8c34: Preparing\n",
      "bcf0b9fb86f7: Preparing\n",
      "d1c87b4917ba: Preparing\n",
      "1379185bec41: Preparing\n",
      "34c09c07d44f: Preparing\n",
      "8da672bd8fef: Preparing\n",
      "301342a5ac2c: Preparing\n",
      "3ac2454fe7ca: Preparing\n",
      "9b9ef40c3fb2: Preparing\n",
      "49fa2998b485: Preparing\n",
      "72400ed43881: Preparing\n",
      "97e5b4ec388b: Preparing\n",
      "b20c62adb3cf: Preparing\n",
      "bf18a6c0e470: Preparing\n",
      "0de0186b0e0f: Preparing\n",
      "d152753df06e: Preparing\n",
      "653349137921: Preparing\n",
      "e71e95da3d2b: Preparing\n",
      "6d2269456418: Preparing\n",
      "521a1bca4c9e: Preparing\n",
      "0fd113e52582: Preparing\n",
      "9fd67b1e1831: Preparing\n",
      "f1c9680a678d: Preparing\n",
      "fa4b3468268c: Preparing\n",
      "66ad31b9547f: Preparing\n",
      "8d897fc1271a: Preparing\n",
      "b0c360818224: Preparing\n",
      "d35aa7fd29b6: Preparing\n",
      "c0eeb6e15fd7: Preparing\n",
      "91cba8fa7129: Preparing\n",
      "d152753df06e: Waiting\n",
      "653349137921: Waiting\n",
      "e71e95da3d2b: Waiting\n",
      "6d2269456418: Waiting\n",
      "521a1bca4c9e: Waiting\n",
      "0fd113e52582: Waiting\n",
      "9fd67b1e1831: Waiting\n",
      "f1c9680a678d: Waiting\n",
      "fa4b3468268c: Waiting\n",
      "66ad31b9547f: Waiting\n",
      "8d897fc1271a: Waiting\n",
      "b0c360818224: Waiting\n",
      "d35aa7fd29b6: Waiting\n",
      "c0eeb6e15fd7: Waiting\n",
      "91cba8fa7129: Waiting\n",
      "d1c87b4917ba: Waiting\n",
      "1379185bec41: Waiting\n",
      "34c09c07d44f: Waiting\n",
      "8da672bd8fef: Waiting\n",
      "301342a5ac2c: Waiting\n",
      "3ac2454fe7ca: Waiting\n",
      "9b9ef40c3fb2: Waiting\n",
      "49fa2998b485: Waiting\n",
      "72400ed43881: Waiting\n",
      "97e5b4ec388b: Waiting\n",
      "b20c62adb3cf: Waiting\n",
      "bf18a6c0e470: Waiting\n",
      "0de0186b0e0f: Waiting\n",
      "2333bf2d8c34: Pushed\n",
      "bcf0b9fb86f7: Pushed\n",
      "be23f8a4ed08: Pushed\n",
      "4c7f538fbd20: Pushed\n",
      "1379185bec41: Pushed\n",
      "34c09c07d44f: Pushed\n",
      "d1c87b4917ba: Pushed\n",
      "9b9ef40c3fb2: Pushed\n",
      "8da672bd8fef: Pushed\n",
      "49fa2998b485: Pushed\n",
      "97e5b4ec388b: Pushed\n",
      "b20c62adb3cf: Pushed\n",
      "bf18a6c0e470: Pushed\n",
      "72400ed43881: Pushed\n",
      "3ac2454fe7ca: Pushed\n",
      "d152753df06e: Pushed\n",
      "eb94f24f5ad7: Pushed\n",
      "6d2269456418: Pushed\n",
      "653349137921: Pushed\n",
      "0fd113e52582: Pushed\n",
      "e71e95da3d2b: Pushed\n",
      "f1c9680a678d: Pushed\n",
      "fa4b3468268c: Pushed\n",
      "66ad31b9547f: Pushed\n",
      "9fd67b1e1831: Pushed\n",
      "8d897fc1271a: Pushed\n",
      "b0c360818224: Pushed\n",
      "d35aa7fd29b6: Pushed\n",
      "c0eeb6e15fd7: Pushed\n",
      "91cba8fa7129: Pushed\n",
      "521a1bca4c9e: Pushed\n",
      "301342a5ac2c: Pushed\n",
      "0de0186b0e0f: Pushed\n",
      "latest: digest: sha256:2a1a3944d02ec80d1da40ab1b9d6c08b5c0252be818327cc01b3b9255ed3dd10 size: 7229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 137 ms, sys: 32.2 ms, total: 170 ms\n",
      "Wall time: 22min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "# Makoto.Sano@Mack-the-Psych.com\n",
    "algorithm_name=sagemaker-vdok3-bert-cv-def\n",
    "\n",
    "cd container\n",
    "\n",
    "chmod +x vdok3_sage/train\n",
    "chmod +x vdok3_sage/serve\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build  -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "# Makoto.Sano@Mack-the-Psych.com\n",
    "prefix = 'vdok3_bert_cv_def'\n",
    "\n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sess = sage.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIRECTORY = 'data'\n",
    "\n",
    "data_location = sess.upload_data(WORK_DIRECTORY, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-17 01:35:50 Starting - Starting the training job...\n",
      "2021-08-17 01:35:54 Starting - Launching requested ML instancesProfilerReport-1629164150: InProgress\n",
      "......\n",
      "2021-08-17 01:37:11 Starting - Preparing the instances for training......\n",
      "2021-08-17 01:38:19 Downloading - Downloading input data...\n",
      "2021-08-17 01:38:51 Training - Downloading the training image........................\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34mStarting the training.\u001b[0m\n",
      "\u001b[34mbert.embeddings.word_embeddings.weightembeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.position_embeddings.weightembeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.token_type_embeddings.weightembeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.gammaembeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.betaembeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.weightencoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.biasencoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.weightencoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.biasencoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.weightencoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.biasencoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.weightencoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.biasencoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.gammaencoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.betaencoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.weightencoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.biasencoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.weightencoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.biasencoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.gammaencoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.betaencoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.weightencoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.biasencoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.weightencoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.biasencoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.weightencoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.biasencoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.weightencoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.biasencoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.gammaencoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.betaencoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.weightencoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.biasencoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.weightencoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.biasencoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.gammaencoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.betaencoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.weightencoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.biasencoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.weightencoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.biasencoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.weightencoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.biasencoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.weightencoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.biasencoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.gammaencoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.betaencoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.weightencoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.biasencoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.weightencoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.biasencoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.gammaencoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.betaencoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.weightencoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.biasencoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.weightencoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.biasencoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.weightencoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.biasencoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.weightencoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.biasencoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.gammaencoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.betaencoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.weightencoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.biasencoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.weightencoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.biasencoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.gammaencoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.betaencoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.weightencoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.biasencoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.weightencoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.biasencoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.weightencoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.biasencoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.weightencoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.biasencoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.gammaencoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.betaencoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.weightencoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.biasencoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.weightencoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.biasencoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.gammaencoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.betaencoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.weightencoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.biasencoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.weightencoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.biasencoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.weightencoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.biasencoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.weightencoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.biasencoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.gammaencoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.betaencoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.weightencoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.biasencoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.weightencoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.biasencoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.gammaencoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.betaencoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.weightencoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.biasencoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.weightencoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.biasencoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.weightencoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.biasencoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.weightencoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.biasencoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.gammaencoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.betaencoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.weightencoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.biasencoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.weightencoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.biasencoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.gammaencoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.betaencoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.weightencoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.biasencoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.weightencoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.biasencoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.weightencoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.biasencoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.weightencoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.biasencoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.gammaencoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.betaencoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.weightencoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.biasencoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.weightencoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.biasencoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.gammaencoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.betaencoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.weightencoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.biasencoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.weightencoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.biasencoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.weightencoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.biasencoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.weightencoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.biasencoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.gammaencoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.betaencoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.weightencoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.biasencoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.weightencoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.biasencoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.gammaencoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.betaencoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.weightencoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.biasencoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.weightencoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.biasencoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.weightencoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.biasencoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.weightencoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.biasencoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.gammaencoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.betaencoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.weightencoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.biasencoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.weightencoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.biasencoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.gammaencoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.betaencoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.weightencoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.biasencoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.weightencoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.biasencoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.weightencoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.biasencoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.weightencoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.biasencoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.gammaencoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.betaencoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.weightencoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.biasencoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.weightencoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.biasencoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.gammaencoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.betaencoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.weightencoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.biasencoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.weightencoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.biasencoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.weightencoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.biasencoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.weightencoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.biasencoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.gammaencoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.betaencoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.weightencoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.biasencoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.weightencoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.biasencoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.gammaencoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.betaencoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.weightpooler.dense.weight\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.biaspooler.dense.bias\u001b[0m\n",
      "\u001b[34m----------------\u001b[0m\n",
      "\u001b[34mRANDOM SET:  0\u001b[0m\n",
      "\u001b[34mConcat Value Len: 5084\u001b[0m\n",
      "\u001b[34m(tensor([[ 101, 2129, 2057,  ...,    0,    0,    0],\n",
      "        [ 101, 2043, 2019,  ...,    0,    0,    0],\n",
      "        [ 101, 1996, 2801,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1037, 2711,  ...,    0,    0,    0],\n",
      "        [ 101, 2000, 2817,  ...,    0,    0,    0],\n",
      "        [ 101, 2129, 2057,  ...,    0,    0,    0]]), tensor([16, 34, 18, 20, 19, 20, 20, 10, 10, 19, 12, 16, 11, 18, 18, 11, 14, 24,\n",
      "        13, 16, 11, 16, 16, 19, 13, 13, 12, 22, 20, 20, 10, 23]))\u001b[0m\n",
      "\u001b[34mtensor([0, 2, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0])\u001b[0m\n",
      "\u001b[34m['[CLS]', 'when', 'an', 'animal', 'moves', 'from', 'one', 'place', 'to', 'another', ',', 'usually', 'following', 'the', 'seasons', '.', 'to', 'go', 'from', 'one', 'country', ',', 'region', ',', 'or', 'place', 'to', 'another', '.', 'to', 'travel', 'someplace', 'far', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34mUsing device:  cuda:0\u001b[0m\n",
      "\u001b[34m-----start-------\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.8285 || 10iter: 0.9354 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.5193 || 10iter: 0.8789 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.6915 || 10iter: 0.8796 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.5683 || 10iter: 0.8802 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.5471 || 10iter: 0.8798 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.6741 || 10iter: 0.8846 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.5430 || 10iter: 0.8808 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.4368 || 10iter: 0.8810 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.4601 || 10iter: 0.8825 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.4691 || 10iter: 0.8836 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1948 || 10iter: 0.8824 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.3754 || 10iter: 0.8829 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mEpoch 1/10 | train |  Loss: 0.4948 Acc: 0.8257\u001b[0m\n",
      "\u001b[34mEpoch 1/10 |  val  |  Loss: 0.2993 Acc: 0.8653\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.5313 || 10iter: 0.8875 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.2515 || 10iter: 0.8808 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.3624 || 10iter: 0.8823 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.4049 || 10iter: 0.8818 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.4048 || 10iter: 0.8845 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2254 || 10iter: 0.8883 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.3122 || 10iter: 0.8828 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.4330 || 10iter: 0.8850 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1495 || 10iter: 0.8833 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2026 || 10iter: 0.8843 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.3296 || 10iter: 0.8852 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.3038 || 10iter: 0.8859 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mEpoch 2/10 | train |  Loss: 0.3197 Acc: 0.8594\u001b[0m\n",
      "\u001b[34mEpoch 2/10 |  val  |  Loss: 0.2774 Acc: 0.8692\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.2256 || 10iter: 0.8910 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.3802 || 10iter: 0.8837 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1583 || 10iter: 0.8861 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.4551 || 10iter: 0.8847 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.4612 || 10iter: 0.8845 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.3267 || 10iter: 0.8844 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1957 || 10iter: 0.8852 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.2298 || 10iter: 0.8872 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1944 || 10iter: 0.8873 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2781 || 10iter: 0.8855 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1868 || 10iter: 0.8868 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.3152 || 10iter: 0.8859 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mEpoch 3/10 | train |  Loss: 0.2843 Acc: 0.8773\u001b[0m\n",
      "\u001b[34mEpoch 3/10 |  val  |  Loss: 0.2390 Acc: 0.8928\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.2879 || 10iter: 0.8936 sec. || Accuracy: 0.875\u001b[0m\n",
      "\n",
      "2021-08-17 01:43:52 Training - Training image download completed. Training in progress.\u001b[34mIteration 20 || Loss: 0.3201 || 10iter: 0.8872 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.2368 || 10iter: 0.8884 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.0769 || 10iter: 0.8884 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.2148 || 10iter: 0.8893 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.3999 || 10iter: 0.8878 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1895 || 10iter: 0.8919 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.3491 || 10iter: 0.8899 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1804 || 10iter: 0.8955 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2225 || 10iter: 0.8892 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.3803 || 10iter: 0.8899 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1969 || 10iter: 0.8926 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mEpoch 4/10 | train |  Loss: 0.2538 Acc: 0.8894\u001b[0m\n",
      "\u001b[34mEpoch 4/10 |  val  |  Loss: 0.2342 Acc: 0.8899\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.2543 || 10iter: 0.8952 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1969 || 10iter: 0.8894 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.2176 || 10iter: 0.8905 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.3921 || 10iter: 0.8912 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.2953 || 10iter: 0.8951 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2846 || 10iter: 0.8945 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.2482 || 10iter: 0.8920 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.2126 || 10iter: 0.8920 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1457 || 10iter: 0.8934 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2071 || 10iter: 0.8940 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.2550 || 10iter: 0.8970 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0624 || 10iter: 0.9049 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 5/10 | train |  Loss: 0.2429 Acc: 0.8938\u001b[0m\n",
      "\u001b[34mEpoch 5/10 |  val  |  Loss: 0.2291 Acc: 0.8938\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0777 || 10iter: 0.8980 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1688 || 10iter: 0.8937 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.2550 || 10iter: 0.8916 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.2354 || 10iter: 0.8913 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.3409 || 10iter: 0.8924 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.1296 || 10iter: 0.8931 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.2213 || 10iter: 0.8922 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.2002 || 10iter: 0.8950 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1246 || 10iter: 0.8938 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2246 || 10iter: 0.8925 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1902 || 10iter: 0.8929 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1055 || 10iter: 0.8932 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mEpoch 6/10 | train |  Loss: 0.2241 Acc: 0.9039\u001b[0m\n",
      "\u001b[34mEpoch 6/10 |  val  |  Loss: 0.1990 Acc: 0.9194\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1881 || 10iter: 0.8992 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1209 || 10iter: 0.8952 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.2213 || 10iter: 0.8947 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1992 || 10iter: 0.8950 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.5065 || 10iter: 0.8944 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.1120 || 10iter: 0.8953 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1058 || 10iter: 0.8946 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1975 || 10iter: 0.8968 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.2479 || 10iter: 0.8964 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2395 || 10iter: 0.8976 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.2766 || 10iter: 0.8948 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1526 || 10iter: 0.8948 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mEpoch 7/10 | train |  Loss: 0.2119 Acc: 0.9098\u001b[0m\n",
      "\u001b[34mEpoch 7/10 |  val  |  Loss: 0.2034 Acc: 0.9076\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1748 || 10iter: 0.9009 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1705 || 10iter: 0.8977 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1037 || 10iter: 0.8982 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1107 || 10iter: 0.8992 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1223 || 10iter: 0.8962 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0624 || 10iter: 0.8958 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1688 || 10iter: 0.8959 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.0892 || 10iter: 0.8981 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1996 || 10iter: 0.8958 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2253 || 10iter: 0.8970 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1527 || 10iter: 0.8967 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.2280 || 10iter: 0.8971 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mEpoch 8/10 | train |  Loss: 0.1902 Acc: 0.9230\u001b[0m\n",
      "\u001b[34mEpoch 8/10 |  val  |  Loss: 0.1949 Acc: 0.9194\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.2354 || 10iter: 0.9018 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0339 || 10iter: 0.8966 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1751 || 10iter: 0.8994 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1858 || 10iter: 0.8991 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1135 || 10iter: 0.9033 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0973 || 10iter: 0.9038 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.2428 || 10iter: 0.9034 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.2183 || 10iter: 0.9039 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.0959 || 10iter: 0.8967 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2949 || 10iter: 0.8987 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.2657 || 10iter: 0.8994 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1414 || 10iter: 0.8998 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mEpoch 9/10 | train |  Loss: 0.1788 Acc: 0.9267\u001b[0m\n",
      "\u001b[34mEpoch 9/10 |  val  |  Loss: 0.2074 Acc: 0.9056\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.3276 || 10iter: 0.9054 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.2401 || 10iter: 0.8989 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.4040 || 10iter: 0.8987 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.0789 || 10iter: 0.8982 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1000 || 10iter: 0.8990 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2607 || 10iter: 0.8985 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1643 || 10iter: 0.8986 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1282 || 10iter: 0.9005 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1464 || 10iter: 0.9004 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1183 || 10iter: 0.9005 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.2025 || 10iter: 0.8974 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1202 || 10iter: 0.8984 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 10/10 | train |  Loss: 0.1763 Acc: 0.9250\u001b[0m\n",
      "\u001b[34mEpoch 10/10 |  val  |  Loss: 0.2165 Acc: 0.8968\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/53 [00:00<?, ?it/s]#015  4%|         | 2/53 [00:00<00:04, 12.31it/s]#015  8%|         | 4/53 [00:00<00:03, 12.30it/s]#015 11%|        | 6/53 [00:00<00:03, 12.29it/s]#015 15%|        | 8/53 [00:00<00:03, 12.27it/s]#015 19%|        | 10/53 [00:00<00:03, 12.26it/s]#015 23%|       | 12/53 [00:00<00:03, 12.25it/s]#015 26%|       | 14/53 [00:01<00:03, 12.25it/s]#015 30%|       | 16/53 [00:01<00:03, 12.24it/s]#015 34%|      | 18/53 [00:01<00:02, 12.22it/s]#015 38%|      | 20/53 [00:01<00:02, 12.22it/s]#015 42%|     | 22/53 [00:01<00:02, 12.20it/s]#015 45%|     | 24/53 [00:01<00:02, 12.19it/s]#015 49%|     | 26/53 [00:02<00:02, 12.20it/s]#015 53%|    | 28/53 [00:02<00:02, 12.22it/s]#015 57%|    | 30/53 [00:02<00:01, 12.22it/s]#015 60%|    | 32/53 [00:02<00:01, 12.20it/s]#015 64%|   | 34/53 [00:02<00:01, 12.20it/s]#015 68%|   | 36/53 [00:02<00:01, 12.20it/s]#015 72%|  | 38/53 [00:03<00:01, 12.19it/s]#015 75%|  | 40/53 [00:03<00:01, 12.21it/s]#015 79%|  | 42/53 [00:03<00:00, 12.20it/s]#015 83%| | 44/53 [00:03<00:00, 12.20it/s]#015 87%| | 46/53 [00:03<00:00, 12.20it/s]#015 91%| | 48/53 [00:03<00:00, 12.19it/s]#015 94%|| 50/53 [00:04<00:00, 12.19it/s]#015 98%|| 52/53 [00:04<00:00, 12.18it/s]#015100%|| 53/53 [00:04<00:00, 12.23it/s]\u001b[0m\n",
      "\u001b[34mTest Data 1694 Accuracy: 0.9085\u001b[0m\n",
      "\u001b[34mRecall                      0.9085\u001b[0m\n",
      "\u001b[34mPrecision                   0.9248\u001b[0m\n",
      "\u001b[34mF1                          0.9142\u001b[0m\n",
      "\u001b[34mKappa                       0.7386\u001b[0m\n",
      "\u001b[34mQuadratic Weighted Kappa    0.8100\u001b[0m\n",
      "\u001b[34mdtype: float64\u001b[0m\n",
      "\u001b[34mConfusion Matrix:\n",
      "      0    1    2\u001b[0m\n",
      "\u001b[34m0  1286   72   25\u001b[0m\n",
      "\u001b[34m1    14  148   22\u001b[0m\n",
      "\u001b[34m2     3   19  105\u001b[0m\n",
      "\u001b[34m----------------\u001b[0m\n",
      "\u001b[34mRANDOM SET:  1\u001b[0m\n",
      "\u001b[34mConcat Value Len: 5084\u001b[0m\n",
      "\u001b[34m(tensor([[ 101, 2129, 2057,  ...,    0,    0,    0],\n",
      "        [ 101, 2000, 2202,  ...,    0,    0,    0],\n",
      "        [ 101, 2009, 2965,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1037, 2711,  ...,    0,    0,    0],\n",
      "        [ 101, 2000, 2817,  ...,    0,    0,    0],\n",
      "        [ 101, 2129, 2057,  ...,    0,    0,    0]]), tensor([16, 14, 14, 20, 19, 11, 20, 10, 10, 14, 12, 16, 12, 32, 12, 11, 14, 14,\n",
      "        13, 19, 11, 15, 16, 19, 13, 13, 12, 22, 20, 20, 10, 23]))\u001b[0m\n",
      "\u001b[34mtensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0])\u001b[0m\n",
      "\u001b[34m['[CLS]', 'to', 'take', 'care', 'of', 'or', 'make', 'decisions', 'about', 'something', '.', 'd', '##k', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34mUsing device:  cuda:0\u001b[0m\n",
      "\u001b[34m-----start-------\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.6952 || 10iter: 0.8978 sec. || Accuracy: 0.6875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.2940 || 10iter: 0.9000 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1162 || 10iter: 0.8956 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.3104 || 10iter: 0.8958 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.3219 || 10iter: 0.8946 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.1928 || 10iter: 0.8955 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.2612 || 10iter: 0.9006 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.2376 || 10iter: 0.8958 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.2125 || 10iter: 0.8957 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2684 || 10iter: 0.8948 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1470 || 10iter: 0.8965 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.2506 || 10iter: 0.8942 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mEpoch 1/10 | train |  Loss: 0.2477 Acc: 0.9002\u001b[0m\n",
      "\u001b[34mEpoch 1/10 |  val  |  Loss: 0.2232 Acc: 0.9115\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.2100 || 10iter: 0.9084 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0603 || 10iter: 0.9023 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.2573 || 10iter: 0.9014 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.2370 || 10iter: 0.9025 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1686 || 10iter: 0.9058 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2220 || 10iter: 0.9089 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1839 || 10iter: 0.9067 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.2690 || 10iter: 0.9075 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.0385 || 10iter: 0.9024 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1678 || 10iter: 0.9064 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1937 || 10iter: 0.9023 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.2557 || 10iter: 0.9018 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mEpoch 2/10 | train |  Loss: 0.1858 Acc: 0.9265\u001b[0m\n",
      "\u001b[34mEpoch 2/10 |  val  |  Loss: 0.1983 Acc: 0.9154\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0625 || 10iter: 0.9130 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.2199 || 10iter: 0.9089 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0631 || 10iter: 0.9040 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.2881 || 10iter: 0.9100 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.2017 || 10iter: 0.9044 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0653 || 10iter: 0.9027 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1528 || 10iter: 0.9045 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.0644 || 10iter: 0.9078 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.0754 || 10iter: 0.9096 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2545 || 10iter: 0.9029 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1883 || 10iter: 0.9033 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0986 || 10iter: 0.9042 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mEpoch 3/10 | train |  Loss: 0.1727 Acc: 0.9319\u001b[0m\n",
      "\u001b[34mEpoch 3/10 |  val  |  Loss: 0.1925 Acc: 0.9312\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0799 || 10iter: 0.9086 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0601 || 10iter: 0.9025 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1994 || 10iter: 0.9070 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.0411 || 10iter: 0.9023 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0691 || 10iter: 0.9039 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.3577 || 10iter: 0.9028 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0878 || 10iter: 0.9027 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1314 || 10iter: 0.9048 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1404 || 10iter: 0.9054 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1010 || 10iter: 0.9059 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1637 || 10iter: 0.9050 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.2475 || 10iter: 0.9047 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mEpoch 4/10 | train |  Loss: 0.1591 Acc: 0.9366\u001b[0m\n",
      "\u001b[34mEpoch 4/10 |  val  |  Loss: 0.2048 Acc: 0.9135\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1592 || 10iter: 0.9106 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1458 || 10iter: 0.9093 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0895 || 10iter: 0.9052 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.4152 || 10iter: 0.9057 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.2972 || 10iter: 0.9064 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2247 || 10iter: 0.9094 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1855 || 10iter: 0.9053 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1254 || 10iter: 0.9063 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.0568 || 10iter: 0.9056 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2297 || 10iter: 0.9050 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1990 || 10iter: 0.9043 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0821 || 10iter: 0.9049 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 5/10 | train |  Loss: 0.1521 Acc: 0.9375\u001b[0m\n",
      "\u001b[34mEpoch 5/10 |  val  |  Loss: 0.2042 Acc: 0.9253\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0702 || 10iter: 0.9084 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0468 || 10iter: 0.9054 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.2861 || 10iter: 0.9035 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1481 || 10iter: 0.9047 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.2729 || 10iter: 0.9046 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.1739 || 10iter: 0.9052 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1071 || 10iter: 0.9032 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.2156 || 10iter: 0.9042 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1318 || 10iter: 0.9037 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2243 || 10iter: 0.9099 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0899 || 10iter: 0.9068 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0805 || 10iter: 0.9050 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 6/10 | train |  Loss: 0.1400 Acc: 0.9484\u001b[0m\n",
      "\u001b[34mEpoch 6/10 |  val  |  Loss: 0.2074 Acc: 0.9243\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0634 || 10iter: 0.9147 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0755 || 10iter: 0.9049 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.2565 || 10iter: 0.9064 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1985 || 10iter: 0.9106 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1638 || 10iter: 0.9131 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2694 || 10iter: 0.9032 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0334 || 10iter: 0.9036 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.0656 || 10iter: 0.9040 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1407 || 10iter: 0.9031 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.3332 || 10iter: 0.9045 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0717 || 10iter: 0.9039 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0262 || 10iter: 0.9034 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mEpoch 7/10 | train |  Loss: 0.1332 Acc: 0.9496\u001b[0m\n",
      "\u001b[34mEpoch 7/10 |  val  |  Loss: 0.2065 Acc: 0.9233\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1295 || 10iter: 0.9098 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0626 || 10iter: 0.9060 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0506 || 10iter: 0.9039 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1595 || 10iter: 0.9044 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0521 || 10iter: 0.9055 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.1299 || 10iter: 0.9044 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0553 || 10iter: 0.9046 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.0390 || 10iter: 0.9044 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1115 || 10iter: 0.9042 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1447 || 10iter: 0.9038 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0346 || 10iter: 0.9045 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1578 || 10iter: 0.9074 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mEpoch 8/10 | train |  Loss: 0.1296 Acc: 0.9511\u001b[0m\n",
      "\u001b[34mEpoch 8/10 |  val  |  Loss: 0.2161 Acc: 0.9282\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1816 || 10iter: 0.9087 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0328 || 10iter: 0.9050 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0563 || 10iter: 0.9041 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1600 || 10iter: 0.9079 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0916 || 10iter: 0.9075 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0336 || 10iter: 0.9056 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0525 || 10iter: 0.9047 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.0364 || 10iter: 0.9040 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.0529 || 10iter: 0.9033 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1335 || 10iter: 0.9037 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0365 || 10iter: 0.9035 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1205 || 10iter: 0.9036 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mEpoch 9/10 | train |  Loss: 0.1137 Acc: 0.9589\u001b[0m\n",
      "\u001b[34mEpoch 9/10 |  val  |  Loss: 0.2331 Acc: 0.9135\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1318 || 10iter: 0.9091 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0667 || 10iter: 0.9038 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1580 || 10iter: 0.9036 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.0050 || 10iter: 0.9034 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0312 || 10iter: 0.9034 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.1787 || 10iter: 0.9032 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0965 || 10iter: 0.9033 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.0618 || 10iter: 0.9032 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1122 || 10iter: 0.9035 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0095 || 10iter: 0.9032 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1305 || 10iter: 0.9030 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1500 || 10iter: 0.9040 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 10/10 | train |  Loss: 0.1148 Acc: 0.9555\u001b[0m\n",
      "\u001b[34mEpoch 10/10 |  val  |  Loss: 0.2723 Acc: 0.9066\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/53 [00:00<?, ?it/s]#015  4%|         | 2/53 [00:00<00:04, 12.27it/s]#015  8%|         | 4/53 [00:00<00:03, 12.26it/s]#015 11%|        | 6/53 [00:00<00:03, 12.24it/s]#015 15%|        | 8/53 [00:00<00:03, 12.23it/s]#015 19%|        | 10/53 [00:00<00:03, 12.20it/s]#015 23%|       | 12/53 [00:00<00:03, 12.18it/s]#015 26%|       | 14/53 [00:01<00:03, 12.17it/s]#015 30%|       | 16/53 [00:01<00:03, 12.17it/s]#015 34%|      | 18/53 [00:01<00:02, 12.16it/s]#015 38%|      | 20/53 [00:01<00:02, 12.16it/s]#015 42%|     | 22/53 [00:01<00:02, 12.15it/s]#015 45%|     | 24/53 [00:01<00:02, 12.14it/s]#015 49%|     | 26/53 [00:02<00:02, 12.15it/s]#015 53%|    | 28/53 [00:02<00:02, 12.14it/s]#015 57%|    | 30/53 [00:02<00:01, 12.13it/s]#015 60%|    | 32/53 [00:02<00:01, 12.13it/s]#015 64%|   | 34/53 [00:02<00:01, 12.11it/s]#015 68%|   | 36/53 [00:02<00:01, 12.11it/s]#015 72%|  | 38/53 [00:03<00:01, 12.11it/s]#015 75%|  | 40/53 [00:03<00:01, 12.12it/s]#015 79%|  | 42/53 [00:03<00:00, 12.11it/s]#015 83%| | 44/53 [00:03<00:00, 12.11it/s]#015 87%| | 46/53 [00:03<00:00, 12.11it/s]#015 91%| | 48/53 [00:03<00:00, 12.11it/s]#015 94%|| 50/53 [00:04<00:00, 12.08it/s]#015 98%|| 52/53 [00:04<00:00, 12.09it/s]#015100%|| 53/53 [00:04<00:00, 12.15it/s]\u001b[0m\n",
      "\u001b[34mTest Data 1694 Accuracy: 0.9268\u001b[0m\n",
      "\u001b[34mRecall                      0.9268\u001b[0m\n",
      "\u001b[34mPrecision                   0.9372\u001b[0m\n",
      "\u001b[34mF1                          0.9300\u001b[0m\n",
      "\u001b[34mKappa                       0.7906\u001b[0m\n",
      "\u001b[34mQuadratic Weighted Kappa    0.8404\u001b[0m\n",
      "\u001b[34mdtype: float64\u001b[0m\n",
      "\u001b[34mConfusion Matrix:\n",
      "      0    1    2\u001b[0m\n",
      "\u001b[34m0  1295   58   23\u001b[0m\n",
      "\u001b[34m1    12  157   24\u001b[0m\n",
      "\u001b[34m2     4    3  118\u001b[0m\n",
      "\u001b[34m----------------\u001b[0m\n",
      "\u001b[34mRANDOM SET:  2\u001b[0m\n",
      "\u001b[34mConcat Value Len: 5084\u001b[0m\n",
      "\u001b[34m(tensor([[ 101, 1996, 2801,  ...,    0,    0,    0],\n",
      "        [ 101, 2000, 2202,  ...,    0,    0,    0],\n",
      "        [ 101, 2009, 2965,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1037, 2711,  ...,    0,    0,    0],\n",
      "        [ 101, 1037, 2711,  ...,    0,    0,    0],\n",
      "        [ 101, 2619, 2017,  ...,    0,    0,    0]]), tensor([17, 14, 14, 20, 14, 11, 20, 16, 18, 14, 14, 15, 12, 32, 12, 11, 14, 14,\n",
      "        11, 19, 11, 15, 16, 19, 13, 23, 12, 15, 20, 20, 21, 22]))\u001b[0m\n",
      "\u001b[34mtensor([0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 2, 0, 2, 0, 1, 1, 1])\u001b[0m\n",
      "\u001b[34m['[CLS]', 'to', 'take', 'care', 'of', 'or', 'make', 'decisions', 'about', 'something', '.', 'd', '##k', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34mUsing device:  cuda:0\u001b[0m\n",
      "\u001b[34m-----start-------\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.4325 || 10iter: 0.9007 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.2222 || 10iter: 0.9003 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.2886 || 10iter: 0.9000 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1275 || 10iter: 0.8995 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1548 || 10iter: 0.9006 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0475 || 10iter: 0.9002 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.2390 || 10iter: 0.9000 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1295 || 10iter: 0.8997 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1815 || 10iter: 0.9010 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2298 || 10iter: 0.9008 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1403 || 10iter: 0.9018 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1440 || 10iter: 0.9014 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mEpoch 1/10 | train |  Loss: 0.2055 Acc: 0.9225\u001b[0m\n",
      "\u001b[34mEpoch 1/10 |  val  |  Loss: 0.2057 Acc: 0.9213\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.2180 || 10iter: 0.9074 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1225 || 10iter: 0.9018 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1330 || 10iter: 0.9025 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1284 || 10iter: 0.9027 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0672 || 10iter: 0.9037 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2171 || 10iter: 0.9063 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0104 || 10iter: 0.9085 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.3957 || 10iter: 0.9092 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1012 || 10iter: 0.9055 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0387 || 10iter: 0.9044 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1269 || 10iter: 0.9055 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1575 || 10iter: 0.9028 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 2/10 | train |  Loss: 0.1350 Acc: 0.9489\u001b[0m\n",
      "\u001b[34mEpoch 2/10 |  val  |  Loss: 0.2021 Acc: 0.9243\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0859 || 10iter: 0.9091 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0521 || 10iter: 0.9030 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0856 || 10iter: 0.9026 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.2709 || 10iter: 0.9027 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1659 || 10iter: 0.9019 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0485 || 10iter: 0.9031 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.2554 || 10iter: 0.9023 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.0451 || 10iter: 0.9026 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1557 || 10iter: 0.9025 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0850 || 10iter: 0.9028 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1048 || 10iter: 0.9072 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0647 || 10iter: 0.9049 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 3/10 | train |  Loss: 0.1313 Acc: 0.9516\u001b[0m\n",
      "\u001b[34mEpoch 3/10 |  val  |  Loss: 0.2240 Acc: 0.9184\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1563 || 10iter: 0.9123 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0324 || 10iter: 0.9031 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0675 || 10iter: 0.9047 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.0313 || 10iter: 0.9042 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0325 || 10iter: 0.9071 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2848 || 10iter: 0.9101 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0915 || 10iter: 0.9097 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1076 || 10iter: 0.9204 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.0789 || 10iter: 0.9062 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0500 || 10iter: 0.9072 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0793 || 10iter: 0.9055 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.3093 || 10iter: 0.9043 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mEpoch 4/10 | train |  Loss: 0.1191 Acc: 0.9530\u001b[0m\n",
      "\u001b[34mEpoch 4/10 |  val  |  Loss: 0.2635 Acc: 0.9105\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0859 || 10iter: 0.9097 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0958 || 10iter: 0.9047 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0252 || 10iter: 0.9041 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1377 || 10iter: 0.9042 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1393 || 10iter: 0.9036 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.1486 || 10iter: 0.9071 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0461 || 10iter: 0.9136 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.0468 || 10iter: 0.9073 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1359 || 10iter: 0.9088 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1412 || 10iter: 0.9100 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.2796 || 10iter: 0.9043 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0219 || 10iter: 0.9084 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mEpoch 5/10 | train |  Loss: 0.1197 Acc: 0.9570\u001b[0m\n",
      "\u001b[34mEpoch 5/10 |  val  |  Loss: 0.2307 Acc: 0.9204\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0466 || 10iter: 0.9139 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0239 || 10iter: 0.9080 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0657 || 10iter: 0.9043 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.0372 || 10iter: 0.9066 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1025 || 10iter: 0.9031 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0936 || 10iter: 0.9052 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0445 || 10iter: 0.9055 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.0458 || 10iter: 0.9046 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1390 || 10iter: 0.9051 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1518 || 10iter: 0.9038 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0739 || 10iter: 0.9049 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0537 || 10iter: 0.9056 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 6/10 | train |  Loss: 0.1011 Acc: 0.9639\u001b[0m\n",
      "\u001b[34mEpoch 6/10 |  val  |  Loss: 0.2440 Acc: 0.9223\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0442 || 10iter: 0.9133 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1226 || 10iter: 0.9033 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.2321 || 10iter: 0.9034 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1357 || 10iter: 0.9031 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0418 || 10iter: 0.9038 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.1692 || 10iter: 0.9032 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0945 || 10iter: 0.9035 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.0640 || 10iter: 0.9032 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.0234 || 10iter: 0.9032 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1862 || 10iter: 0.9062 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0518 || 10iter: 0.9028 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0510 || 10iter: 0.9054 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 7/10 | train |  Loss: 0.0952 Acc: 0.9648\u001b[0m\n",
      "\u001b[34mEpoch 7/10 |  val  |  Loss: 0.2537 Acc: 0.9253\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0388 || 10iter: 0.9120 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0155 || 10iter: 0.9041 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0578 || 10iter: 0.9048 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.0895 || 10iter: 0.9059 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0135 || 10iter: 0.9069 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0568 || 10iter: 0.9067 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1540 || 10iter: 0.9094 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.0342 || 10iter: 0.9138 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.0649 || 10iter: 0.9061 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0399 || 10iter: 0.9022 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0693 || 10iter: 0.9040 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0306 || 10iter: 0.9040 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mEpoch 8/10 | train |  Loss: 0.0883 Acc: 0.9678\u001b[0m\n",
      "\u001b[34mEpoch 8/10 |  val  |  Loss: 0.2236 Acc: 0.9322\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0485 || 10iter: 0.9105 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0662 || 10iter: 0.9066 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1842 || 10iter: 0.9050 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.0904 || 10iter: 0.9036 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0640 || 10iter: 0.9025 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0246 || 10iter: 0.9048 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0336 || 10iter: 0.9049 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.0108 || 10iter: 0.9041 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.0035 || 10iter: 0.9030 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1391 || 10iter: 0.9039 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0455 || 10iter: 0.9054 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1774 || 10iter: 0.9074 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 9/10 | train |  Loss: 0.0843 Acc: 0.9661\u001b[0m\n",
      "\u001b[34mEpoch 9/10 |  val  |  Loss: 0.2281 Acc: 0.9282\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0829 || 10iter: 0.9096 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0106 || 10iter: 0.9036 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1048 || 10iter: 0.9047 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.0046 || 10iter: 0.9030 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0456 || 10iter: 0.9028 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0226 || 10iter: 0.9031 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.2179 || 10iter: 0.9100 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.0153 || 10iter: 0.9071 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1045 || 10iter: 0.9072 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0214 || 10iter: 0.9061 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0909 || 10iter: 0.9053 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.2168 || 10iter: 0.9062 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mEpoch 10/10 | train |  Loss: 0.0842 Acc: 0.9705\u001b[0m\n",
      "\u001b[34mEpoch 10/10 |  val  |  Loss: 0.2259 Acc: 0.9223\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/53 [00:00<?, ?it/s]#015  4%|         | 2/53 [00:00<00:04, 12.21it/s]#015  8%|         | 4/53 [00:00<00:04, 12.21it/s]#015 11%|        | 6/53 [00:00<00:03, 12.21it/s]#015 15%|        | 8/53 [00:00<00:03, 12.19it/s]#015 19%|        | 10/53 [00:00<00:03, 12.19it/s]#015 23%|       | 12/53 [00:00<00:03, 12.19it/s]#015 26%|       | 14/53 [00:01<00:03, 12.20it/s]#015 30%|       | 16/53 [00:01<00:03, 12.19it/s]#015 34%|      | 18/53 [00:01<00:02, 12.17it/s]#015 38%|      | 20/53 [00:01<00:02, 12.16it/s]#015 42%|     | 22/53 [00:01<00:02, 12.16it/s]#015 45%|     | 24/53 [00:01<00:02, 12.16it/s]#015 49%|     | 26/53 [00:02<00:02, 12.16it/s]#015 53%|    | 28/53 [00:02<00:02, 12.14it/s]#015 57%|    | 30/53 [00:02<00:01, 12.14it/s]#015 60%|    | 32/53 [00:02<00:01, 12.14it/s]#015 64%|   | 34/53 [00:02<00:01, 12.14it/s]#015 68%|   | 36/53 [00:02<00:01, 12.14it/s]#015 72%|  | 38/53 [00:03<00:01, 12.12it/s]#015 75%|  | 40/53 [00:03<00:01, 12.12it/s]#015 79%|  | 42/53 [00:03<00:00, 12.12it/s]#015 83%| | 44/53 [00:03<00:00, 12.12it/s]#015 87%| | 46/53 [00:03<00:00, 12.12it/s]#015 91%| | 48/53 [00:03<00:00, 12.11it/s]#015 94%|| 50/53 [00:04<00:00, 12.11it/s]#015 98%|| 52/53 [00:04<00:00, 12.12it/s]#015100%|| 53/53 [00:04<00:00, 12.16it/s]\u001b[0m\n",
      "\u001b[34mTest Data 1694 Accuracy: 0.9510\u001b[0m\n",
      "\u001b[34mRecall                      0.9510\u001b[0m\n",
      "\u001b[34mPrecision                   0.9496\u001b[0m\n",
      "\u001b[34mF1                          0.9498\u001b[0m\n",
      "\u001b[34mKappa                       0.8380\u001b[0m\n",
      "\u001b[34mQuadratic Weighted Kappa    0.8952\u001b[0m\n",
      "\u001b[34mdtype: float64\u001b[0m\n",
      "\u001b[34mConfusion Matrix:\n",
      "      0    1    2\u001b[0m\n",
      "\u001b[34m0  1367   16    6\u001b[0m\n",
      "\u001b[34m1    37  139   11\u001b[0m\n",
      "\u001b[34m2     5    8  105\u001b[0m\n",
      "\u001b[34m----------------\u001b[0m\n",
      "\u001b[34mRANDOM SET:  3\u001b[0m\n",
      "\u001b[34mConcat Value Len: 5082\u001b[0m\n",
      "\u001b[34m(tensor([[ 101, 1037, 2486,  ...,    0,    0,    0],\n",
      "        [ 101, 1037, 2711,  ...,    0,    0,    0],\n",
      "        [ 101, 1037, 2711,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 5577, 2242,  ...,    0,    0,    0],\n",
      "        [ 101, 2129, 2057,  ...,    0,    0,    0],\n",
      "        [ 101, 1996, 2801,  ...,    0,    0,    0]]), tensor([10, 19, 18, 10, 16, 14, 10, 10, 14, 22, 19, 11, 10, 14, 14, 26, 22, 32,\n",
      "        18, 14, 14, 14, 13, 19, 16, 15, 10, 16, 14, 12, 15, 20]))\u001b[0m\n",
      "\u001b[34mtensor([0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
      "        0, 0, 2, 0, 0, 0, 0, 0])\u001b[0m\n",
      "\u001b[34m['[CLS]', 'a', 'person', 'who', 'creates', 'something', 'new', 'that', 'has', 'never', 'been', 'made', 'before', 'you', 'are', 'making', 'something', 'new', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34mUsing device:  cuda:0\u001b[0m\n",
      "\u001b[34m-----start-------\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.3008 || 10iter: 0.9010 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.2282 || 10iter: 0.9002 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0881 || 10iter: 0.9009 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1083 || 10iter: 0.9043 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1210 || 10iter: 0.9018 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2192 || 10iter: 0.9028 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.3511 || 10iter: 0.9018 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.2376 || 10iter: 0.9107 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.0426 || 10iter: 0.9149 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.3363 || 10iter: 0.9067 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1593 || 10iter: 0.9025 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.3092 || 10iter: 0.9025 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mEpoch 1/10 | train |  Loss: 0.1878 Acc: 0.9297\u001b[0m\n",
      "\u001b[34mEpoch 1/10 |  val  |  Loss: 0.1202 Acc: 0.9596\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1049 || 10iter: 0.9096 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1811 || 10iter: 0.9074 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1318 || 10iter: 0.9027 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.0797 || 10iter: 0.9022 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0393 || 10iter: 0.9017 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.1114 || 10iter: 0.9025 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1469 || 10iter: 0.9030 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.0946 || 10iter: 0.9021 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1939 || 10iter: 0.9051 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1548 || 10iter: 0.9032 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1286 || 10iter: 0.9032 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0315 || 10iter: 0.9032 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mEpoch 2/10 | train |  Loss: 0.1212 Acc: 0.9555\u001b[0m\n",
      "\u001b[34mEpoch 2/10 |  val  |  Loss: 0.1524 Acc: 0.9449\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0503 || 10iter: 0.9086 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0101 || 10iter: 0.9035 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0392 || 10iter: 0.9036 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.0594 || 10iter: 0.9036 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1378 || 10iter: 0.9039 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.1496 || 10iter: 0.9055 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0568 || 10iter: 0.9041 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.0991 || 10iter: 0.9029 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.0161 || 10iter: 0.9062 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1369 || 10iter: 0.9055 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.2574 || 10iter: 0.9053 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0240 || 10iter: 0.9041 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mEpoch 3/10 | train |  Loss: 0.1172 Acc: 0.9562\u001b[0m\n",
      "\u001b[34mEpoch 3/10 |  val  |  Loss: 0.1239 Acc: 0.9567\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.2249 || 10iter: 0.9099 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1977 || 10iter: 0.9039 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0388 || 10iter: 0.9083 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.0343 || 10iter: 0.9122 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0757 || 10iter: 0.9083 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0439 || 10iter: 0.9091 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0048 || 10iter: 0.9096 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1929 || 10iter: 0.9099 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.2094 || 10iter: 0.9062 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1375 || 10iter: 0.9063 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0746 || 10iter: 0.9050 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1282 || 10iter: 0.9059 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 4/10 | train |  Loss: 0.1007 Acc: 0.9616\u001b[0m\n",
      "\u001b[34mEpoch 4/10 |  val  |  Loss: 0.1910 Acc: 0.9291\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1117 || 10iter: 0.9110 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0846 || 10iter: 0.9057 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0911 || 10iter: 0.9057 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.0343 || 10iter: 0.9049 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0790 || 10iter: 0.9044 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0959 || 10iter: 0.9114 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0517 || 10iter: 0.9069 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1318 || 10iter: 0.9114 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.0818 || 10iter: 0.9109 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0154 || 10iter: 0.9060 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1527 || 10iter: 0.9047 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0254 || 10iter: 0.9056 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mEpoch 5/10 | train |  Loss: 0.0977 Acc: 0.9641\u001b[0m\n",
      "\u001b[34mEpoch 5/10 |  val  |  Loss: 0.1537 Acc: 0.9518\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0743 || 10iter: 0.9118 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0533 || 10iter: 0.9048 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1829 || 10iter: 0.9061 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.0656 || 10iter: 0.9073 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.2351 || 10iter: 0.9100 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.1237 || 10iter: 0.9091 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1689 || 10iter: 0.9068 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.0152 || 10iter: 0.9044 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.0191 || 10iter: 0.9053 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0919 || 10iter: 0.9053 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0417 || 10iter: 0.9058 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0768 || 10iter: 0.9052 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 6/10 | train |  Loss: 0.0851 Acc: 0.9668\u001b[0m\n",
      "\u001b[34mEpoch 6/10 |  val  |  Loss: 0.1502 Acc: 0.9547\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0853 || 10iter: 0.9100 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0135 || 10iter: 0.9060 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1184 || 10iter: 0.9051 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.0248 || 10iter: 0.9054 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1147 || 10iter: 0.9047 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0591 || 10iter: 0.9047 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0339 || 10iter: 0.9048 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.0955 || 10iter: 0.9046 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1715 || 10iter: 0.9046 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0508 || 10iter: 0.9048 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0130 || 10iter: 0.9077 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0254 || 10iter: 0.9056 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mEpoch 7/10 | train |  Loss: 0.0877 Acc: 0.9663\u001b[0m\n",
      "\u001b[34mEpoch 7/10 |  val  |  Loss: 0.1674 Acc: 0.9478\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0446 || 10iter: 0.9114 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0640 || 10iter: 0.9052 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1584 || 10iter: 0.9061 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.0861 || 10iter: 0.9048 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0319 || 10iter: 0.9044 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0357 || 10iter: 0.9080 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0700 || 10iter: 0.9047 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1235 || 10iter: 0.9027 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1059 || 10iter: 0.9034 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0090 || 10iter: 0.9052 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1250 || 10iter: 0.9031 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0429 || 10iter: 0.9041 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 8/10 | train |  Loss: 0.0916 Acc: 0.9705\u001b[0m\n",
      "\u001b[34mEpoch 8/10 |  val  |  Loss: 0.1889 Acc: 0.9488\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0986 || 10iter: 0.9113 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0954 || 10iter: 0.9033 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1065 || 10iter: 0.9041 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1060 || 10iter: 0.9035 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1008 || 10iter: 0.9056 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0246 || 10iter: 0.9092 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0297 || 10iter: 0.9032 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.0236 || 10iter: 0.9093 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.2071 || 10iter: 0.9064 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1201 || 10iter: 0.9035 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0259 || 10iter: 0.9065 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0213 || 10iter: 0.9040 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mEpoch 9/10 | train |  Loss: 0.0872 Acc: 0.9666\u001b[0m\n",
      "\u001b[34mEpoch 9/10 |  val  |  Loss: 0.1892 Acc: 0.9419\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1027 || 10iter: 0.9095 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0340 || 10iter: 0.9050 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0726 || 10iter: 0.9041 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.0388 || 10iter: 0.9031 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0434 || 10iter: 0.9030 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0333 || 10iter: 0.9031 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0786 || 10iter: 0.9026 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1628 || 10iter: 0.9020 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.0384 || 10iter: 0.9035 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1801 || 10iter: 0.9023 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0673 || 10iter: 0.9033 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.2594 || 10iter: 0.9025 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mEpoch 10/10 | train |  Loss: 0.0706 Acc: 0.9747\u001b[0m\n",
      "\u001b[34mEpoch 10/10 |  val  |  Loss: 0.1620 Acc: 0.9518\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/53 [00:00<?, ?it/s]#015  4%|         | 2/53 [00:00<00:04, 12.29it/s]#015  8%|         | 4/53 [00:00<00:03, 12.26it/s]#015 11%|        | 6/53 [00:00<00:03, 12.24it/s]#015 15%|        | 8/53 [00:00<00:03, 12.22it/s]#015 19%|        | 10/53 [00:00<00:03, 12.22it/s]#015 23%|       | 12/53 [00:00<00:03, 12.18it/s]#015 26%|       | 14/53 [00:01<00:03, 12.18it/s]#015 30%|       | 16/53 [00:01<00:03, 12.15it/s]#015 34%|      | 18/53 [00:01<00:02, 12.14it/s]#015 38%|      | 20/53 [00:01<00:02, 12.13it/s]#015 42%|     | 22/53 [00:01<00:02, 12.13it/s]#015 45%|     | 24/53 [00:01<00:02, 12.14it/s]#015 49%|     | 26/53 [00:02<00:02, 12.14it/s]#015 53%|    | 28/53 [00:02<00:02, 12.14it/s]#015 57%|    | 30/53 [00:02<00:01, 12.13it/s]#015 60%|    | 32/53 [00:02<00:01, 12.12it/s]#015 64%|   | 34/53 [00:02<00:01, 12.13it/s]#015 68%|   | 36/53 [00:02<00:01, 12.12it/s]#015 72%|  | 38/53 [00:03<00:01, 12.11it/s]#015 75%|  | 40/53 [00:03<00:01, 12.11it/s]#015 79%|  | 42/53 [00:03<00:00, 12.13it/s]#015 83%| | 44/53 [00:03<00:00, 12.12it/s]#015 87%| | 46/53 [00:03<00:00, 12.11it/s]#015 91%| | 48/53 [00:03<00:00, 12.12it/s]#015 94%|| 50/53 [00:04<00:00, 12.13it/s]#015 98%|| 52/53 [00:04<00:00, 12.13it/s]#015100%|| 53/53 [00:04<00:00, 12.14it/s]\u001b[0m\n",
      "\u001b[34mTest Data 1696 Accuracy: 0.9605\u001b[0m\n",
      "\u001b[34mRecall                      0.9605\u001b[0m\n",
      "\u001b[34mPrecision                   0.9621\u001b[0m\n",
      "\u001b[34mF1                          0.9609\u001b[0m\n",
      "\u001b[34mKappa                       0.8758\u001b[0m\n",
      "\u001b[34mQuadratic Weighted Kappa    0.9218\u001b[0m\n",
      "\u001b[34mdtype: float64\u001b[0m\n",
      "\u001b[34mConfusion Matrix:\n",
      "      0    1    2\u001b[0m\n",
      "\u001b[34m0  1362   23    2\u001b[0m\n",
      "\u001b[34m1    10  164   10\u001b[0m\n",
      "\u001b[34m2     5   17  103\u001b[0m\n",
      "\u001b[34m----------------\u001b[0m\n",
      "\u001b[34mALL DATA (Macro Average):\n",
      "         Recall  Precision        F1     Kappa  Quadratic Weighted Kappa\u001b[0m\n",
      "\u001b[34mcount  4.000000   4.000000  4.000000  4.000000                  4.000000\u001b[0m\n",
      "\u001b[34mmean   0.936700   0.943425  0.938725  0.810750                  0.866850\u001b[0m\n",
      "\u001b[34mstd    0.023553   0.016047  0.020752  0.059402                  0.050842\u001b[0m\n",
      "\u001b[34mmin    0.908500   0.924800  0.914200  0.738600                  0.810000\u001b[0m\n",
      "\u001b[34m25%    0.922225   0.934100  0.926050  0.777600                  0.832800\u001b[0m\n",
      "\u001b[34m50%    0.938900   0.943400  0.939900  0.814300                  0.867800\u001b[0m\n",
      "\u001b[34m75%    0.953375   0.952725  0.952575  0.847450                  0.901850\u001b[0m\n",
      "\u001b[34mmax    0.960500   0.962100  0.960900  0.875800                  0.921800\u001b[0m\n",
      "\u001b[34m----------------\u001b[0m\n",
      "\u001b[34mALL DATA (Micro Average):\u001b[0m\n",
      "\u001b[34mRecall                      0.9367\u001b[0m\n",
      "\u001b[34mPrecision                   0.9412\u001b[0m\n",
      "\u001b[34mF1                          0.9385\u001b[0m\n",
      "\u001b[34mKappa                       0.8082\u001b[0m\n",
      "\u001b[34mQuadratic Weighted Kappa    0.8644\u001b[0m\n",
      "\u001b[34mdtype: float64\u001b[0m\n",
      "\u001b[34mConfusion Matrix:\n",
      "      0    1    2\u001b[0m\n",
      "\u001b[34m0  5310  169   56\u001b[0m\n",
      "\u001b[34m1    73  608   67\u001b[0m\n",
      "\u001b[34m2    17   47  431\u001b[0m\n",
      "\u001b[34mTraining complete.\u001b[0m\n",
      "\n",
      "2021-08-17 01:53:55 Uploading - Uploading generated training model\n",
      "2021-08-17 01:56:56 Completed - Training job completed\n",
      "ProfilerReport-1629164150: IssuesFound\n",
      "Training seconds: 1101\n",
      "Billable seconds: 1101\n"
     ]
    }
   ],
   "source": [
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "\n",
    "# Makoto.Sano@Mack-the-Psych.com\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/sagemaker-vdok3-bert-cv-def:latest'.format(account, region)\n",
    "vdok3bert = sage.estimator.Estimator(image,\n",
    "                       role, 1, 'ml.p3.2xlarge',\n",
    "                       output_path=\"s3://{}/output\".format(sess.default_bucket()),\n",
    "                       sagemaker_session=sess)\n",
    "vdok3bert.fit(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "predictor = vdok3bert.deploy(1, 'ml.p3.2xlarge', serializer=csv_serializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score_Class,Definition-Score\n",
      "0,0\n",
      "1,1\n",
      "1,1\n",
      "2,2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_in = pd.read_csv('data/Head4-Serialized-Def-ELVA.PILOT.POST-TEST.csv')\n",
    "np_in = np.vstack((np.array(df_in.columns), df_in.to_numpy()))\n",
    "print(predictor.predict(np_in).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "sess.delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_output_folder = \"batch-transform-output\"\n",
    "output_path=\"s3://{}/{}\".format(sess.default_bucket(), transform_output_folder)\n",
    "\n",
    "transformer = vdok3bert.transformer(instance_count=1,\n",
    "                               instance_type='ml.p3.2xlarge',\n",
    "                               output_path=output_path,\n",
    "                               assemble_with='Line',\n",
    "                               accept='text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................\u001b[34mStarting the inference server with 8 workers.\u001b[0m\n",
      "\u001b[34m[2021-08-17 02:14:17 +0000] [41] [INFO] Starting gunicorn 20.1.0\u001b[0m\n",
      "\u001b[34m[2021-08-17 02:14:17 +0000] [41] [INFO] Listening at: unix:/tmp/gunicorn.sock (41)\u001b[0m\n",
      "\u001b[34m[2021-08-17 02:14:17 +0000] [41] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-08-17 02:14:17 +0000] [45] [INFO] Booting worker with pid: 45\u001b[0m\n",
      "\u001b[34m[2021-08-17 02:14:17 +0000] [46] [INFO] Booting worker with pid: 46\u001b[0m\n",
      "\u001b[34m[2021-08-17 02:14:17 +0000] [54] [INFO] Booting worker with pid: 54\u001b[0m\n",
      "\u001b[34m[2021-08-17 02:14:17 +0000] [55] [INFO] Booting worker with pid: 55\u001b[0m\n",
      "\u001b[34m[2021-08-17 02:14:17 +0000] [63] [INFO] Booting worker with pid: 63\u001b[0m\n",
      "\u001b[34m[2021-08-17 02:14:17 +0000] [72] [INFO] Booting worker with pid: 72\u001b[0m\n",
      "\u001b[34m[2021-08-17 02:14:18 +0000] [86] [INFO] Booting worker with pid: 86\u001b[0m\n",
      "\u001b[34m[2021-08-17 02:14:18 +0000] [89] [INFO] Booting worker with pid: 89\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34mbert.embeddings.word_embeddings.weightembeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.position_embeddings.weightembeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.token_type_embeddings.weightembeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.gammaembeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.betaembeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.weightencoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.biasencoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.weightencoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.biasencoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.weightencoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.biasencoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.weightencoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.biasencoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.gammaencoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.betaencoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.weightencoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.biasencoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.weightencoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.biasencoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.gammaencoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.betaencoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.weightencoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.biasencoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.weightencoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.biasencoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.weightencoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.biasencoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.weightencoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.biasencoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.gammaencoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.betaencoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.weightencoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.biasencoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.weightencoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.biasencoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.gammaencoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.betaencoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.weightencoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.biasencoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.weightencoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.biasencoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.weightencoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.biasencoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.weightencoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.biasencoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.gammaencoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.betaencoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.weightencoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.biasencoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.weightencoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.biasencoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.gammaencoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.betaencoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.weightencoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.biasencoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.weightencoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.biasencoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.weightencoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.biasencoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.weightencoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.biasencoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.gammaencoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.betaencoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.weightencoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.biasencoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.weightencoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.biasencoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.gammaencoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.betaencoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.weightencoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.biasencoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.weightencoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.biasencoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.weightencoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.biasencoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.weightencoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.biasencoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.gammaencoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.betaencoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.weightencoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.biasencoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.weightencoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.biasencoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.gammaencoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.betaencoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.weightencoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.biasencoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.weightencoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.biasencoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.weightencoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.biasencoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.weightencoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.biasencoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.gammaencoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.betaencoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.weightencoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.biasencoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.weightencoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.biasencoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.gammaencoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.betaencoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.weightencoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.biasencoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.weightencoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.biasencoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.weightencoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.biasencoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.weightencoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.biasencoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.gammaencoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.betaencoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.weightencoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.biasencoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.weightencoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.biasencoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.gammaencoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.betaencoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.weightencoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.biasencoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.weightencoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.biasencoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.weightencoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.biasencoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.weightencoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.biasencoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.gammaencoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.betaencoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.weightencoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.biasencoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.weightencoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.biasencoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.gammaencoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.betaencoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.weightencoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.biasencoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.weightencoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.biasencoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.weightencoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.biasencoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.weightencoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.biasencoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.gammaencoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.betaencoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.weightencoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.biasencoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.weightencoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.biasencoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.gammaencoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.betaencoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.weightencoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.biasencoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.weightencoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.biasencoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.weightencoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.biasencoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.weightencoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.biasencoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.gammaencoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.betaencoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.weightencoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.biasencoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.weightencoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.biasencoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.gammaencoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.betaencoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.weightencoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.biasencoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.weightencoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.biasencoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.weightencoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.biasencoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.weightencoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.biasencoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.gammaencoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.betaencoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.weightencoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.biasencoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.weightencoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.biasencoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.gammaencoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.betaencoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.weightencoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.biasencoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.weightencoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.biasencoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.weightencoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.biasencoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.weightencoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.biasencoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.gammaencoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.betaencoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.weightencoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.biasencoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.weightencoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.biasencoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.gammaencoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.betaencoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.weightpooler.dense.weight\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.biaspooler.dense.bias\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Aug/2021:02:14:36 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Aug/2021:02:14:36 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 4 records\u001b[0m\n",
      "\u001b[34mbert.embeddings.word_embeddings.weightembeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.position_embeddings.weightembeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.token_type_embeddings.weightembeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.gammaembeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.betaembeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.weightencoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.biasencoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.weightencoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.biasencoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.weightencoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.biasencoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.weightencoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.biasencoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.gammaencoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.betaencoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.weightencoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.biasencoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.weightencoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.biasencoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.gammaencoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.betaencoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.weightencoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.biasencoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.weightencoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.biasencoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.weightencoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.biasencoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.weightencoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.biasencoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.gammaencoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.betaencoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.weightencoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.biasencoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.weightencoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.biasencoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.gammaencoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.betaencoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.weightencoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.biasencoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.weightencoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.biasencoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.weightencoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.biasencoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.weightencoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.biasencoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.gammaencoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.betaencoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.weightencoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.biasencoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.weightencoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.biasencoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.gammaencoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.betaencoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.weightencoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.biasencoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.weightencoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.biasencoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.weightencoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.biasencoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.weightencoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.biasencoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.gammaencoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.betaencoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.weightencoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.biasencoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.weightencoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.biasencoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.gammaencoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.betaencoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.weightencoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.biasencoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.weightencoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.biasencoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.weightencoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.biasencoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.weightencoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.biasencoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.gammaencoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.betaencoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.weightencoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.biasencoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.weightencoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.biasencoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.gammaencoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.betaencoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.weightencoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.biasencoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.weightencoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.biasencoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.weightencoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.biasencoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.weightencoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.biasencoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.gammaencoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.betaencoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.weightencoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.biasencoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.weightencoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.biasencoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.gammaencoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.betaencoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.weightencoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.biasencoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.weightencoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.biasencoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.weightencoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.biasencoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.weightencoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.biasencoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.gammaencoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.betaencoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.weightencoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.biasencoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.weightencoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.biasencoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.gammaencoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.betaencoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.weightencoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.biasencoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.weightencoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.biasencoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.weightencoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.biasencoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.weightencoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.biasencoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.gammaencoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.betaencoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.weightencoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.biasencoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.weightencoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.biasencoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.gammaencoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.betaencoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.weightencoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.biasencoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.weightencoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.biasencoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.weightencoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.biasencoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.weightencoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.biasencoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.gammaencoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.betaencoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.weightencoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.biasencoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.weightencoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.biasencoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.gammaencoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.betaencoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.weightencoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.biasencoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.weightencoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.biasencoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.weightencoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.biasencoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.weightencoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.biasencoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.gammaencoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.betaencoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.weightencoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.biasencoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.weightencoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.biasencoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.gammaencoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.betaencoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.weightencoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.biasencoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.weightencoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.biasencoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.weightencoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.biasencoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.weightencoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.biasencoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.gammaencoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.betaencoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.weightencoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.biasencoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.weightencoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.biasencoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.gammaencoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.betaencoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.weightencoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.biasencoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.weightencoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.biasencoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.weightencoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.biasencoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.weightencoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.biasencoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.gammaencoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.betaencoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.weightencoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.biasencoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.weightencoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.biasencoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.gammaencoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.betaencoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.weightpooler.dense.weight\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.biaspooler.dense.bias\u001b[0m\n",
      "\n",
      "\u001b[32m2021-08-17T02:14:36.206:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/1 [00:00<?, ?it/s]#015100%|| 1/1 [00:00<00:00, 37.06it/s]\u001b[0m\n",
      "\u001b[34mTest Data 4 Accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Aug/2021:02:14:45 +0000] \"POST /invocations HTTP/1.1\" 200 45 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m#015  0%|          | 0/1 [00:00<?, ?it/s]#015100%|| 1/1 [00:00<00:00, 37.06it/s]\u001b[0m\n",
      "\u001b[35mTest Data 4 Accuracy: 1.0000\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [17/Aug/2021:02:14:45 +0000] \"POST /invocations HTTP/1.1\" 200 45 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mStarting the inference server with 8 workers.\u001b[0m\n",
      "\u001b[35mStarting the inference server with 8 workers.\u001b[0m\n",
      "\u001b[34m[2021-08-17 02:14:17 +0000] [41] [INFO] Starting gunicorn 20.1.0\u001b[0m\n",
      "\u001b[34m[2021-08-17 02:14:17 +0000] [41] [INFO] Listening at: unix:/tmp/gunicorn.sock (41)\u001b[0m\n",
      "\u001b[34m[2021-08-17 02:14:17 +0000] [41] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-08-17 02:14:17 +0000] [45] [INFO] Booting worker with pid: 45\u001b[0m\n",
      "\u001b[34m[2021-08-17 02:14:17 +0000] [46] [INFO] Booting worker with pid: 46\u001b[0m\n",
      "\u001b[34m[2021-08-17 02:14:17 +0000] [54] [INFO] Booting worker with pid: 54\u001b[0m\n",
      "\u001b[34m[2021-08-17 02:14:17 +0000] [55] [INFO] Booting worker with pid: 55\u001b[0m\n",
      "\u001b[34m[2021-08-17 02:14:17 +0000] [63] [INFO] Booting worker with pid: 63\u001b[0m\n",
      "\u001b[34m[2021-08-17 02:14:17 +0000] [72] [INFO] Booting worker with pid: 72\u001b[0m\n",
      "\u001b[34m[2021-08-17 02:14:18 +0000] [86] [INFO] Booting worker with pid: 86\u001b[0m\n",
      "\u001b[34m[2021-08-17 02:14:18 +0000] [89] [INFO] Booting worker with pid: 89\u001b[0m\n",
      "\u001b[35m[2021-08-17 02:14:17 +0000] [41] [INFO] Starting gunicorn 20.1.0\u001b[0m\n",
      "\u001b[35m[2021-08-17 02:14:17 +0000] [41] [INFO] Listening at: unix:/tmp/gunicorn.sock (41)\u001b[0m\n",
      "\u001b[35m[2021-08-17 02:14:17 +0000] [41] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2021-08-17 02:14:17 +0000] [45] [INFO] Booting worker with pid: 45\u001b[0m\n",
      "\u001b[35m[2021-08-17 02:14:17 +0000] [46] [INFO] Booting worker with pid: 46\u001b[0m\n",
      "\u001b[35m[2021-08-17 02:14:17 +0000] [54] [INFO] Booting worker with pid: 54\u001b[0m\n",
      "\u001b[35m[2021-08-17 02:14:17 +0000] [55] [INFO] Booting worker with pid: 55\u001b[0m\n",
      "\u001b[35m[2021-08-17 02:14:17 +0000] [63] [INFO] Booting worker with pid: 63\u001b[0m\n",
      "\u001b[35m[2021-08-17 02:14:17 +0000] [72] [INFO] Booting worker with pid: 72\u001b[0m\n",
      "\u001b[35m[2021-08-17 02:14:18 +0000] [86] [INFO] Booting worker with pid: 86\u001b[0m\n",
      "\u001b[35m[2021-08-17 02:14:18 +0000] [89] [INFO] Booting worker with pid: 89\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34mbert.embeddings.word_embeddings.weightembeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.position_embeddings.weightembeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.token_type_embeddings.weightembeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.gammaembeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.betaembeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.weightencoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.biasencoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.embeddings.word_embeddings.weightembeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[35mbert.embeddings.position_embeddings.weightembeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[35mbert.embeddings.token_type_embeddings.weightembeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[35mbert.embeddings.LayerNorm.gammaembeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.embeddings.LayerNorm.betaembeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.query.weightencoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.query.biasencoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.weightencoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.biasencoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.weightencoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.biasencoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.weightencoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.biasencoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.gammaencoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.betaencoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.weightencoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.biasencoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.weightencoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.biasencoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.gammaencoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.betaencoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.weightencoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.biasencoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.weightencoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.biasencoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.weightencoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.biasencoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.weightencoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.biasencoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.gammaencoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.betaencoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.weightencoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.biasencoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.weightencoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.biasencoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.key.weightencoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.key.biasencoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.value.weightencoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.value.biasencoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.dense.weightencoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.dense.biasencoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.LayerNorm.gammaencoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.LayerNorm.betaencoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.intermediate.dense.weightencoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.intermediate.dense.biasencoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.dense.weightencoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.dense.biasencoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.LayerNorm.gammaencoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.LayerNorm.betaencoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.query.weightencoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.query.biasencoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.key.weightencoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.key.biasencoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.value.weightencoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.value.biasencoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.dense.weightencoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.dense.biasencoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.LayerNorm.gammaencoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.LayerNorm.betaencoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.intermediate.dense.weightencoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.intermediate.dense.biasencoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.dense.weightencoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.dense.biasencoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.gammaencoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.betaencoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.weightencoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.biasencoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.weightencoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.biasencoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.weightencoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.biasencoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.weightencoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.biasencoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.gammaencoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.betaencoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.weightencoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.biasencoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.weightencoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.biasencoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.gammaencoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.betaencoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.weightencoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.biasencoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.weightencoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.biasencoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.weightencoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.biasencoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.weightencoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.biasencoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.gammaencoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.betaencoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.LayerNorm.gammaencoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.LayerNorm.betaencoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.query.weightencoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.query.biasencoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.key.weightencoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.key.biasencoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.value.weightencoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.value.biasencoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.dense.weightencoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.dense.biasencoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.LayerNorm.gammaencoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.LayerNorm.betaencoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.intermediate.dense.weightencoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.intermediate.dense.biasencoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.dense.weightencoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.dense.biasencoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.LayerNorm.gammaencoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.LayerNorm.betaencoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.query.weightencoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.query.biasencoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.key.weightencoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.key.biasencoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.value.weightencoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.value.biasencoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.dense.weightencoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.dense.biasencoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.LayerNorm.gammaencoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.LayerNorm.betaencoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.weightencoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.biasencoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.weightencoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.biasencoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.gammaencoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.betaencoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.weightencoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.biasencoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.weightencoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.biasencoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.weightencoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.biasencoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.weightencoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.biasencoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.gammaencoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.betaencoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.weightencoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.biasencoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.weightencoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.biasencoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.gammaencoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.betaencoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.weightencoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.biasencoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.weightencoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.biasencoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.weightencoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.biasencoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.weightencoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.biasencoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.gammaencoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.betaencoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.weightencoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.biasencoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.weightencoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.intermediate.dense.weightencoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.intermediate.dense.biasencoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.dense.weightencoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.dense.biasencoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.LayerNorm.gammaencoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.LayerNorm.betaencoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.query.weightencoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.query.biasencoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.key.weightencoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.key.biasencoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.value.weightencoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.value.biasencoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.dense.weightencoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.dense.biasencoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.LayerNorm.gammaencoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.LayerNorm.betaencoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.intermediate.dense.weightencoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.intermediate.dense.biasencoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.dense.weightencoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.dense.biasencoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.LayerNorm.gammaencoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.LayerNorm.betaencoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.query.weightencoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.query.biasencoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.key.weightencoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.key.biasencoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.value.weightencoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.value.biasencoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.dense.weightencoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.dense.biasencoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.LayerNorm.gammaencoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.LayerNorm.betaencoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.intermediate.dense.weightencoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.intermediate.dense.biasencoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.dense.weightencoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.biasencoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.gammaencoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.betaencoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.weightencoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.biasencoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.weightencoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.biasencoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.weightencoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.biasencoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.weightencoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.biasencoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.gammaencoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.betaencoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.weightencoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.biasencoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.weightencoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.biasencoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.gammaencoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.betaencoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.weightencoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.biasencoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.weightencoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.biasencoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.weightencoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.biasencoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.weightencoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.biasencoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.gammaencoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.betaencoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.weightencoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.biasencoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.dense.biasencoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.LayerNorm.gammaencoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.LayerNorm.betaencoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.query.weightencoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.query.biasencoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.key.weightencoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.key.biasencoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.value.weightencoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.value.biasencoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.dense.weightencoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.dense.biasencoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.LayerNorm.gammaencoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.LayerNorm.betaencoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.intermediate.dense.weightencoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.intermediate.dense.biasencoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.dense.weightencoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.dense.biasencoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.LayerNorm.gammaencoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.LayerNorm.betaencoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.query.weightencoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.query.biasencoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.key.weightencoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.key.biasencoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.value.weightencoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.value.biasencoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.dense.weightencoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.dense.biasencoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.LayerNorm.gammaencoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.LayerNorm.betaencoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.intermediate.dense.weightencoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.intermediate.dense.biasencoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.weightencoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.biasencoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.gammaencoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.betaencoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.weightencoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.biasencoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.weightencoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.biasencoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.weightencoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.biasencoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.weightencoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.biasencoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.gammaencoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.betaencoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.weightencoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.biasencoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.weightencoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.biasencoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.gammaencoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.betaencoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.weightencoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.biasencoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.weightencoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.biasencoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.weightencoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.biasencoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.weightencoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.biasencoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.gammaencoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.betaencoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.weightencoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.biasencoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.weightencoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.biasencoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.gammaencoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.betaencoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.weightencoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.dense.weightencoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.dense.biasencoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.LayerNorm.gammaencoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.LayerNorm.betaencoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.query.weightencoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.query.biasencoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.key.weightencoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.key.biasencoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.value.weightencoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.value.biasencoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.dense.weightencoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.dense.biasencoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.LayerNorm.gammaencoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.LayerNorm.betaencoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.intermediate.dense.weightencoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.intermediate.dense.biasencoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.dense.weightencoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.dense.biasencoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.LayerNorm.gammaencoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.LayerNorm.betaencoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.query.weightencoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.query.biasencoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.key.weightencoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.key.biasencoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.value.weightencoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.value.biasencoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.dense.weightencoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.dense.biasencoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.LayerNorm.gammaencoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.LayerNorm.betaencoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.intermediate.dense.weightencoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.intermediate.dense.biasencoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.dense.weightencoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.dense.biasencoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.LayerNorm.gammaencoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.LayerNorm.betaencoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.query.weightencoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.biasencoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.weightencoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.biasencoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.weightencoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.biasencoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.weightencoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.biasencoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.gammaencoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.betaencoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.weightencoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.biasencoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.weightencoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.biasencoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.gammaencoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.betaencoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.weightencoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.biasencoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.weightencoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.biasencoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.weightencoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.biasencoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.weightencoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.biasencoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.gammaencoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.betaencoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.weightencoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.biasencoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.weightencoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.biasencoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.gammaencoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.betaencoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.weightpooler.dense.weight\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.biaspooler.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.query.biasencoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.key.weightencoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.key.biasencoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.value.weightencoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.value.biasencoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.dense.weightencoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.dense.biasencoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.LayerNorm.gammaencoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.LayerNorm.betaencoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.intermediate.dense.weightencoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.intermediate.dense.biasencoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.dense.weightencoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.dense.biasencoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.LayerNorm.gammaencoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.LayerNorm.betaencoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.query.weightencoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.query.biasencoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.key.weightencoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.key.biasencoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.value.weightencoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.value.biasencoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.dense.weightencoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.dense.biasencoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.LayerNorm.gammaencoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.LayerNorm.betaencoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.intermediate.dense.weightencoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.intermediate.dense.biasencoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.dense.weightencoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.dense.biasencoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.LayerNorm.gammaencoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.LayerNorm.betaencoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.pooler.dense.weightpooler.dense.weight\u001b[0m\n",
      "\u001b[35mbert.pooler.dense.biaspooler.dense.bias\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Aug/2021:02:14:36 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Aug/2021:02:14:36 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 4 records\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [17/Aug/2021:02:14:36 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [17/Aug/2021:02:14:36 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 4 records\u001b[0m\n",
      "\u001b[32m2021-08-17T02:14:36.206:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34mbert.embeddings.word_embeddings.weightembeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.position_embeddings.weightembeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.token_type_embeddings.weightembeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.gammaembeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.betaembeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.weightencoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.biasencoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.weightencoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.biasencoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.weightencoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.biasencoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.weightencoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.biasencoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.gammaencoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.betaencoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.weightencoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.biasencoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.weightencoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.embeddings.word_embeddings.weightembeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[35mbert.embeddings.position_embeddings.weightembeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[35mbert.embeddings.token_type_embeddings.weightembeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[35mbert.embeddings.LayerNorm.gammaembeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.embeddings.LayerNorm.betaembeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.query.weightencoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.query.biasencoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.key.weightencoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.key.biasencoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.value.weightencoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.value.biasencoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.dense.weightencoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.dense.biasencoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.LayerNorm.gammaencoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.LayerNorm.betaencoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.intermediate.dense.weightencoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.intermediate.dense.biasencoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.dense.weightencoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.biasencoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.gammaencoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.betaencoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.weightencoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.biasencoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.weightencoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.biasencoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.weightencoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.biasencoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.weightencoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.biasencoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.gammaencoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.betaencoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.weightencoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.biasencoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.weightencoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.biasencoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.gammaencoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.betaencoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.weightencoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.biasencoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.weightencoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.biasencoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.weightencoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.biasencoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.weightencoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.biasencoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.gammaencoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.betaencoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.weightencoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.biasencoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.dense.biasencoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.LayerNorm.gammaencoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.LayerNorm.betaencoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.query.weightencoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.query.biasencoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.key.weightencoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.key.biasencoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.value.weightencoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.value.biasencoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.dense.weightencoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.dense.biasencoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.LayerNorm.gammaencoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.LayerNorm.betaencoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.intermediate.dense.weightencoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.intermediate.dense.biasencoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.dense.weightencoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.dense.biasencoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.LayerNorm.gammaencoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.LayerNorm.betaencoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.query.weightencoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.query.biasencoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.key.weightencoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.key.biasencoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.value.weightencoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.value.biasencoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.dense.weightencoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.dense.biasencoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.LayerNorm.gammaencoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.LayerNorm.betaencoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.intermediate.dense.weightencoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.intermediate.dense.biasencoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.weightencoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.biasencoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.gammaencoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.betaencoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.weightencoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.biasencoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.weightencoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.biasencoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.weightencoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.biasencoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.weightencoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.biasencoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.gammaencoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.betaencoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.weightencoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.biasencoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.weightencoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.biasencoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.gammaencoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.betaencoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.weightencoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.biasencoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.weightencoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.biasencoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.weightencoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.biasencoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.weightencoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.biasencoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.gammaencoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.betaencoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.weightencoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.biasencoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.weightencoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.biasencoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.gammaencoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.betaencoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.weightencoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.dense.weightencoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.dense.biasencoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.LayerNorm.gammaencoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.LayerNorm.betaencoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.query.weightencoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.query.biasencoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.key.weightencoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.key.biasencoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.value.weightencoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.value.biasencoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.dense.weightencoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.dense.biasencoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.LayerNorm.gammaencoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.LayerNorm.betaencoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.intermediate.dense.weightencoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.intermediate.dense.biasencoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.dense.weightencoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.dense.biasencoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.LayerNorm.gammaencoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.LayerNorm.betaencoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.query.weightencoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.query.biasencoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.key.weightencoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.key.biasencoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.value.weightencoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.value.biasencoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.dense.weightencoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.dense.biasencoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.LayerNorm.gammaencoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.LayerNorm.betaencoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.intermediate.dense.weightencoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.intermediate.dense.biasencoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.dense.weightencoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.dense.biasencoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.LayerNorm.gammaencoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.LayerNorm.betaencoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.query.weightencoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.biasencoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.weightencoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.biasencoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.weightencoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.biasencoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.weightencoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.biasencoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.gammaencoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.betaencoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.weightencoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.biasencoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.weightencoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.biasencoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.gammaencoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.betaencoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.weightencoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.biasencoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.weightencoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.biasencoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.weightencoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.biasencoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.weightencoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.biasencoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.gammaencoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.betaencoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.weightencoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.biasencoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.weightencoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.biasencoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.gammaencoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.betaencoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.weightencoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.biasencoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.weightencoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.biasencoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.query.biasencoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.key.weightencoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.key.biasencoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.value.weightencoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.value.biasencoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.dense.weightencoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.dense.biasencoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.LayerNorm.gammaencoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.LayerNorm.betaencoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.intermediate.dense.weightencoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.intermediate.dense.biasencoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.dense.weightencoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.dense.biasencoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.LayerNorm.gammaencoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.LayerNorm.betaencoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.query.weightencoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.query.biasencoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.key.weightencoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.key.biasencoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.value.weightencoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.value.biasencoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.dense.weightencoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.dense.biasencoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.LayerNorm.gammaencoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.LayerNorm.betaencoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.intermediate.dense.weightencoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.intermediate.dense.biasencoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.dense.weightencoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.dense.biasencoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.LayerNorm.gammaencoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.LayerNorm.betaencoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.query.weightencoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.query.biasencoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.key.weightencoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.key.biasencoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.weightencoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.biasencoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.weightencoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.biasencoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.gammaencoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.betaencoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.weightencoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.biasencoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.weightencoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.biasencoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.gammaencoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.betaencoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.weightencoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.biasencoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.weightencoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.biasencoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.weightencoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.biasencoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.weightencoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.biasencoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.gammaencoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.betaencoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.weightencoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.biasencoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.weightencoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.biasencoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.gammaencoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.betaencoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.weightencoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.biasencoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.weightencoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.biasencoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.weightencoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.biasencoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.weightencoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.biasencoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.value.weightencoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.value.biasencoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.dense.weightencoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.dense.biasencoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.LayerNorm.gammaencoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.LayerNorm.betaencoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.intermediate.dense.weightencoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.intermediate.dense.biasencoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.dense.weightencoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.dense.biasencoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.LayerNorm.gammaencoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.LayerNorm.betaencoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.query.weightencoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.query.biasencoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.key.weightencoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.key.biasencoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.value.weightencoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.value.biasencoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.dense.weightencoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.dense.biasencoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.LayerNorm.gammaencoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.LayerNorm.betaencoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.intermediate.dense.weightencoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.intermediate.dense.biasencoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.dense.weightencoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.dense.biasencoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.LayerNorm.gammaencoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.LayerNorm.betaencoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.query.weightencoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.query.biasencoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.key.weightencoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.key.biasencoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.value.weightencoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.value.biasencoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.dense.weightencoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.dense.biasencoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.gammaencoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.betaencoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.weightencoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.biasencoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.weightencoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.biasencoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.gammaencoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.betaencoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.weightencoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.biasencoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.weightencoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.biasencoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.weightencoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.biasencoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.weightencoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.biasencoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.gammaencoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.betaencoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.weightencoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.biasencoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.weightencoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.biasencoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.gammaencoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.betaencoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.weightencoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.biasencoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.weightencoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.biasencoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.weightencoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.biasencoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.weightencoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.biasencoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.gammaencoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.LayerNorm.gammaencoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.LayerNorm.betaencoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.intermediate.dense.weightencoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.intermediate.dense.biasencoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.dense.weightencoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.dense.biasencoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.LayerNorm.gammaencoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.LayerNorm.betaencoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.query.weightencoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.query.biasencoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.key.weightencoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.key.biasencoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.value.weightencoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.value.biasencoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.dense.weightencoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.dense.biasencoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.LayerNorm.gammaencoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.LayerNorm.betaencoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.intermediate.dense.weightencoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.intermediate.dense.biasencoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.dense.weightencoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.dense.biasencoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.LayerNorm.gammaencoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.LayerNorm.betaencoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.query.weightencoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.query.biasencoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.key.weightencoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.key.biasencoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.value.weightencoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.value.biasencoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.dense.weightencoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.dense.biasencoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.LayerNorm.gammaencoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.betaencoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.weightencoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.biasencoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.weightencoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.biasencoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.gammaencoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.betaencoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.weightpooler.dense.weight\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.biaspooler.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.LayerNorm.betaencoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.intermediate.dense.weightencoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.intermediate.dense.biasencoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.dense.weightencoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.dense.biasencoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.LayerNorm.gammaencoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.LayerNorm.betaencoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.pooler.dense.weightpooler.dense.weight\u001b[0m\n",
      "\u001b[35mbert.pooler.dense.biaspooler.dense.bias\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/1 [00:00<?, ?it/s]#015100%|| 1/1 [00:00<00:00, 37.06it/s]\u001b[0m\n",
      "\u001b[34mTest Data 4 Accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Aug/2021:02:14:45 +0000] \"POST /invocations HTTP/1.1\" 200 45 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m#015  0%|          | 0/1 [00:00<?, ?it/s]#015100%|| 1/1 [00:00<00:00, 37.06it/s]\u001b[0m\n",
      "\u001b[35mTest Data 4 Accuracy: 1.0000\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [17/Aug/2021:02:14:45 +0000] \"POST /invocations HTTP/1.1\" 200 45 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "Transform results: \n",
      "Score_Class,Definition-Score\n",
      "0,0\n",
      "1,1\n",
      "1,1\n",
      "2,2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformer.transform(data_location + '/Head4-Serialized-Def-ELVA.PILOT.POST-TEST.csv', content_type='text/csv', split_type='Line')\n",
    "transformer.wait()\n",
    "\n",
    "s3_client = sess.boto_session.client('s3')\n",
    "s3_client.download_file(sess.default_bucket(), \"{}/Head4-Serialized-Def-ELVA.PILOT.POST-TEST.csv.out\".format(transform_output_folder), '/tmp/Head4-Serialized-Def-ELVA.PILOT.POST-TEST.csv.out')\n",
    "with open('/tmp/Head4-Serialized-Def-ELVA.PILOT.POST-TEST.csv.out') as f:\n",
    "    results = f.readlines()   \n",
    "print(\"Transform results: \\n{}\".format(''.join(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
