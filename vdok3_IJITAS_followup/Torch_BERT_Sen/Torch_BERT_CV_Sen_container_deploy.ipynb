{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Sending build context to Docker daemon  40.45kB\n",
      "Step 1/32 : FROM nvidia/cuda:10.0-cudnn7-devel-ubuntu16.04\n",
      " ---> 225b79605de8\n",
      "Step 2/32 : RUN apt-get -y update && apt-get -y upgrade && apt-get install -y --no-install-recommends          curl          git          unzip          bzip2          libgl1-mesa-glx          wget          nginx          ca-certificates     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> f81dac796496\n",
      "Step 3/32 : RUN git clone https://github.com/pyenv/pyenv.git .pyenv\n",
      " ---> Using cache\n",
      " ---> 29b7049525ea\n",
      "Step 4/32 : WORKDIR /\n",
      " ---> Using cache\n",
      " ---> 1794dc1050f9\n",
      "Step 5/32 : ENV HOME  /\n",
      " ---> Using cache\n",
      " ---> 710d1b71c6eb\n",
      "Step 6/32 : ENV PYENV_ROOT /.pyenv\n",
      " ---> Using cache\n",
      " ---> a30013e47bf5\n",
      "Step 7/32 : ENV PATH $PYENV_ROOT/shims:$PYENV_ROOT/bin:$PATH\n",
      " ---> Using cache\n",
      " ---> a48564c82db3\n",
      "Step 8/32 : RUN pyenv install anaconda3-5.0.0\n",
      " ---> Using cache\n",
      " ---> c3ed4ddab997\n",
      "Step 9/32 : RUN pyenv global anaconda3-5.0.0\n",
      " ---> Using cache\n",
      " ---> 65c508120e0b\n",
      "Step 10/32 : RUN pyenv rehash\n",
      " ---> Using cache\n",
      " ---> 66bdb3840a4d\n",
      "Step 11/32 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> 6047104a257b\n",
      "Step 12/32 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> d8cb40faabaf\n",
      "Step 13/32 : ENV PATH=\"/opt/program:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 51bceb4a60c8\n",
      "Step 14/32 : ENV PYTHONIOENCODING=utf-8\n",
      " ---> Using cache\n",
      " ---> c8a745d7115b\n",
      "Step 15/32 : WORKDIR /opt/program\n",
      " ---> Using cache\n",
      " ---> 6de9a03efd99\n",
      "Step 16/32 : RUN git clone https://github.com/mack-the-psych/plimac3.git\n",
      " ---> Using cache\n",
      " ---> 8c10524ee2be\n",
      "Step 17/32 : RUN echo \"/opt/program/plimac3/Lib\" > /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/plimac-custom.pth\n",
      " ---> Using cache\n",
      " ---> 1f685b3e7033\n",
      "Step 18/32 : RUN echo \"/opt/program/plimac3/Tools\" >> /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/plimac-custom.pth\n",
      " ---> Using cache\n",
      " ---> e870aaa642ef\n",
      "Step 19/32 : RUN conda install -c anaconda setuptools\n",
      " ---> Using cache\n",
      " ---> 06877fef41d7\n",
      "Step 20/32 : RUN pip install --upgrade pip &&     pip install tensorflow-gpu==1.14.0 --user &&     pip install ml_metrics==0.1.4 &&     pip install --upgrade scipy==1.1.0 &&     conda clean --all &&     conda install pytorch==1.0.0 torchvision==0.2.1 cuda100 -c pytorch &&     pip install torchtext==0.4.0 &&     pip install attrdict==2.0.1 &&     pip uninstall --yes numpy &&     pip install numpy==1.16.4 &&     pip uninstall --yes gast &&     pip install gast==0.2.2 &&     pip install -U gevent==1.4.0 --ignore-installed &&     pip install gunicorn\n",
      " ---> Using cache\n",
      " ---> 5d94a0ac1fc5\n",
      "Step 21/32 : WORKDIR /opt/program\n",
      " ---> Using cache\n",
      " ---> 9c91bc6c5f5f\n",
      "Step 22/32 : RUN git clone https://github.com/mack-the-psych/vdok3.git\n",
      " ---> Using cache\n",
      " ---> 9e1d3284468b\n",
      "Step 23/32 : RUN echo \"/opt/program/vdok3/prep\" > /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/vdok3-custom.pth\n",
      " ---> Using cache\n",
      " ---> b9ef5d6f32ed\n",
      "Step 24/32 : RUN echo \"/opt/program/vdok3/extract\" >> /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/vdok3-custom.pth\n",
      " ---> Using cache\n",
      " ---> ed3b292d0e77\n",
      "Step 25/32 : RUN echo \"/opt/program/vdok3/process\" >> /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/vdok3-custom.pth\n",
      " ---> Using cache\n",
      " ---> 0da41942eca6\n",
      "Step 26/32 : RUN echo \"/opt/program/vdok3/reorganize\" >> /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/vdok3-custom.pth\n",
      " ---> Using cache\n",
      " ---> ce0aab64eaf8\n",
      "Step 27/32 : RUN echo \"/opt/program/vdok3/train\" >> /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/vdok3-custom.pth\n",
      " ---> Using cache\n",
      " ---> 3b7fa4f87f53\n",
      "Step 28/32 : RUN echo \"/opt/program/vdok3/train/pytorch_advanced/nlp_sentiment_bert\" >> /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/vdok3-custom.pth\n",
      " ---> Using cache\n",
      " ---> 0da9f8e55dcf\n",
      "Step 29/32 : WORKDIR /opt/program/vdok3/train/pytorch_advanced/nlp_sentiment_bert\n",
      " ---> Using cache\n",
      " ---> 85c4183b3e50\n",
      "Step 30/32 : RUN python make_folders_and_data_downloads.py\n",
      " ---> Using cache\n",
      " ---> 2125e32b7b14\n",
      "Step 31/32 : COPY vdok3_sage /opt/program\n",
      " ---> d41d31e61b2d\n",
      "Step 32/32 : WORKDIR /opt/program\n",
      " ---> Running in 74696ded79d7\n",
      "Removing intermediate container 74696ded79d7\n",
      " ---> 691e6f3e358c\n",
      "Successfully built 691e6f3e358c\n",
      "Successfully tagged sagemaker-vdok3-bert-cv-sen:latest\n",
      "The push refers to repository [822408253028.dkr.ecr.us-west-2.amazonaws.com/sagemaker-vdok3-bert-cv-sen]\n",
      "885032acef94: Preparing\n",
      "eb94f24f5ad7: Preparing\n",
      "be23f8a4ed08: Preparing\n",
      "2333bf2d8c34: Preparing\n",
      "bcf0b9fb86f7: Preparing\n",
      "d1c87b4917ba: Preparing\n",
      "1379185bec41: Preparing\n",
      "34c09c07d44f: Preparing\n",
      "8da672bd8fef: Preparing\n",
      "301342a5ac2c: Preparing\n",
      "3ac2454fe7ca: Preparing\n",
      "9b9ef40c3fb2: Preparing\n",
      "49fa2998b485: Preparing\n",
      "72400ed43881: Preparing\n",
      "97e5b4ec388b: Preparing\n",
      "b20c62adb3cf: Preparing\n",
      "bf18a6c0e470: Preparing\n",
      "0de0186b0e0f: Preparing\n",
      "d152753df06e: Preparing\n",
      "653349137921: Preparing\n",
      "e71e95da3d2b: Preparing\n",
      "6d2269456418: Preparing\n",
      "521a1bca4c9e: Preparing\n",
      "0fd113e52582: Preparing\n",
      "9fd67b1e1831: Preparing\n",
      "f1c9680a678d: Preparing\n",
      "fa4b3468268c: Preparing\n",
      "66ad31b9547f: Preparing\n",
      "8d897fc1271a: Preparing\n",
      "b0c360818224: Preparing\n",
      "d35aa7fd29b6: Preparing\n",
      "c0eeb6e15fd7: Preparing\n",
      "91cba8fa7129: Preparing\n",
      "d152753df06e: Waiting\n",
      "653349137921: Waiting\n",
      "e71e95da3d2b: Waiting\n",
      "6d2269456418: Waiting\n",
      "521a1bca4c9e: Waiting\n",
      "0fd113e52582: Waiting\n",
      "9fd67b1e1831: Waiting\n",
      "f1c9680a678d: Waiting\n",
      "fa4b3468268c: Waiting\n",
      "66ad31b9547f: Waiting\n",
      "8d897fc1271a: Waiting\n",
      "b0c360818224: Waiting\n",
      "d35aa7fd29b6: Waiting\n",
      "c0eeb6e15fd7: Waiting\n",
      "91cba8fa7129: Waiting\n",
      "3ac2454fe7ca: Waiting\n",
      "9b9ef40c3fb2: Waiting\n",
      "49fa2998b485: Waiting\n",
      "72400ed43881: Waiting\n",
      "97e5b4ec388b: Waiting\n",
      "b20c62adb3cf: Waiting\n",
      "bf18a6c0e470: Waiting\n",
      "0de0186b0e0f: Waiting\n",
      "d1c87b4917ba: Waiting\n",
      "1379185bec41: Waiting\n",
      "34c09c07d44f: Waiting\n",
      "8da672bd8fef: Waiting\n",
      "301342a5ac2c: Waiting\n",
      "885032acef94: Pushed\n",
      "bcf0b9fb86f7: Pushed\n",
      "2333bf2d8c34: Pushed\n",
      "be23f8a4ed08: Pushed\n",
      "1379185bec41: Pushed\n",
      "34c09c07d44f: Pushed\n",
      "d1c87b4917ba: Pushed\n",
      "9b9ef40c3fb2: Pushed\n",
      "8da672bd8fef: Pushed\n",
      "49fa2998b485: Pushed\n",
      "97e5b4ec388b: Pushed\n",
      "b20c62adb3cf: Pushed\n",
      "bf18a6c0e470: Pushed\n",
      "72400ed43881: Pushed\n",
      "3ac2454fe7ca: Pushed\n",
      "d152753df06e: Pushed\n",
      "653349137921: Pushed\n",
      "6d2269456418: Pushed\n",
      "eb94f24f5ad7: Pushed\n",
      "0fd113e52582: Pushed\n",
      "e71e95da3d2b: Pushed\n",
      "f1c9680a678d: Pushed\n",
      "fa4b3468268c: Pushed\n",
      "66ad31b9547f: Pushed\n",
      "8d897fc1271a: Pushed\n",
      "b0c360818224: Pushed\n",
      "d35aa7fd29b6: Pushed\n",
      "c0eeb6e15fd7: Pushed\n",
      "9fd67b1e1831: Pushed\n",
      "91cba8fa7129: Pushed\n",
      "521a1bca4c9e: Pushed\n",
      "0de0186b0e0f: Pushed\n",
      "301342a5ac2c: Pushed\n",
      "latest: digest: sha256:888cd22efa9b4bff9bd0a65bd2a3526ab3d0793552e6e3dae93f0864f4cbcb3f size: 7229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16 ms, sys: 4.66 ms, total: 20.6 ms\n",
      "Wall time: 5min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "# Makoto.Sano@Mack-the-Psych.com\n",
    "algorithm_name=sagemaker-vdok3-bert-cv-sen\n",
    "\n",
    "cd container\n",
    "\n",
    "chmod +x vdok3_sage/train\n",
    "chmod +x vdok3_sage/serve\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build  -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "# Makoto.Sano@Mack-the-Psych.com\n",
    "prefix = 'vdok3_bert_cv_sen'\n",
    "\n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sess = sage.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIRECTORY = 'data'\n",
    "\n",
    "data_location = sess.upload_data(WORK_DIRECTORY, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-17 03:14:31 Starting - Starting the training job...\n",
      "2021-08-17 03:14:33 Starting - Launching requested ML instancesProfilerReport-1629170071: InProgress\n",
      "......\n",
      "2021-08-17 03:15:46 Starting - Preparing the instances for training.........\n",
      "2021-08-17 03:17:22 Downloading - Downloading input data\n",
      "2021-08-17 03:17:22 Training - Downloading the training image.....................\n",
      "2021-08-17 03:21:03 Training - Training image download completed. Training in progress..\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34mStarting the training.\u001b[0m\n",
      "\u001b[34mbert.embeddings.word_embeddings.weight→embeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.position_embeddings.weight→embeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.token_type_embeddings.weight→embeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.gamma→embeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.beta→embeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.weight→encoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.bias→encoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.weight→encoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.bias→encoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.weight→encoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.bias→encoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.weight→encoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.bias→encoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.gamma→encoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.beta→encoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.weight→encoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.bias→encoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.weight→encoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.bias→encoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.gamma→encoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.beta→encoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.weight→encoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.bias→encoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.weight→encoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.bias→encoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.weight→encoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.bias→encoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.weight→encoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.bias→encoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.gamma→encoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.beta→encoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.weight→encoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.bias→encoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.weight→encoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.bias→encoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.gamma→encoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.beta→encoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.weight→encoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.bias→encoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.weight→encoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.bias→encoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.weight→encoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.bias→encoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.weight→encoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.bias→encoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.gamma→encoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.beta→encoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.weight→encoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.bias→encoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.weight→encoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.bias→encoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.gamma→encoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.beta→encoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.weight→encoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.bias→encoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.weight→encoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.bias→encoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.weight→encoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.bias→encoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.weight→encoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.bias→encoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.gamma→encoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.beta→encoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.weight→encoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.bias→encoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.weight→encoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.bias→encoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.gamma→encoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.beta→encoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.weight→encoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.bias→encoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.weight→encoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.bias→encoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.weight→encoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.bias→encoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.weight→encoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.bias→encoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.gamma→encoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.beta→encoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.weight→encoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.bias→encoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.weight→encoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.bias→encoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.gamma→encoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.beta→encoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.weight→encoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.bias→encoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.weight→encoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.bias→encoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.weight→encoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.bias→encoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.weight→encoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.bias→encoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.gamma→encoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.beta→encoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.weight→encoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.bias→encoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.weight→encoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.bias→encoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.gamma→encoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.beta→encoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.weight→encoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.bias→encoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.weight→encoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.bias→encoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.weight→encoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.bias→encoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.weight→encoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.bias→encoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.gamma→encoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.beta→encoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.weight→encoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.bias→encoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.weight→encoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.bias→encoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.gamma→encoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.beta→encoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.weight→encoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.bias→encoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.weight→encoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.bias→encoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.weight→encoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.bias→encoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.weight→encoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.bias→encoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.gamma→encoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.beta→encoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.weight→encoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.bias→encoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.weight→encoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.bias→encoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.gamma→encoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.beta→encoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.weight→encoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.bias→encoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.weight→encoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.bias→encoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.weight→encoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.bias→encoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.weight→encoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.bias→encoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.gamma→encoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.beta→encoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.weight→encoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.bias→encoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.weight→encoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.bias→encoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.gamma→encoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.beta→encoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.weight→encoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.bias→encoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.weight→encoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.bias→encoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.weight→encoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.bias→encoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.weight→encoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.bias→encoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.gamma→encoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.beta→encoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.weight→encoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.bias→encoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.weight→encoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.bias→encoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.gamma→encoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.beta→encoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.weight→encoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.bias→encoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.weight→encoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.bias→encoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.weight→encoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.bias→encoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.weight→encoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.bias→encoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.gamma→encoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.beta→encoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.weight→encoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.bias→encoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.weight→encoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.bias→encoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.gamma→encoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.beta→encoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.weight→encoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.bias→encoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.weight→encoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.bias→encoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.weight→encoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.bias→encoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.weight→encoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.bias→encoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.gamma→encoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.beta→encoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.weight→encoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.bias→encoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.weight→encoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.bias→encoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.gamma→encoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.beta→encoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.weight→pooler.dense.weight\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.bias→pooler.dense.bias\u001b[0m\n",
      "\u001b[34m----------------\u001b[0m\n",
      "\u001b[34mRANDOM SET:  0\u001b[0m\n",
      "\u001b[34mConcat Value Len: 5020\u001b[0m\n",
      "\u001b[34m(tensor([[  101,  1996,  3778,  ...,     0,     0,     0],\n",
      "        [  101,  2726, 17046,  ...,     0,     0,     0],\n",
      "        [  101,  2017,  2064,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1996,  3011,  ...,     0,     0,     0],\n",
      "        [  101,  3888,  6198,  ...,     0,     0,     0],\n",
      "        [  101,  8836,  4536,  ...,     0,     0,     0]]), tensor([42, 64, 39, 53, 92, 48, 68, 93, 73, 88, 58, 68, 68, 67, 94, 68, 56, 35,\n",
      "        42, 81, 58, 68, 48, 65, 68, 52, 76, 51, 32, 56, 77, 52]))\u001b[0m\n",
      "\u001b[34mtensor([0, 0, 1, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 1, 0])\u001b[0m\n",
      "\u001b[34m['[CLS]', 'thomas', 'edison', 'created', 'the', 'first', 'light', 'bulb', '.', 'he', 'is', 'an', 'inventor', '.', 'sam', 'born', 'created', 'a', 'machine', 'that', 'makes', 'lo', '##lli', '##pop', '##s', '.', 'he', 'is', 'an', 'inventor', '.', 'josephine', 'cochrane', 'created', 'the', 'dish', '##wash', '##er', '.', 'she', 'is', 'an', 'inventor', '.', 'ellen', 'och', '##oa', 'created', 'a', 'system', 'to', 'build', 'things', 'with', 'a', 'robot', '.', 'she', 'is', 'an', 'inventor', '.', 'nr', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34mUsing device:  cuda:0\u001b[0m\n",
      "\u001b[34m-----start-------\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.6384 || 10iter: 0.9513 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.7667 || 10iter: 0.8934 sec. || Accuracy: 0.625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.3566 || 10iter: 0.8938 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.4661 || 10iter: 0.8942 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.3741 || 10iter: 0.8942 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.3908 || 10iter: 0.8936 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.5514 || 10iter: 0.8927 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.5934 || 10iter: 0.8933 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.2101 || 10iter: 0.8954 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.3324 || 10iter: 0.8982 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.2548 || 10iter: 0.8925 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.3247 || 10iter: 0.8927 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mEpoch 1/10 | train |  Loss: 0.5326 Acc: 0.7938\u001b[0m\n",
      "\u001b[34mEpoch 1/10 |  val  |  Loss: 0.5464 Acc: 0.7958\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.4614 || 10iter: 0.9007 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.2780 || 10iter: 0.8940 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.4639 || 10iter: 0.8994 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.4357 || 10iter: 0.9006 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.3218 || 10iter: 0.8947 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.3978 || 10iter: 0.8941 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.4468 || 10iter: 0.8940 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.3369 || 10iter: 0.8943 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.3090 || 10iter: 0.8939 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.4233 || 10iter: 0.8962 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.4476 || 10iter: 0.8964 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.3463 || 10iter: 0.8969 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mEpoch 2/10 | train |  Loss: 0.3678 Acc: 0.8399\u001b[0m\n",
      "\u001b[34mEpoch 2/10 |  val  |  Loss: 0.3777 Acc: 0.8416\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.3860 || 10iter: 0.9030 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.3694 || 10iter: 0.8967 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.3135 || 10iter: 0.8968 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.3281 || 10iter: 0.8967 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.2934 || 10iter: 0.8972 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.4881 || 10iter: 0.8970 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.4835 || 10iter: 0.8963 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.2452 || 10iter: 0.8967 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.3148 || 10iter: 0.8986 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2742 || 10iter: 0.9007 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.3288 || 10iter: 0.8969 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.2547 || 10iter: 0.8977 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mEpoch 3/10 | train |  Loss: 0.3319 Acc: 0.8556\u001b[0m\n",
      "\u001b[34mEpoch 3/10 |  val  |  Loss: 0.3498 Acc: 0.8526\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1737 || 10iter: 0.9040 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.2161 || 10iter: 0.8967 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.2418 || 10iter: 0.8990 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.3783 || 10iter: 0.9005 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.2448 || 10iter: 0.8961 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2171 || 10iter: 0.8957 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.3774 || 10iter: 0.8975 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.3651 || 10iter: 0.8966 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.2158 || 10iter: 0.9008 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.3267 || 10iter: 0.8985 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.2034 || 10iter: 0.8967 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.5524 || 10iter: 0.8972 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mEpoch 4/10 | train |  Loss: 0.3046 Acc: 0.8668\u001b[0m\n",
      "\u001b[34mEpoch 4/10 |  val  |  Loss: 0.3392 Acc: 0.8625\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.3232 || 10iter: 0.9033 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.4025 || 10iter: 0.8970 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.3166 || 10iter: 0.8957 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.3831 || 10iter: 0.8966 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.2777 || 10iter: 0.8960 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2016 || 10iter: 0.9017 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.2209 || 10iter: 0.8993 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.3648 || 10iter: 0.8976 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.2398 || 10iter: 0.8978 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0667 || 10iter: 0.8970 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.2753 || 10iter: 0.8983 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.3530 || 10iter: 0.8984 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mEpoch 5/10 | train |  Loss: 0.2867 Acc: 0.8810\u001b[0m\n",
      "\u001b[34mEpoch 5/10 |  val  |  Loss: 0.3197 Acc: 0.8665\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.2660 || 10iter: 0.9044 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0878 || 10iter: 0.8961 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.3045 || 10iter: 0.8994 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.3146 || 10iter: 0.8979 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.2642 || 10iter: 0.8981 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2277 || 10iter: 0.8968 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.3426 || 10iter: 0.8974 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.4550 || 10iter: 0.8972 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1454 || 10iter: 0.8995 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2739 || 10iter: 0.9006 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.2951 || 10iter: 0.8993 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1762 || 10iter: 0.8996 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mEpoch 6/10 | train |  Loss: 0.2754 Acc: 0.8877\u001b[0m\n",
      "\u001b[34mEpoch 6/10 |  val  |  Loss: 0.3105 Acc: 0.8635\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1828 || 10iter: 0.9051 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.2424 || 10iter: 0.9006 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1494 || 10iter: 0.9014 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.3296 || 10iter: 0.8997 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.2192 || 10iter: 0.8995 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2492 || 10iter: 0.8977 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.3194 || 10iter: 0.8992 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.2512 || 10iter: 0.9009 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.2964 || 10iter: 0.9022 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.3649 || 10iter: 0.9013 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1151 || 10iter: 0.9002 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.2731 || 10iter: 0.8979 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mEpoch 7/10 | train |  Loss: 0.2490 Acc: 0.8999\u001b[0m\n",
      "\u001b[34mEpoch 7/10 |  val  |  Loss: 0.3099 Acc: 0.8715\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0923 || 10iter: 0.9042 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.3677 || 10iter: 0.8977 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.3189 || 10iter: 0.8995 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.2902 || 10iter: 0.9028 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.4084 || 10iter: 0.9059 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.4970 || 10iter: 0.9023 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.2953 || 10iter: 0.9024 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.3428 || 10iter: 0.9008 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.4137 || 10iter: 0.8998 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2619 || 10iter: 0.9001 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0558 || 10iter: 0.9002 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.2935 || 10iter: 0.9008 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mEpoch 8/10 | train |  Loss: 0.2465 Acc: 0.8959\u001b[0m\n",
      "\u001b[34mEpoch 8/10 |  val  |  Loss: 0.3074 Acc: 0.8645\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1594 || 10iter: 0.9047 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1619 || 10iter: 0.8993 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.2862 || 10iter: 0.9049 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.2283 || 10iter: 0.9008 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1765 || 10iter: 0.9025 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.1730 || 10iter: 0.8985 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.2189 || 10iter: 0.8974 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.2872 || 10iter: 0.8984 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.2431 || 10iter: 0.8991 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1809 || 10iter: 0.8995 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1206 || 10iter: 0.8986 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.4156 || 10iter: 0.8998 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mEpoch 9/10 | train |  Loss: 0.2168 Acc: 0.9099\u001b[0m\n",
      "\u001b[34mEpoch 9/10 |  val  |  Loss: 0.3005 Acc: 0.8745\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1761 || 10iter: 0.9038 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1575 || 10iter: 0.8986 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1966 || 10iter: 0.8985 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1294 || 10iter: 0.9001 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1793 || 10iter: 0.8979 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.1829 || 10iter: 0.9010 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1605 || 10iter: 0.9026 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1745 || 10iter: 0.9018 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1527 || 10iter: 0.8991 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2485 || 10iter: 0.8983 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.2571 || 10iter: 0.8982 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1618 || 10iter: 0.9014 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mEpoch 10/10 | train |  Loss: 0.2086 Acc: 0.9156\u001b[0m\n",
      "\u001b[34mEpoch 10/10 |  val  |  Loss: 0.3095 Acc: 0.8775\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/53 [00:00<?, ?it/s]#015  4%|▍         | 2/53 [00:00<00:04, 12.33it/s]#015  8%|▊         | 4/53 [00:00<00:03, 12.25it/s]#015 11%|█▏        | 6/53 [00:00<00:03, 12.24it/s]#015 15%|█▌        | 8/53 [00:00<00:03, 12.24it/s]#015 19%|█▉        | 10/53 [00:00<00:03, 12.21it/s]#015 23%|██▎       | 12/53 [00:00<00:03, 12.20it/s]#015 26%|██▋       | 14/53 [00:01<00:03, 12.19it/s]#015 30%|███       | 16/53 [00:01<00:03, 12.20it/s]#015 34%|███▍      | 18/53 [00:01<00:02, 12.20it/s]#015 38%|███▊      | 20/53 [00:01<00:02, 12.21it/s]#015 42%|████▏     | 22/53 [00:01<00:02, 12.22it/s]#015 45%|████▌     | 24/53 [00:01<00:02, 12.21it/s]#015 49%|████▉     | 26/53 [00:02<00:02, 12.21it/s]#015 53%|█████▎    | 28/53 [00:02<00:02, 12.21it/s]#015 57%|█████▋    | 30/53 [00:02<00:01, 12.22it/s]#015 60%|██████    | 32/53 [00:02<00:01, 12.22it/s]#015 64%|██████▍   | 34/53 [00:02<00:01, 12.21it/s]#015 68%|██████▊   | 36/53 [00:02<00:01, 12.21it/s]#015 72%|███████▏  | 38/53 [00:03<00:01, 12.19it/s]#015 75%|███████▌  | 40/53 [00:03<00:01, 12.20it/s]#015 79%|███████▉  | 42/53 [00:03<00:00, 12.20it/s]#015 83%|████████▎ | 44/53 [00:03<00:00, 12.20it/s]#015 87%|████████▋ | 46/53 [00:03<00:00, 12.20it/s]#015 91%|█████████ | 48/53 [00:03<00:00, 12.20it/s]#015 94%|█████████▍| 50/53 [00:04<00:00, 12.20it/s]#015 98%|█████████▊| 52/53 [00:04<00:00, 12.20it/s]#015100%|██████████| 53/53 [00:04<00:00, 12.36it/s]\u001b[0m\n",
      "\u001b[34mTest Data 1673 Accuracy: 0.9050\u001b[0m\n",
      "\u001b[34mRecall                      0.9050\u001b[0m\n",
      "\u001b[34mPrecision                   0.8997\u001b[0m\n",
      "\u001b[34mF1                          0.9006\u001b[0m\n",
      "\u001b[34mKappa                       0.7507\u001b[0m\n",
      "\u001b[34mQuadratic Weighted Kappa    0.8113\u001b[0m\n",
      "\u001b[34mdtype: float64\u001b[0m\n",
      "\u001b[34mConfusion Matrix:\n",
      "      0    1   2  3\u001b[0m\n",
      "\u001b[34m0  1239   19   7  2\u001b[0m\n",
      "\u001b[34m1    49  188  20  0\u001b[0m\n",
      "\u001b[34m2    16   27  82  1\u001b[0m\n",
      "\u001b[34m3     3    0  15  5\u001b[0m\n",
      "\u001b[34m----------------\u001b[0m\n",
      "\u001b[34mRANDOM SET:  1\u001b[0m\n",
      "\u001b[34mConcat Value Len: 5020\u001b[0m\n",
      "\u001b[34m(tensor([[  101,  1996,  3778,  ...,     0,     0,     0],\n",
      "        [  101,  2726, 17046,  ...,     0,     0,     0],\n",
      "        [  101,  2017,  2064,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1996,  3011,  ...,     0,     0,     0],\n",
      "        [  101,  2116,  7074,  ...,     0,     0,     0],\n",
      "        [  101,  8836,  4536,  ...,     0,     0,     0]]), tensor([ 42,  64,  39,  53,  36,  82,  68,  93,  73,  71,  99,  68,  68,  67,\n",
      "         42,  23,  56,  35,  80,  81,  58, 126,  93,  65,  68,  82,  81,  51,\n",
      "         32,  56,  32,  52]))\u001b[0m\n",
      "\u001b[34mtensor([0, 0, 1, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 2, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0])\u001b[0m\n",
      "\u001b[34m['[CLS]', 'thomas', 'edison', 'created', 'the', 'first', 'light', 'bulb', '.', 'he', 'is', 'an', 'inventor', '.', 'sam', 'born', 'created', 'a', 'machine', 'that', 'makes', 'lo', '##lli', '##pop', '##s', '.', 'he', 'is', 'an', 'inventor', '.', 'josephine', 'cochrane', 'created', 'the', 'dish', '##wash', '##er', '.', 'she', 'is', 'an', 'inventor', '.', 'ellen', 'och', '##oa', 'created', 'a', 'system', 'to', 'build', 'things', 'with', 'a', 'robot', '.', 'she', 'is', 'an', 'inventor', '.', 'nr', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34mUsing device:  cuda:0\u001b[0m\n",
      "\u001b[34m-----start-------\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.3527 || 10iter: 0.9022 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.2172 || 10iter: 0.8980 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0964 || 10iter: 0.8999 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1908 || 10iter: 0.9051 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.2939 || 10iter: 0.9021 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0313 || 10iter: 0.8997 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.3866 || 10iter: 0.8991 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.2643 || 10iter: 0.8986 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.2245 || 10iter: 0.8996 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1708 || 10iter: 0.9060 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1856 || 10iter: 0.9056 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1870 || 10iter: 0.9013 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mEpoch 1/10 | train |  Loss: 0.3156 Acc: 0.8765\u001b[0m\n",
      "\u001b[34mEpoch 1/10 |  val  |  Loss: 0.2832 Acc: 0.8904\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.3067 || 10iter: 0.9059 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1754 || 10iter: 0.9019 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.2345 || 10iter: 0.9014 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.2439 || 10iter: 0.9038 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1402 || 10iter: 0.9019 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2305 || 10iter: 0.9023 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1574 || 10iter: 0.9049 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.2343 || 10iter: 0.9012 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1720 || 10iter: 0.9003 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2863 || 10iter: 0.8996 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.2156 || 10iter: 0.9010 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.3092 || 10iter: 0.9019 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mEpoch 2/10 | train |  Loss: 0.2327 Acc: 0.9036\u001b[0m\n",
      "\u001b[34mEpoch 2/10 |  val  |  Loss: 0.2746 Acc: 0.8865\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.2061 || 10iter: 0.9085 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1931 || 10iter: 0.9038 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1050 || 10iter: 0.9004 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1331 || 10iter: 0.9007 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1556 || 10iter: 0.9008 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2624 || 10iter: 0.9012 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.2122 || 10iter: 0.9007 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.0730 || 10iter: 0.9008 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1635 || 10iter: 0.9017 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2819 || 10iter: 0.9026 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1021 || 10iter: 0.9047 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1151 || 10iter: 0.9007 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 3/10 | train |  Loss: 0.2101 Acc: 0.9161\u001b[0m\n",
      "\u001b[34mEpoch 3/10 |  val  |  Loss: 0.2811 Acc: 0.8884\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1088 || 10iter: 0.9120 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.2413 || 10iter: 0.9061 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1442 || 10iter: 0.9061 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.2230 || 10iter: 0.9066 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1429 || 10iter: 0.9061 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2739 || 10iter: 0.9034 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1724 || 10iter: 0.9037 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.2437 || 10iter: 0.9033 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.0826 || 10iter: 0.9056 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2766 || 10iter: 0.9042 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.2301 || 10iter: 0.9029 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1437 || 10iter: 0.9028 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 4/10 | train |  Loss: 0.2011 Acc: 0.9161\u001b[0m\n",
      "\u001b[34mEpoch 4/10 |  val  |  Loss: 0.2674 Acc: 0.8875\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1183 || 10iter: 0.9103 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.4974 || 10iter: 0.9056 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1439 || 10iter: 0.9061 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.2663 || 10iter: 0.9059 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1281 || 10iter: 0.9105 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2336 || 10iter: 0.9089 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0834 || 10iter: 0.9112 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.0800 || 10iter: 0.9063 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1378 || 10iter: 0.9053 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0852 || 10iter: 0.9056 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1797 || 10iter: 0.9062 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1744 || 10iter: 0.9084 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mEpoch 5/10 | train |  Loss: 0.1882 Acc: 0.9260\u001b[0m\n",
      "\u001b[34mEpoch 5/10 |  val  |  Loss: 0.2824 Acc: 0.8954\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1514 || 10iter: 0.9154 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1097 || 10iter: 0.9099 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.2769 || 10iter: 0.9087 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.0954 || 10iter: 0.9090 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1153 || 10iter: 0.9059 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.3078 || 10iter: 0.9088 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1632 || 10iter: 0.9066 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1781 || 10iter: 0.9048 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.3645 || 10iter: 0.9038 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1068 || 10iter: 0.9057 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1323 || 10iter: 0.9041 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1308 || 10iter: 0.9036 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 6/10 | train |  Loss: 0.1743 Acc: 0.9338\u001b[0m\n",
      "\u001b[34mEpoch 6/10 |  val  |  Loss: 0.3096 Acc: 0.8775\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.2421 || 10iter: 0.9097 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1168 || 10iter: 0.9055 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.2392 || 10iter: 0.9049 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1382 || 10iter: 0.9058 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0982 || 10iter: 0.9051 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.1136 || 10iter: 0.9067 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.2559 || 10iter: 0.9093 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1651 || 10iter: 0.9058 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.2326 || 10iter: 0.9058 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2460 || 10iter: 0.9088 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1671 || 10iter: 0.9071 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1435 || 10iter: 0.9057 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mEpoch 7/10 | train |  Loss: 0.1594 Acc: 0.9328\u001b[0m\n",
      "\u001b[34mEpoch 7/10 |  val  |  Loss: 0.2520 Acc: 0.9034\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0437 || 10iter: 0.9094 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1479 || 10iter: 0.9093 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1305 || 10iter: 0.9121 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.2847 || 10iter: 0.9129 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1757 || 10iter: 0.9099 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2080 || 10iter: 0.9133 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1041 || 10iter: 0.9060 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1842 || 10iter: 0.9075 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.0604 || 10iter: 0.9082 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2153 || 10iter: 0.9068 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0562 || 10iter: 0.9073 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.2032 || 10iter: 0.9082 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mEpoch 8/10 | train |  Loss: 0.1455 Acc: 0.9417\u001b[0m\n",
      "\u001b[34mEpoch 8/10 |  val  |  Loss: 0.2822 Acc: 0.8884\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0585 || 10iter: 0.9148 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0707 || 10iter: 0.9099 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.2189 || 10iter: 0.9090 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1558 || 10iter: 0.9089 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0639 || 10iter: 0.9141 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.1263 || 10iter: 0.9116 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.2347 || 10iter: 0.9111 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.2161 || 10iter: 0.9090 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1762 || 10iter: 0.9087 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1768 || 10iter: 0.9108 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.2353 || 10iter: 0.9083 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1737 || 10iter: 0.9033 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mEpoch 9/10 | train |  Loss: 0.1413 Acc: 0.9447\u001b[0m\n",
      "\u001b[34mEpoch 9/10 |  val  |  Loss: 0.2578 Acc: 0.8994\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0661 || 10iter: 0.9126 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0844 || 10iter: 0.9085 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1288 || 10iter: 0.9075 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1283 || 10iter: 0.9081 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0266 || 10iter: 0.9077 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.1613 || 10iter: 0.9116 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.2109 || 10iter: 0.9100 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.2104 || 10iter: 0.9073 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1232 || 10iter: 0.9061 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0277 || 10iter: 0.9044 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.2013 || 10iter: 0.9063 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0656 || 10iter: 0.9080 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mEpoch 10/10 | train |  Loss: 0.1296 Acc: 0.9485\u001b[0m\n",
      "\u001b[34mEpoch 10/10 |  val  |  Loss: 0.2874 Acc: 0.8914\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/53 [00:00<?, ?it/s]#015  4%|▍         | 2/53 [00:00<00:04, 12.14it/s]#015  8%|▊         | 4/53 [00:00<00:04, 12.15it/s]#015 11%|█▏        | 6/53 [00:00<00:03, 12.13it/s]#015 15%|█▌        | 8/53 [00:00<00:03, 12.12it/s]#015 19%|█▉        | 10/53 [00:00<00:03, 12.11it/s]#015 23%|██▎       | 12/53 [00:00<00:03, 12.11it/s]#015 26%|██▋       | 14/53 [00:01<00:03, 12.13it/s]#015 30%|███       | 16/53 [00:01<00:03, 12.13it/s]#015 34%|███▍      | 18/53 [00:01<00:02, 12.12it/s]#015 38%|███▊      | 20/53 [00:01<00:02, 12.15it/s]#015 42%|████▏     | 22/53 [00:01<00:02, 12.14it/s]#015 45%|████▌     | 24/53 [00:01<00:02, 12.14it/s]#015 49%|████▉     | 26/53 [00:02<00:02, 12.14it/s]#015 53%|█████▎    | 28/53 [00:02<00:02, 12.15it/s]#015 57%|█████▋    | 30/53 [00:02<00:01, 12.13it/s]#015 60%|██████    | 32/53 [00:02<00:01, 12.12it/s]#015 64%|██████▍   | 34/53 [00:02<00:01, 12.15it/s]#015 68%|██████▊   | 36/53 [00:02<00:01, 12.14it/s]#015 72%|███████▏  | 38/53 [00:03<00:01, 12.12it/s]#015 75%|███████▌  | 40/53 [00:03<00:01, 12.11it/s]#015 79%|███████▉  | 42/53 [00:03<00:00, 12.12it/s]#015 83%|████████▎ | 44/53 [00:03<00:00, 12.14it/s]#015 87%|████████▋ | 46/53 [00:03<00:00, 12.15it/s]#015 91%|█████████ | 48/53 [00:03<00:00, 12.13it/s]#015 94%|█████████▍| 50/53 [00:04<00:00, 12.10it/s]#015 98%|█████████▊| 52/53 [00:04<00:00, 12.11it/s]#015100%|██████████| 53/53 [00:04<00:00, 12.28it/s]\u001b[0m\n",
      "\u001b[34mTest Data 1673 Accuracy: 0.9277\u001b[0m\n",
      "\u001b[34mRecall                      0.9277\u001b[0m\n",
      "\u001b[34mPrecision                   0.9297\u001b[0m\n",
      "\u001b[34mF1                          0.9285\u001b[0m\n",
      "\u001b[34mKappa                       0.8140\u001b[0m\n",
      "\u001b[34mQuadratic Weighted Kappa    0.8651\u001b[0m\n",
      "\u001b[34mdtype: float64\u001b[0m\n",
      "\u001b[34mConfusion Matrix:\n",
      "      0    1   2   3\u001b[0m\n",
      "\u001b[34m0  1247   28   9   1\u001b[0m\n",
      "\u001b[34m1    16  196  29   1\u001b[0m\n",
      "\u001b[34m2     5   20  99   4\u001b[0m\n",
      "\u001b[34m3     3    1   4  10\u001b[0m\n",
      "\u001b[34m----------------\u001b[0m\n",
      "\u001b[34mRANDOM SET:  2\u001b[0m\n",
      "\u001b[34mConcat Value Len: 5020\u001b[0m\n",
      "\u001b[34m(tensor([[  101,  1996,  4650,  ...,     0,     0,     0],\n",
      "        [  101,  2726, 17046,  ...,     0,     0,     0],\n",
      "        [  101,  2023, 12779,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1996,  4650,  ...,     0,     0,     0],\n",
      "        [  101,  2116,  7074,  ...,     0,     0,     0],\n",
      "        [  101,  8836,  4536,  ...,     0,     0,     0]]), tensor([ 53,  64,  74,  63,  36,  82,  68,  56,  82,  71,  99,  68,  68,  67,\n",
      "         42,  23,  68,  56,  80,  81,  75, 126,  93,  65,  42,  82,  81,  51,\n",
      "         32,  53,  32,  52]))\u001b[0m\n",
      "\u001b[34mtensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 2, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0])\u001b[0m\n",
      "\u001b[34m['[CLS]', 'thomas', 'edison', 'created', 'the', 'first', 'light', 'bulb', '.', 'he', 'is', 'an', 'inventor', '.', 'sam', 'born', 'created', 'a', 'machine', 'that', 'makes', 'lo', '##lli', '##pop', '##s', '.', 'he', 'is', 'an', 'inventor', '.', 'josephine', 'cochrane', 'created', 'the', 'dish', '##wash', '##er', '.', 'she', 'is', 'an', 'inventor', '.', 'ellen', 'och', '##oa', 'created', 'a', 'system', 'to', 'build', 'things', 'with', 'a', 'robot', '.', 'she', 'is', 'an', 'inventor', '.', 'nr', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34mUsing device:  cuda:0\u001b[0m\n",
      "\u001b[34m-----start-------\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.3257 || 10iter: 0.9072 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1590 || 10iter: 0.9020 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0900 || 10iter: 0.9019 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.2384 || 10iter: 0.8989 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.2956 || 10iter: 0.9009 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2453 || 10iter: 0.9036 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1735 || 10iter: 0.9019 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.2376 || 10iter: 0.9024 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.2579 || 10iter: 0.9039 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2821 || 10iter: 0.9019 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1149 || 10iter: 0.9042 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.2180 || 10iter: 0.9029 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mEpoch 1/10 | train |  Loss: 0.2451 Acc: 0.9026\u001b[0m\n",
      "\u001b[34mEpoch 1/10 |  val  |  Loss: 0.2444 Acc: 0.9074\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1609 || 10iter: 0.9110 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1894 || 10iter: 0.8978 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1031 || 10iter: 0.9041 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.2371 || 10iter: 0.9050 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1185 || 10iter: 0.9104 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2315 || 10iter: 0.8980 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0505 || 10iter: 0.8963 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1887 || 10iter: 0.8958 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1050 || 10iter: 0.9000 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2315 || 10iter: 0.9024 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.3016 || 10iter: 0.9032 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.2069 || 10iter: 0.9054 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mEpoch 2/10 | train |  Loss: 0.1675 Acc: 0.9320\u001b[0m\n",
      "\u001b[34mEpoch 2/10 |  val  |  Loss: 0.2457 Acc: 0.9104\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0466 || 10iter: 0.9073 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1252 || 10iter: 0.8998 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1919 || 10iter: 0.8945 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1067 || 10iter: 0.8993 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.2205 || 10iter: 0.8995 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.1461 || 10iter: 0.8987 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0754 || 10iter: 0.8977 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1369 || 10iter: 0.8970 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1384 || 10iter: 0.8956 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1594 || 10iter: 0.8994 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0910 || 10iter: 0.9013 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0775 || 10iter: 0.8971 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 3/10 | train |  Loss: 0.1549 Acc: 0.9380\u001b[0m\n",
      "\u001b[34mEpoch 3/10 |  val  |  Loss: 0.2546 Acc: 0.9064\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0410 || 10iter: 0.9035 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1310 || 10iter: 0.8953 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1127 || 10iter: 0.8990 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1196 || 10iter: 0.9024 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1396 || 10iter: 0.9022 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0974 || 10iter: 0.9013 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.2137 || 10iter: 0.9000 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.2560 || 10iter: 0.9018 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.0694 || 10iter: 0.9029 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1006 || 10iter: 0.9034 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.2670 || 10iter: 0.9026 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1092 || 10iter: 0.8985 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 4/10 | train |  Loss: 0.1348 Acc: 0.9472\u001b[0m\n",
      "\u001b[34mEpoch 4/10 |  val  |  Loss: 0.2434 Acc: 0.9114\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1472 || 10iter: 0.9088 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1671 || 10iter: 0.8972 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0382 || 10iter: 0.9010 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1995 || 10iter: 0.8992 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0738 || 10iter: 0.8994 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0967 || 10iter: 0.9014 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0381 || 10iter: 0.8966 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1770 || 10iter: 0.8981 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1891 || 10iter: 0.8979 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2470 || 10iter: 0.8945 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0651 || 10iter: 0.8936 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1204 || 10iter: 0.8961 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mEpoch 5/10 | train |  Loss: 0.1281 Acc: 0.9460\u001b[0m\n",
      "\u001b[34mEpoch 5/10 |  val  |  Loss: 0.2461 Acc: 0.9133\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0678 || 10iter: 0.9017 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0931 || 10iter: 0.8991 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0878 || 10iter: 0.9008 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.0343 || 10iter: 0.9004 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0302 || 10iter: 0.9009 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.1857 || 10iter: 0.9038 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1455 || 10iter: 0.9044 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1875 || 10iter: 0.9015 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1788 || 10iter: 0.8993 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0996 || 10iter: 0.8976 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1586 || 10iter: 0.9003 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1588 || 10iter: 0.8995 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 6/10 | train |  Loss: 0.1180 Acc: 0.9559\u001b[0m\n",
      "\u001b[34mEpoch 6/10 |  val  |  Loss: 0.2764 Acc: 0.8994\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0219 || 10iter: 0.9018 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0755 || 10iter: 0.8955 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0719 || 10iter: 0.9008 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1133 || 10iter: 0.9022 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1930 || 10iter: 0.8958 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.1223 || 10iter: 0.8958 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0547 || 10iter: 0.8961 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.0679 || 10iter: 0.8958 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.0656 || 10iter: 0.8962 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0769 || 10iter: 0.8965 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1716 || 10iter: 0.8993 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0955 || 10iter: 0.8955 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mEpoch 7/10 | train |  Loss: 0.1116 Acc: 0.9577\u001b[0m\n",
      "\u001b[34mEpoch 7/10 |  val  |  Loss: 0.2548 Acc: 0.9163\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0824 || 10iter: 0.9047 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.2076 || 10iter: 0.8951 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1763 || 10iter: 0.8951 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1428 || 10iter: 0.8984 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0984 || 10iter: 0.8961 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2358 || 10iter: 0.8978 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0619 || 10iter: 0.8975 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1735 || 10iter: 0.8966 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.0437 || 10iter: 0.8978 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1178 || 10iter: 0.8976 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1560 || 10iter: 0.8965 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0652 || 10iter: 0.8957 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 8/10 | train |  Loss: 0.1046 Acc: 0.9602\u001b[0m\n",
      "\u001b[34mEpoch 8/10 |  val  |  Loss: 0.2691 Acc: 0.9104\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1046 || 10iter: 0.9009 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0140 || 10iter: 0.8946 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0862 || 10iter: 0.8976 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1201 || 10iter: 0.8974 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0266 || 10iter: 0.8980 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.1022 || 10iter: 0.8978 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1084 || 10iter: 0.8981 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1020 || 10iter: 0.8995 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1046 || 10iter: 0.8990 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1775 || 10iter: 0.9020 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.3000 || 10iter: 0.9028 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1199 || 10iter: 0.9009 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 9/10 | train |  Loss: 0.1007 Acc: 0.9629\u001b[0m\n",
      "\u001b[34mEpoch 9/10 |  val  |  Loss: 0.2800 Acc: 0.9094\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0399 || 10iter: 0.9029 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0570 || 10iter: 0.8960 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0489 || 10iter: 0.9011 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.0194 || 10iter: 0.9018 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0406 || 10iter: 0.9029 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0876 || 10iter: 0.9083 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0669 || 10iter: 0.9029 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1470 || 10iter: 0.8964 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1125 || 10iter: 0.8959 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0077 || 10iter: 0.9035 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0344 || 10iter: 0.8986 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1727 || 10iter: 0.8964 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mEpoch 10/10 | train |  Loss: 0.0922 Acc: 0.9674\u001b[0m\n",
      "\u001b[34mEpoch 10/10 |  val  |  Loss: 0.2701 Acc: 0.9143\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/53 [00:00<?, ?it/s]#015  4%|▍         | 2/53 [00:00<00:04, 12.35it/s]#015  8%|▊         | 4/53 [00:00<00:03, 12.34it/s]#015 11%|█▏        | 6/53 [00:00<00:03, 12.32it/s]#015 15%|█▌        | 8/53 [00:00<00:03, 12.32it/s]#015 19%|█▉        | 10/53 [00:00<00:03, 12.28it/s]#015 23%|██▎       | 12/53 [00:00<00:03, 12.25it/s]#015 26%|██▋       | 14/53 [00:01<00:03, 12.25it/s]#015 30%|███       | 16/53 [00:01<00:03, 12.26it/s]#015 34%|███▍      | 18/53 [00:01<00:02, 12.26it/s]#015 38%|███▊      | 20/53 [00:01<00:02, 12.25it/s]#015 42%|████▏     | 22/53 [00:01<00:02, 12.23it/s]#015 45%|████▌     | 24/53 [00:01<00:02, 12.24it/s]#015 49%|████▉     | 26/53 [00:02<00:02, 12.23it/s]#015 53%|█████▎    | 28/53 [00:02<00:02, 12.22it/s]#015 57%|█████▋    | 30/53 [00:02<00:01, 12.23it/s]#015 60%|██████    | 32/53 [00:02<00:01, 12.23it/s]#015 64%|██████▍   | 34/53 [00:02<00:01, 12.26it/s]#015 68%|██████▊   | 36/53 [00:02<00:01, 12.24it/s]#015 72%|███████▏  | 38/53 [00:03<00:01, 12.23it/s]#015 75%|███████▌  | 40/53 [00:03<00:01, 12.24it/s]#015 79%|███████▉  | 42/53 [00:03<00:00, 12.27it/s]#015 83%|████████▎ | 44/53 [00:03<00:00, 12.24it/s]#015 87%|████████▋ | 46/53 [00:03<00:00, 12.23it/s]#015 91%|█████████ | 48/53 [00:03<00:00, 12.22it/s]#015 94%|█████████▍| 50/53 [00:04<00:00, 12.24it/s]#015 98%|█████████▊| 52/53 [00:04<00:00, 12.27it/s]#015100%|██████████| 53/53 [00:04<00:00, 12.41it/s]\u001b[0m\n",
      "\u001b[34mTest Data 1673 Accuracy: 0.9331\u001b[0m\n",
      "\u001b[34mRecall                      0.9331\u001b[0m\n",
      "\u001b[34mPrecision                   0.9373\u001b[0m\n",
      "\u001b[34mF1                          0.9345\u001b[0m\n",
      "\u001b[34mKappa                       0.8349\u001b[0m\n",
      "\u001b[34mQuadratic Weighted Kappa    0.8677\u001b[0m\n",
      "\u001b[34mdtype: float64\u001b[0m\n",
      "\u001b[34mConfusion Matrix:\n",
      "      0    1   2  3\u001b[0m\n",
      "\u001b[34m0  1217   31  15  0\u001b[0m\n",
      "\u001b[34m1    17  240  26  0\u001b[0m\n",
      "\u001b[34m2     6   14  95  0\u001b[0m\n",
      "\u001b[34m3     1    0   2  9\u001b[0m\n",
      "\u001b[34m----------------\u001b[0m\n",
      "\u001b[34mRANDOM SET:  3\u001b[0m\n",
      "\u001b[34mConcat Value Len: 5019\u001b[0m\n",
      "\u001b[34m(tensor([[  101,  2726, 17046,  ...,     0,     0,     0],\n",
      "        [  101,  2017,  2064,  ...,     0,     0,     0],\n",
      "        [  101,  1045,  3266,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  9155, 28166,  ...,     0,     0,     0],\n",
      "        [  101,  9155,  7126,  ...,     0,     0,     0],\n",
      "        [  101,  9155,  7126,  ...,     0,     0,     0]]), tensor([ 69,  41,  23,  56,  92,  68,  35,  58,  63,  82,  85,  41,  84,  71,\n",
      "         99,  35,  92,  81,  23,  99,  63,  57, 127,  56,  78,  93,  32,  99,\n",
      "         68,  81,  60,  58]))\u001b[0m\n",
      "\u001b[34mtensor([1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0])\u001b[0m\n",
      "\u001b[34m['[CLS]', 'you', 'can', 'measure', 'how', 'long', 'something', 'is', 'with', 'a', 'ruler', '.', 'you', 'can', 'measure', 'weight', 'with', 'a', 'scale', '.', 'you', 'can', 'measure', 'pressure', 'in', 'the', 'atmosphere', 'with', 'a', 'bar', '##ometer', '.', 'i', 'measure', 'to', 'see', 'how', 'long', 'things', 'are', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34mUsing device:  cuda:0\u001b[0m\n",
      "\u001b[34m-----start-------\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.5137 || 10iter: 0.8986 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.2853 || 10iter: 0.8961 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1461 || 10iter: 0.8980 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.3350 || 10iter: 0.8969 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.3363 || 10iter: 0.8975 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2634 || 10iter: 0.8936 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0998 || 10iter: 0.8966 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1926 || 10iter: 0.8944 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1782 || 10iter: 0.8942 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.3495 || 10iter: 0.8943 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.2010 || 10iter: 0.8943 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1882 || 10iter: 0.8941 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mEpoch 1/10 | train |  Loss: 0.3006 Acc: 0.8802\u001b[0m\n",
      "\u001b[34mEpoch 1/10 |  val  |  Loss: 0.1618 Acc: 0.9373\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1825 || 10iter: 0.9047 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1758 || 10iter: 0.9000 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1845 || 10iter: 0.8974 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.0812 || 10iter: 0.8946 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1087 || 10iter: 0.8958 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2881 || 10iter: 0.8928 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0955 || 10iter: 0.8938 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.0471 || 10iter: 0.8937 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.0869 || 10iter: 0.8940 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2355 || 10iter: 0.8940 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0902 || 10iter: 0.8947 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.2500 || 10iter: 0.9049 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mEpoch 2/10 | train |  Loss: 0.1549 Acc: 0.9397\u001b[0m\n",
      "\u001b[34mEpoch 2/10 |  val  |  Loss: 0.1847 Acc: 0.9373\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.4508 || 10iter: 0.9021 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1252 || 10iter: 0.8999 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0894 || 10iter: 0.9096 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.2308 || 10iter: 0.9006 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.2749 || 10iter: 0.8987 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.1728 || 10iter: 0.8973 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0904 || 10iter: 0.8967 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1225 || 10iter: 0.8973 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.2635 || 10iter: 0.8956 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0993 || 10iter: 0.8965 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1374 || 10iter: 0.8996 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.2760 || 10iter: 0.9025 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mEpoch 3/10 | train |  Loss: 0.1446 Acc: 0.9457\u001b[0m\n",
      "\u001b[34mEpoch 3/10 |  val  |  Loss: 0.1617 Acc: 0.9442\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0437 || 10iter: 0.9021 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1980 || 10iter: 0.8953 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1238 || 10iter: 0.8951 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1718 || 10iter: 0.8953 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1382 || 10iter: 0.8952 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0327 || 10iter: 0.8963 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1643 || 10iter: 0.8969 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1392 || 10iter: 0.8967 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1282 || 10iter: 0.8959 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0306 || 10iter: 0.8948 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1220 || 10iter: 0.8960 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1453 || 10iter: 0.8956 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mEpoch 4/10 | train |  Loss: 0.1199 Acc: 0.9537\u001b[0m\n",
      "\u001b[34mEpoch 4/10 |  val  |  Loss: 0.1784 Acc: 0.9333\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1093 || 10iter: 0.9022 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0904 || 10iter: 0.9020 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0763 || 10iter: 0.9009 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1475 || 10iter: 0.8989 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0261 || 10iter: 0.8981 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0550 || 10iter: 0.9031 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1064 || 10iter: 0.8991 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.2578 || 10iter: 0.8983 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1445 || 10iter: 0.8991 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1340 || 10iter: 0.8987 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0665 || 10iter: 0.8993 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0776 || 10iter: 0.8973 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 5/10 | train |  Loss: 0.1210 Acc: 0.9549\u001b[0m\n",
      "\u001b[34mEpoch 5/10 |  val  |  Loss: 0.1810 Acc: 0.9422\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1800 || 10iter: 0.9033 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0452 || 10iter: 0.8978 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0945 || 10iter: 0.8985 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.0826 || 10iter: 0.9001 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1030 || 10iter: 0.8976 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0761 || 10iter: 0.8996 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0708 || 10iter: 0.9002 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1997 || 10iter: 0.9002 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.0646 || 10iter: 0.9017 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0266 || 10iter: 0.9004 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0365 || 10iter: 0.9003 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0715 || 10iter: 0.9010 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 6/10 | train |  Loss: 0.1006 Acc: 0.9639\u001b[0m\n",
      "\u001b[34mEpoch 6/10 |  val  |  Loss: 0.1954 Acc: 0.9363\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0547 || 10iter: 0.9135 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0722 || 10iter: 0.9030 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1263 || 10iter: 0.9022 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1391 || 10iter: 0.9089 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0544 || 10iter: 0.9059 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0984 || 10iter: 0.9035 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1187 || 10iter: 0.9007 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.0629 || 10iter: 0.9007 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1141 || 10iter: 0.9015 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0633 || 10iter: 0.9009 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0086 || 10iter: 0.8990 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0443 || 10iter: 0.9023 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 7/10 | train |  Loss: 0.0953 Acc: 0.9629\u001b[0m\n",
      "\u001b[34mEpoch 7/10 |  val  |  Loss: 0.1848 Acc: 0.9412\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0826 || 10iter: 0.9104 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.3063 || 10iter: 0.9016 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0453 || 10iter: 0.9018 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1745 || 10iter: 0.9005 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0818 || 10iter: 0.9027 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0403 || 10iter: 0.8970 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0775 || 10iter: 0.8990 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.0302 || 10iter: 0.9701 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1044 || 10iter: 1.0041 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0694 || 10iter: 1.0397 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1572 || 10iter: 0.8993 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0476 || 10iter: 0.8976 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 8/10 | train |  Loss: 0.0920 Acc: 0.9654\u001b[0m\n",
      "\u001b[34mEpoch 8/10 |  val  |  Loss: 0.1928 Acc: 0.9353\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0707 || 10iter: 0.9735 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0801 || 10iter: 0.8997 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1421 || 10iter: 0.9052 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.0268 || 10iter: 0.8956 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0780 || 10iter: 0.8968 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0129 || 10iter: 0.8961 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1001 || 10iter: 0.8949 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.0725 || 10iter: 0.8939 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.0570 || 10iter: 0.8944 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1249 || 10iter: 0.8986 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.3140 || 10iter: 0.9017 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.2807 || 10iter: 1.0099 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mEpoch 9/10 | train |  Loss: 0.0906 Acc: 0.9639\u001b[0m\n",
      "\u001b[34mEpoch 9/10 |  val  |  Loss: 0.1927 Acc: 0.9343\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0431 || 10iter: 0.9057 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0372 || 10iter: 0.9002 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0911 || 10iter: 0.9003 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.0679 || 10iter: 0.9004 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0708 || 10iter: 0.9013 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0854 || 10iter: 0.9009 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0170 || 10iter: 0.9583 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1696 || 10iter: 1.1138 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1087 || 10iter: 0.9405 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0154 || 10iter: 0.9014 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0602 || 10iter: 0.9481 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0808 || 10iter: 1.0457 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 10/10 | train |  Loss: 0.0814 Acc: 0.9716\u001b[0m\n",
      "\u001b[34mEpoch 10/10 |  val  |  Loss: 0.1875 Acc: 0.9422\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/53 [00:00<?, ?it/s]#015  4%|▍         | 2/53 [00:00<00:04, 12.23it/s]#015  8%|▊         | 4/53 [00:00<00:04, 11.95it/s]#015 11%|█▏        | 6/53 [00:00<00:03, 12.04it/s]#015 15%|█▌        | 8/53 [00:00<00:03, 12.06it/s]#015 19%|█▉        | 10/53 [00:00<00:03, 12.07it/s]#015 23%|██▎       | 12/53 [00:00<00:03, 12.10it/s]#015 26%|██▋       | 14/53 [00:01<00:03, 12.13it/s]#015 30%|███       | 16/53 [00:01<00:03, 12.17it/s]#015 34%|███▍      | 18/53 [00:01<00:02, 12.20it/s]#015 38%|███▊      | 20/53 [00:01<00:02, 12.23it/s]#015 42%|████▏     | 22/53 [00:01<00:02, 12.24it/s]#015 45%|████▌     | 24/53 [00:01<00:02, 12.27it/s]#015 49%|████▉     | 26/53 [00:02<00:02, 12.29it/s]#015 53%|█████▎    | 28/53 [00:02<00:02, 12.30it/s]#015 57%|█████▋    | 30/53 [00:02<00:01, 12.31it/s]#015 60%|██████    | 32/53 [00:02<00:01, 12.31it/s]#015 64%|██████▍   | 34/53 [00:02<00:01, 12.30it/s]#015 68%|██████▊   | 36/53 [00:02<00:01, 12.31it/s]#015 72%|███████▏  | 38/53 [00:03<00:01, 12.31it/s]#015 75%|███████▌  | 40/53 [00:03<00:01, 12.30it/s]#015 79%|███████▉  | 42/53 [00:03<00:00, 12.29it/s]#015 83%|████████▎ | 44/53 [00:03<00:00, 12.31it/s]#015 87%|████████▋ | 46/53 [00:03<00:00, 12.31it/s]#015 91%|█████████ | 48/53 [00:03<00:00, 12.31it/s]#015 94%|█████████▍| 50/53 [00:04<00:00, 12.30it/s]#015 98%|█████████▊| 52/53 [00:04<00:00, 12.31it/s]#015100%|██████████| 53/53 [00:04<00:00, 12.39it/s]\u001b[0m\n",
      "\u001b[34mTest Data 1674 Accuracy: 0.9534\u001b[0m\n",
      "\u001b[34mRecall                      0.9534\u001b[0m\n",
      "\u001b[34mPrecision                   0.9551\u001b[0m\n",
      "\u001b[34mF1                          0.9539\u001b[0m\n",
      "\u001b[34mKappa                       0.8868\u001b[0m\n",
      "\u001b[34mQuadratic Weighted Kappa    0.9292\u001b[0m\n",
      "\u001b[34mdtype: float64\u001b[0m\n",
      "\u001b[34mConfusion Matrix:\n",
      "      0    1    2  3\u001b[0m\n",
      "\u001b[34m0  1227   26    3  1\u001b[0m\n",
      "\u001b[34m1     7  247   14  0\u001b[0m\n",
      "\u001b[34m2     0   19  114  2\u001b[0m\n",
      "\u001b[34m3     1    0    5  8\u001b[0m\n",
      "\u001b[34m----------------\u001b[0m\n",
      "\u001b[34mALL DATA (Macro Average):\n",
      "         Recall  Precision        F1     Kappa  Quadratic Weighted Kappa\u001b[0m\n",
      "\u001b[34mcount  4.000000   4.000000  4.000000  4.000000                  4.000000\u001b[0m\n",
      "\u001b[34mmean   0.929800   0.930450  0.929375  0.821600                  0.868325\u001b[0m\n",
      "\u001b[34mstd    0.019894   0.023099  0.022034  0.056310                  0.048195\u001b[0m\n",
      "\u001b[34mmin    0.905000   0.899700  0.900600  0.750700                  0.811300\u001b[0m\n",
      "\u001b[34m25%    0.922025   0.922200  0.921525  0.798175                  0.851650\u001b[0m\n",
      "\u001b[34m50%    0.930400   0.933500  0.931500  0.824450                  0.866400\u001b[0m\n",
      "\u001b[34m75%    0.938175   0.941750  0.939350  0.847875                  0.883075\u001b[0m\n",
      "\u001b[34mmax    0.953400   0.955100  0.953900  0.886800                  0.929200\u001b[0m\n",
      "\u001b[34m----------------\u001b[0m\n",
      "\u001b[34mALL DATA (Micro Average):\u001b[0m\n",
      "\u001b[34mRecall                      0.9298\u001b[0m\n",
      "\u001b[34mPrecision                   0.9304\u001b[0m\n",
      "\u001b[34mF1                          0.9298\u001b[0m\n",
      "\u001b[34mKappa                       0.8231\u001b[0m\n",
      "\u001b[34mQuadratic Weighted Kappa    0.8686\u001b[0m\n",
      "\u001b[34mdtype: float64\u001b[0m\n",
      "\u001b[34mConfusion Matrix:\n",
      "      0    1    2   3\u001b[0m\n",
      "\u001b[34m0  4930  104   34   4\u001b[0m\n",
      "\u001b[34m1    89  871   89   1\u001b[0m\n",
      "\u001b[34m2    27   80  390   7\u001b[0m\n",
      "\u001b[34m3     8    1   26  32\u001b[0m\n",
      "\u001b[34mTraining complete.\u001b[0m\n",
      "\n",
      "2021-08-17 03:32:26 Uploading - Uploading generated training model\n",
      "2021-08-17 03:35:26 Completed - Training job completed\n",
      "ProfilerReport-1629170071: IssuesFound\n",
      "Training seconds: 1091\n",
      "Billable seconds: 1091\n"
     ]
    }
   ],
   "source": [
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "\n",
    "# Makoto.Sano@Mack-the-Psych.com\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/sagemaker-vdok3-bert-cv-sen:latest'.format(account, region)\n",
    "vdok3bert = sage.estimator.Estimator(image,\n",
    "                       role, 1, 'ml.p3.2xlarge',\n",
    "                       output_path=\"s3://{}/output\".format(sess.default_bucket()),\n",
    "                       sagemaker_session=sess)\n",
    "vdok3bert.fit(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "predictor = vdok3bert.deploy(1, 'ml.p3.2xlarge', serializer=csv_serializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score_Class,Sentence-Score\n",
      "0,0\n",
      "2,1\n",
      "2,2\n",
      "2,3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_in = pd.read_csv('data/Pick4-Refmt_Serialized-Sen-ELVA.PILOT.PRE-POST-TEST.csv')\n",
    "np_in = np.vstack((np.array(df_in.columns), df_in.to_numpy()))\n",
    "print(predictor.predict(np_in).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "sess.delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_output_folder = \"batch-transform-output\"\n",
    "output_path=\"s3://{}/{}\".format(sess.default_bucket(), transform_output_folder)\n",
    "\n",
    "transformer = vdok3bert.transformer(instance_count=1,\n",
    "                               instance_type='ml.p3.2xlarge',\n",
    "                               output_path=output_path,\n",
    "                               assemble_with='Line',\n",
    "                               accept='text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................\u001b[34mStarting the inference server with 8 workers.\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:49:10 +0000] [41] [INFO] Starting gunicorn 20.1.0\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:49:10 +0000] [41] [INFO] Listening at: unix:/tmp/gunicorn.sock (41)\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:49:10 +0000] [41] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:49:10 +0000] [45] [INFO] Booting worker with pid: 45\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:49:10 +0000] [46] [INFO] Booting worker with pid: 46\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:49:10 +0000] [47] [INFO] Booting worker with pid: 47\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:49:10 +0000] [55] [INFO] Booting worker with pid: 55\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:49:10 +0000] [63] [INFO] Booting worker with pid: 63\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:49:10 +0000] [71] [INFO] Booting worker with pid: 71\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:49:10 +0000] [79] [INFO] Booting worker with pid: 79\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:49:10 +0000] [80] [INFO] Booting worker with pid: 80\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34mbert.embeddings.word_embeddings.weight→embeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.position_embeddings.weight→embeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.token_type_embeddings.weight→embeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.gamma→embeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.beta→embeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.weight→encoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.bias→encoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.weight→encoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.bias→encoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.weight→encoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.bias→encoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.weight→encoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.bias→encoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.gamma→encoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.beta→encoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.weight→encoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.bias→encoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.weight→encoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.bias→encoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.gamma→encoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.beta→encoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.weight→encoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.bias→encoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.weight→encoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.bias→encoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.weight→encoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.bias→encoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.weight→encoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.bias→encoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.gamma→encoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.beta→encoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.weight→encoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.bias→encoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.weight→encoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.bias→encoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.gamma→encoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.beta→encoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.weight→encoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.bias→encoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.weight→encoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.bias→encoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.weight→encoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.bias→encoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.weight→encoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.bias→encoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.gamma→encoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.beta→encoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.weight→encoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.bias→encoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.weight→encoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.bias→encoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.gamma→encoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.beta→encoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.weight→encoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.bias→encoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.weight→encoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.bias→encoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.weight→encoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.bias→encoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.weight→encoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.bias→encoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.gamma→encoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.beta→encoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.weight→encoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.bias→encoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.weight→encoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.bias→encoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.gamma→encoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.beta→encoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.weight→encoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.bias→encoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.weight→encoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.bias→encoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.weight→encoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.bias→encoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.weight→encoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.bias→encoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.gamma→encoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.beta→encoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.weight→encoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.bias→encoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.weight→encoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.bias→encoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.gamma→encoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.beta→encoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.weight→encoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.bias→encoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.weight→encoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.bias→encoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.weight→encoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.bias→encoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.weight→encoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.bias→encoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.gamma→encoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.beta→encoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.weight→encoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.bias→encoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.weight→encoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.bias→encoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.gamma→encoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.beta→encoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.weight→encoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.bias→encoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.weight→encoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.bias→encoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.weight→encoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.bias→encoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.weight→encoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.bias→encoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.gamma→encoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.beta→encoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.weight→encoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.bias→encoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.weight→encoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.bias→encoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.gamma→encoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.beta→encoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.weight→encoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.bias→encoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.weight→encoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.bias→encoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.weight→encoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.bias→encoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.weight→encoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.bias→encoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.gamma→encoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.beta→encoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.weight→encoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.bias→encoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.weight→encoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.bias→encoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.gamma→encoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.beta→encoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.weight→encoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.bias→encoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.weight→encoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.bias→encoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.weight→encoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.bias→encoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.weight→encoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.bias→encoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.gamma→encoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.beta→encoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.weight→encoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.bias→encoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.weight→encoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.bias→encoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.gamma→encoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.beta→encoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.weight→encoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.bias→encoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.weight→encoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.bias→encoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.weight→encoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.bias→encoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.weight→encoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.bias→encoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.gamma→encoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.beta→encoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.weight→encoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.bias→encoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.weight→encoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.bias→encoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.gamma→encoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.beta→encoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.weight→encoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.bias→encoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.weight→encoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.bias→encoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.weight→encoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.bias→encoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.weight→encoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.bias→encoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.gamma→encoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.beta→encoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.weight→encoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.bias→encoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.weight→encoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.bias→encoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.gamma→encoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.beta→encoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.weight→encoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.bias→encoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.weight→encoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.bias→encoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.weight→encoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.bias→encoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.weight→encoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.bias→encoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.gamma→encoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.beta→encoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.weight→encoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.bias→encoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.weight→encoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.bias→encoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.gamma→encoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.beta→encoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.weight→pooler.dense.weight\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.bias→pooler.dense.bias\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Aug/2021:03:49:28 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Aug/2021:03:49:28 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 4 records\u001b[0m\n",
      "\u001b[34mbert.embeddings.word_embeddings.weight→embeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.position_embeddings.weight→embeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.token_type_embeddings.weight→embeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.gamma→embeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.beta→embeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.weight→encoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.bias→encoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.weight→encoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.bias→encoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.weight→encoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.bias→encoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.weight→encoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.bias→encoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.gamma→encoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.beta→encoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.weight→encoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.bias→encoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.weight→encoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.bias→encoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.gamma→encoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.beta→encoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.weight→encoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.bias→encoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.weight→encoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.bias→encoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.weight→encoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.bias→encoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.weight→encoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.bias→encoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.gamma→encoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.beta→encoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.weight→encoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.bias→encoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.weight→encoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.bias→encoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.gamma→encoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.beta→encoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.weight→encoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.bias→encoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.weight→encoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.bias→encoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.weight→encoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.bias→encoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.weight→encoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.bias→encoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.gamma→encoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.beta→encoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.weight→encoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.bias→encoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.weight→encoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.bias→encoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.gamma→encoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.beta→encoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.weight→encoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.bias→encoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.weight→encoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.bias→encoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.weight→encoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.bias→encoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.weight→encoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.bias→encoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.gamma→encoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.beta→encoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.weight→encoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.bias→encoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.weight→encoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.bias→encoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.gamma→encoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.beta→encoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.weight→encoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.bias→encoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.weight→encoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.bias→encoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.weight→encoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.bias→encoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.weight→encoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.bias→encoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.gamma→encoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.beta→encoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.weight→encoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.bias→encoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.weight→encoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.bias→encoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.gamma→encoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.beta→encoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.weight→encoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.bias→encoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.weight→encoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.bias→encoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.weight→encoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.bias→encoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.weight→encoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.bias→encoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.gamma→encoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.beta→encoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.weight→encoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.bias→encoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.weight→encoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.bias→encoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.gamma→encoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.beta→encoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.weight→encoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.bias→encoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.weight→encoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.bias→encoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.weight→encoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.bias→encoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.weight→encoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.bias→encoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.gamma→encoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.beta→encoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.weight→encoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.bias→encoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.weight→encoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.bias→encoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.gamma→encoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.beta→encoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.weight→encoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.bias→encoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.weight→encoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.bias→encoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.weight→encoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.bias→encoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.weight→encoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.bias→encoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.gamma→encoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.beta→encoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.weight→encoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.bias→encoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.weight→encoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.bias→encoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.gamma→encoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.beta→encoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.weight→encoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.bias→encoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.weight→encoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.bias→encoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.weight→encoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.bias→encoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.weight→encoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.bias→encoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.gamma→encoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.beta→encoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.weight→encoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.bias→encoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.weight→encoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.bias→encoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.gamma→encoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.beta→encoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.weight→encoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.bias→encoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.weight→encoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.bias→encoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.weight→encoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.bias→encoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.weight→encoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.bias→encoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.gamma→encoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.beta→encoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.weight→encoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.bias→encoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.weight→encoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.bias→encoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.gamma→encoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.beta→encoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.weight→encoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.bias→encoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.weight→encoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.bias→encoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.weight→encoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.bias→encoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.weight→encoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.bias→encoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.gamma→encoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.beta→encoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.weight→encoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.bias→encoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.weight→encoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.bias→encoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.gamma→encoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.beta→encoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.weight→encoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.bias→encoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.weight→encoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.bias→encoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.weight→encoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.bias→encoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.weight→encoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.bias→encoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.gamma→encoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.beta→encoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.weight→encoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.bias→encoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.weight→encoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.bias→encoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.gamma→encoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.beta→encoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.weight→pooler.dense.weight\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.bias→pooler.dense.bias\u001b[0m\n",
      "\u001b[32m2021-08-17T03:49:28.294:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/1 [00:00<?, ?it/s]#015100%|██████████| 1/1 [00:00<00:00, 40.21it/s]\u001b[0m\n",
      "\u001b[34mTest Data 4 Accuracy: 0.5000\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Aug/2021:03:49:37 +0000] \"POST /invocations HTTP/1.1\" 200 43 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m#015  0%|          | 0/1 [00:00<?, ?it/s]#015100%|██████████| 1/1 [00:00<00:00, 40.21it/s]\u001b[0m\n",
      "\u001b[35mTest Data 4 Accuracy: 0.5000\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [17/Aug/2021:03:49:37 +0000] \"POST /invocations HTTP/1.1\" 200 43 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\n",
      "\u001b[34mStarting the inference server with 8 workers.\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:49:10 +0000] [41] [INFO] Starting gunicorn 20.1.0\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:49:10 +0000] [41] [INFO] Listening at: unix:/tmp/gunicorn.sock (41)\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:49:10 +0000] [41] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:49:10 +0000] [45] [INFO] Booting worker with pid: 45\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:49:10 +0000] [46] [INFO] Booting worker with pid: 46\u001b[0m\n",
      "\u001b[35mStarting the inference server with 8 workers.\u001b[0m\n",
      "\u001b[35m[2021-08-17 03:49:10 +0000] [41] [INFO] Starting gunicorn 20.1.0\u001b[0m\n",
      "\u001b[35m[2021-08-17 03:49:10 +0000] [41] [INFO] Listening at: unix:/tmp/gunicorn.sock (41)\u001b[0m\n",
      "\u001b[35m[2021-08-17 03:49:10 +0000] [41] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2021-08-17 03:49:10 +0000] [45] [INFO] Booting worker with pid: 45\u001b[0m\n",
      "\u001b[35m[2021-08-17 03:49:10 +0000] [46] [INFO] Booting worker with pid: 46\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:49:10 +0000] [47] [INFO] Booting worker with pid: 47\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:49:10 +0000] [55] [INFO] Booting worker with pid: 55\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:49:10 +0000] [63] [INFO] Booting worker with pid: 63\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:49:10 +0000] [71] [INFO] Booting worker with pid: 71\u001b[0m\n",
      "\u001b[35m[2021-08-17 03:49:10 +0000] [47] [INFO] Booting worker with pid: 47\u001b[0m\n",
      "\u001b[35m[2021-08-17 03:49:10 +0000] [55] [INFO] Booting worker with pid: 55\u001b[0m\n",
      "\u001b[35m[2021-08-17 03:49:10 +0000] [63] [INFO] Booting worker with pid: 63\u001b[0m\n",
      "\u001b[35m[2021-08-17 03:49:10 +0000] [71] [INFO] Booting worker with pid: 71\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:49:10 +0000] [79] [INFO] Booting worker with pid: 79\u001b[0m\n",
      "\u001b[34m[2021-08-17 03:49:10 +0000] [80] [INFO] Booting worker with pid: 80\u001b[0m\n",
      "\u001b[35m[2021-08-17 03:49:10 +0000] [79] [INFO] Booting worker with pid: 79\u001b[0m\n",
      "\u001b[35m[2021-08-17 03:49:10 +0000] [80] [INFO] Booting worker with pid: 80\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34mbert.embeddings.word_embeddings.weight→embeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.position_embeddings.weight→embeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.token_type_embeddings.weight→embeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.gamma→embeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.beta→embeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.weight→encoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.bias→encoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.weight→encoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.bias→encoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.weight→encoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.bias→encoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.embeddings.word_embeddings.weight→embeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[35mbert.embeddings.position_embeddings.weight→embeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[35mbert.embeddings.token_type_embeddings.weight→embeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[35mbert.embeddings.LayerNorm.gamma→embeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.embeddings.LayerNorm.beta→embeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.query.weight→encoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.query.bias→encoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.key.weight→encoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.key.bias→encoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.value.weight→encoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.value.bias→encoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.weight→encoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.bias→encoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.gamma→encoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.beta→encoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.weight→encoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.bias→encoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.weight→encoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.bias→encoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.gamma→encoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.beta→encoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.weight→encoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.bias→encoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.weight→encoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.bias→encoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.weight→encoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.bias→encoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.weight→encoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.bias→encoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.gamma→encoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.dense.weight→encoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.dense.bias→encoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.LayerNorm.gamma→encoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.LayerNorm.beta→encoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.intermediate.dense.weight→encoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.intermediate.dense.bias→encoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.dense.weight→encoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.dense.bias→encoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.LayerNorm.gamma→encoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.LayerNorm.beta→encoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.query.weight→encoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.query.bias→encoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.key.weight→encoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.key.bias→encoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.value.weight→encoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.value.bias→encoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.dense.weight→encoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.dense.bias→encoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.LayerNorm.gamma→encoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.beta→encoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.weight→encoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.bias→encoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.weight→encoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.bias→encoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.gamma→encoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.beta→encoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.weight→encoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.bias→encoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.weight→encoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.bias→encoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.weight→encoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.bias→encoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.weight→encoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.bias→encoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.gamma→encoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.beta→encoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.weight→encoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.bias→encoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.weight→encoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.LayerNorm.beta→encoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.intermediate.dense.weight→encoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.intermediate.dense.bias→encoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.dense.weight→encoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.dense.bias→encoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.LayerNorm.gamma→encoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.LayerNorm.beta→encoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.query.weight→encoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.query.bias→encoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.key.weight→encoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.key.bias→encoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.value.weight→encoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.value.bias→encoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.dense.weight→encoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.dense.bias→encoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.LayerNorm.gamma→encoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.LayerNorm.beta→encoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.intermediate.dense.weight→encoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.intermediate.dense.bias→encoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.dense.weight→encoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.bias→encoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.gamma→encoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.beta→encoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.weight→encoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.bias→encoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.weight→encoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.bias→encoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.weight→encoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.bias→encoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.weight→encoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.bias→encoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.gamma→encoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.beta→encoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.weight→encoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.dense.bias→encoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.LayerNorm.gamma→encoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.LayerNorm.beta→encoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.query.weight→encoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.query.bias→encoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.key.weight→encoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.key.bias→encoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.value.weight→encoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.value.bias→encoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.dense.weight→encoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.dense.bias→encoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.LayerNorm.gamma→encoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.LayerNorm.beta→encoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.intermediate.dense.weight→encoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.bias→encoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.weight→encoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.bias→encoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.gamma→encoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.beta→encoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.weight→encoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.bias→encoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.weight→encoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.bias→encoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.weight→encoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.bias→encoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.weight→encoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.bias→encoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.gamma→encoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.beta→encoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.weight→encoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.bias→encoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.intermediate.dense.bias→encoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.dense.weight→encoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.dense.bias→encoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.LayerNorm.gamma→encoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.LayerNorm.beta→encoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.query.weight→encoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.query.bias→encoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.key.weight→encoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.key.bias→encoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.value.weight→encoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.value.bias→encoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.dense.weight→encoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.dense.bias→encoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.LayerNorm.gamma→encoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.LayerNorm.beta→encoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.intermediate.dense.weight→encoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.intermediate.dense.bias→encoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.weight→encoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.bias→encoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.gamma→encoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.beta→encoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.weight→encoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.bias→encoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.weight→encoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.bias→encoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.weight→encoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.bias→encoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.weight→encoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.bias→encoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.gamma→encoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.beta→encoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.weight→encoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.dense.weight→encoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.dense.bias→encoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.LayerNorm.gamma→encoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.LayerNorm.beta→encoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.query.weight→encoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.query.bias→encoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.key.weight→encoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.key.bias→encoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.value.weight→encoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.value.bias→encoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.dense.weight→encoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.dense.bias→encoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.LayerNorm.gamma→encoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.LayerNorm.beta→encoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.intermediate.dense.weight→encoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.bias→encoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.weight→encoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.bias→encoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.gamma→encoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.beta→encoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.weight→encoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.bias→encoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.weight→encoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.bias→encoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.weight→encoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.bias→encoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.weight→encoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.intermediate.dense.bias→encoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.dense.weight→encoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.dense.bias→encoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.LayerNorm.gamma→encoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.LayerNorm.beta→encoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.query.weight→encoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.query.bias→encoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.key.weight→encoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.key.bias→encoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.value.weight→encoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.value.bias→encoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.dense.weight→encoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.bias→encoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.gamma→encoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.beta→encoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.weight→encoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.bias→encoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.weight→encoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.bias→encoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.gamma→encoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.beta→encoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.weight→encoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.bias→encoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.weight→encoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.bias→encoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.weight→encoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.bias→encoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.dense.bias→encoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.LayerNorm.gamma→encoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.LayerNorm.beta→encoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.intermediate.dense.weight→encoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.intermediate.dense.bias→encoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.dense.weight→encoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.dense.bias→encoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.LayerNorm.gamma→encoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.LayerNorm.beta→encoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.query.weight→encoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.query.bias→encoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.key.weight→encoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.key.bias→encoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.value.weight→encoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.value.bias→encoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.weight→encoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.bias→encoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.gamma→encoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.beta→encoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.weight→encoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.bias→encoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.weight→encoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.bias→encoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.gamma→encoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.beta→encoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.weight→encoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.bias→encoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.weight→encoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.bias→encoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.weight→encoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.bias→encoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.dense.weight→encoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.dense.bias→encoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.LayerNorm.gamma→encoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.LayerNorm.beta→encoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.intermediate.dense.weight→encoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.intermediate.dense.bias→encoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.dense.weight→encoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.dense.bias→encoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.LayerNorm.gamma→encoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.LayerNorm.beta→encoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.query.weight→encoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.query.bias→encoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.key.weight→encoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.key.bias→encoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.value.weight→encoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.value.bias→encoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.weight→encoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.bias→encoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.gamma→encoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.beta→encoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.weight→encoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.bias→encoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.weight→encoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.bias→encoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.gamma→encoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.beta→encoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.weight→encoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.bias→encoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.weight→encoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.bias→encoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.weight→encoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.dense.weight→encoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.dense.bias→encoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.LayerNorm.gamma→encoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.LayerNorm.beta→encoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.intermediate.dense.weight→encoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.intermediate.dense.bias→encoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.dense.weight→encoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.dense.bias→encoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.LayerNorm.gamma→encoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.LayerNorm.beta→encoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.query.weight→encoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.query.bias→encoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.key.weight→encoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.key.bias→encoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.value.weight→encoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.bias→encoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.weight→encoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.bias→encoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.gamma→encoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.beta→encoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.weight→encoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.bias→encoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.weight→encoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.bias→encoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.gamma→encoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.beta→encoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.weight→encoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.bias→encoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.weight→encoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.bias→encoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.weight→encoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.value.bias→encoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.dense.weight→encoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.dense.bias→encoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.LayerNorm.gamma→encoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.LayerNorm.beta→encoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.intermediate.dense.weight→encoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.intermediate.dense.bias→encoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.dense.weight→encoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.dense.bias→encoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.LayerNorm.gamma→encoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.LayerNorm.beta→encoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.query.weight→encoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.query.bias→encoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.key.weight→encoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.key.bias→encoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.value.weight→encoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.bias→encoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.weight→encoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.bias→encoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.gamma→encoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.beta→encoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.weight→encoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.bias→encoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.weight→encoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.bias→encoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.gamma→encoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.beta→encoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.weight→encoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.bias→encoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.weight→encoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.value.bias→encoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.dense.weight→encoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.dense.bias→encoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.LayerNorm.gamma→encoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.LayerNorm.beta→encoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.intermediate.dense.weight→encoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.intermediate.dense.bias→encoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.dense.weight→encoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.dense.bias→encoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.LayerNorm.gamma→encoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.LayerNorm.beta→encoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.query.weight→encoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.query.bias→encoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.key.weight→encoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.bias→encoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.weight→encoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.bias→encoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.weight→encoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.bias→encoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.gamma→encoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.beta→encoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.weight→encoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.bias→encoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.weight→encoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.bias→encoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.gamma→encoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.beta→encoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.weight→pooler.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.key.bias→encoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.value.weight→encoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.value.bias→encoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.dense.weight→encoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.dense.bias→encoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.LayerNorm.gamma→encoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.LayerNorm.beta→encoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.intermediate.dense.weight→encoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.intermediate.dense.bias→encoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.dense.weight→encoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.dense.bias→encoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.LayerNorm.gamma→encoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.LayerNorm.beta→encoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.pooler.dense.weight→pooler.dense.weight\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.bias→pooler.dense.bias\u001b[0m\n",
      "\u001b[35mbert.pooler.dense.bias→pooler.dense.bias\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Aug/2021:03:49:28 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Aug/2021:03:49:28 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 4 records\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [17/Aug/2021:03:49:28 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [17/Aug/2021:03:49:28 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 4 records\u001b[0m\n",
      "\u001b[32m2021-08-17T03:49:28.294:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34mbert.embeddings.word_embeddings.weight→embeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.position_embeddings.weight→embeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.token_type_embeddings.weight→embeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.gamma→embeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.beta→embeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.weight→encoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.bias→encoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.weight→encoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.bias→encoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.weight→encoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.bias→encoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.weight→encoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.bias→encoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.gamma→encoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.beta→encoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.weight→encoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.bias→encoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.weight→encoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.bias→encoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.gamma→encoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.beta→encoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.weight→encoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.bias→encoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.weight→encoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.bias→encoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.weight→encoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.bias→encoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.embeddings.word_embeddings.weight→embeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[35mbert.embeddings.position_embeddings.weight→embeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[35mbert.embeddings.token_type_embeddings.weight→embeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[35mbert.embeddings.LayerNorm.gamma→embeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.embeddings.LayerNorm.beta→embeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.query.weight→encoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.query.bias→encoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.key.weight→encoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.key.bias→encoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.value.weight→encoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.value.bias→encoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.dense.weight→encoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.dense.bias→encoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.LayerNorm.gamma→encoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.LayerNorm.beta→encoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.intermediate.dense.weight→encoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.intermediate.dense.bias→encoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.dense.weight→encoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.dense.bias→encoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.LayerNorm.gamma→encoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.LayerNorm.beta→encoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.query.weight→encoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.query.bias→encoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.key.weight→encoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.key.bias→encoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.value.weight→encoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.value.bias→encoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.weight→encoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.bias→encoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.gamma→encoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.beta→encoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.weight→encoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.bias→encoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.weight→encoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.bias→encoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.gamma→encoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.beta→encoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.weight→encoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.bias→encoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.weight→encoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.bias→encoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.weight→encoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.bias→encoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.weight→encoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.bias→encoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.gamma→encoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.beta→encoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.weight→encoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.bias→encoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.weight→encoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.bias→encoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.gamma→encoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.beta→encoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.weight→encoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.bias→encoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.weight→encoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.bias→encoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.weight→encoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.bias→encoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.weight→encoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.dense.weight→encoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.dense.bias→encoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.LayerNorm.gamma→encoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.LayerNorm.beta→encoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.intermediate.dense.weight→encoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.intermediate.dense.bias→encoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.dense.weight→encoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.dense.bias→encoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.LayerNorm.gamma→encoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.LayerNorm.beta→encoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.query.weight→encoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.query.bias→encoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.key.weight→encoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.key.bias→encoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.value.weight→encoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.value.bias→encoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.dense.weight→encoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.dense.bias→encoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.LayerNorm.gamma→encoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.LayerNorm.beta→encoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.intermediate.dense.weight→encoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.intermediate.dense.bias→encoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.dense.weight→encoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.dense.bias→encoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.LayerNorm.gamma→encoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.LayerNorm.beta→encoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.query.weight→encoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.query.bias→encoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.key.weight→encoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.key.bias→encoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.value.weight→encoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.value.bias→encoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.dense.weight→encoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.bias→encoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.gamma→encoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.beta→encoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.weight→encoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.bias→encoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.weight→encoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.bias→encoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.gamma→encoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.beta→encoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.weight→encoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.bias→encoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.weight→encoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.bias→encoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.weight→encoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.bias→encoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.weight→encoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.bias→encoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.gamma→encoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.beta→encoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.weight→encoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.bias→encoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.weight→encoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.bias→encoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.gamma→encoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.beta→encoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.weight→encoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.bias→encoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.weight→encoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.bias→encoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.weight→encoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.bias→encoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.weight→encoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.bias→encoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.gamma→encoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.beta→encoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.weight→encoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.bias→encoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.weight→encoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.bias→encoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.dense.bias→encoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.LayerNorm.gamma→encoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.LayerNorm.beta→encoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.intermediate.dense.weight→encoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.intermediate.dense.bias→encoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.dense.weight→encoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.dense.bias→encoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.LayerNorm.gamma→encoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.LayerNorm.beta→encoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.query.weight→encoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.query.bias→encoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.key.weight→encoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.key.bias→encoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.value.weight→encoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.value.bias→encoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.dense.weight→encoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.dense.bias→encoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.LayerNorm.gamma→encoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.LayerNorm.beta→encoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.intermediate.dense.weight→encoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.intermediate.dense.bias→encoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.dense.weight→encoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.dense.bias→encoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.LayerNorm.gamma→encoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.LayerNorm.beta→encoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.query.weight→encoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.query.bias→encoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.key.weight→encoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.key.bias→encoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.value.weight→encoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.value.bias→encoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.dense.weight→encoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.dense.bias→encoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.LayerNorm.gamma→encoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.LayerNorm.beta→encoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.intermediate.dense.weight→encoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.intermediate.dense.bias→encoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.dense.weight→encoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.dense.bias→encoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.gamma→encoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.beta→encoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.weight→encoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.bias→encoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.weight→encoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.bias→encoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.weight→encoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.bias→encoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.weight→encoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.bias→encoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.gamma→encoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.beta→encoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.weight→encoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.bias→encoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.weight→encoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.bias→encoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.gamma→encoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.beta→encoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.weight→encoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.bias→encoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.weight→encoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.bias→encoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.weight→encoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.bias→encoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.weight→encoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.bias→encoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.gamma→encoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.beta→encoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.weight→encoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.bias→encoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.weight→encoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.bias→encoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.gamma→encoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.beta→encoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.weight→encoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.bias→encoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.weight→encoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.bias→encoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.LayerNorm.gamma→encoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.LayerNorm.beta→encoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.query.weight→encoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.query.bias→encoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.key.weight→encoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.key.bias→encoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.value.weight→encoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.value.bias→encoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.dense.weight→encoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.dense.bias→encoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.LayerNorm.gamma→encoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.LayerNorm.beta→encoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.intermediate.dense.weight→encoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.intermediate.dense.bias→encoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.dense.weight→encoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.dense.bias→encoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.LayerNorm.gamma→encoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.LayerNorm.beta→encoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.query.weight→encoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.query.bias→encoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.key.weight→encoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.key.bias→encoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.value.weight→encoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.value.bias→encoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.dense.weight→encoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.dense.bias→encoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.LayerNorm.gamma→encoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.LayerNorm.beta→encoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.intermediate.dense.weight→encoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.intermediate.dense.bias→encoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.dense.weight→encoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.dense.bias→encoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.LayerNorm.gamma→encoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.LayerNorm.beta→encoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.query.weight→encoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.query.bias→encoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.key.weight→encoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.key.bias→encoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.weight→encoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.bias→encoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.weight→encoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.bias→encoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.gamma→encoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.beta→encoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.weight→encoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.bias→encoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.weight→encoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.bias→encoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.gamma→encoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.beta→encoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.weight→encoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.bias→encoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.weight→encoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.bias→encoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.weight→encoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.bias→encoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.weight→encoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.bias→encoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.gamma→encoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.beta→encoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.weight→encoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.bias→encoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.weight→encoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.bias→encoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.gamma→encoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.beta→encoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.weight→encoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.bias→encoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.weight→encoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.bias→encoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.weight→encoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.bias→encoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.weight→encoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.bias→encoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.gamma→encoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.beta→encoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.weight→encoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.value.weight→encoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.value.bias→encoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.dense.weight→encoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.dense.bias→encoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.LayerNorm.gamma→encoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.LayerNorm.beta→encoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.intermediate.dense.weight→encoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.intermediate.dense.bias→encoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.dense.weight→encoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.dense.bias→encoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.LayerNorm.gamma→encoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.LayerNorm.beta→encoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.query.weight→encoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.query.bias→encoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.key.weight→encoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.key.bias→encoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.value.weight→encoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.value.bias→encoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.dense.weight→encoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.dense.bias→encoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.LayerNorm.gamma→encoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.LayerNorm.beta→encoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.intermediate.dense.weight→encoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.intermediate.dense.bias→encoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.dense.weight→encoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.dense.bias→encoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.LayerNorm.gamma→encoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.LayerNorm.beta→encoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.query.weight→encoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.query.bias→encoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.key.weight→encoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.key.bias→encoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.value.weight→encoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.value.bias→encoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.dense.weight→encoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.dense.bias→encoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.LayerNorm.gamma→encoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.LayerNorm.beta→encoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.intermediate.dense.weight→encoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.bias→encoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.weight→encoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.bias→encoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.gamma→encoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.beta→encoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.weight→encoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.bias→encoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.weight→encoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.bias→encoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.weight→encoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.bias→encoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.weight→encoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.bias→encoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.gamma→encoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.beta→encoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.weight→encoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.bias→encoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.weight→encoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.bias→encoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.gamma→encoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.beta→encoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.weight→pooler.dense.weight\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.bias→pooler.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.intermediate.dense.bias→encoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.dense.weight→encoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.dense.bias→encoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.LayerNorm.gamma→encoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.LayerNorm.beta→encoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.query.weight→encoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.query.bias→encoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.key.weight→encoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.key.bias→encoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.value.weight→encoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.value.bias→encoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.dense.weight→encoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.dense.bias→encoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.LayerNorm.gamma→encoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.LayerNorm.beta→encoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.intermediate.dense.weight→encoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.intermediate.dense.bias→encoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.dense.weight→encoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.dense.bias→encoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.LayerNorm.gamma→encoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.LayerNorm.beta→encoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.pooler.dense.weight→pooler.dense.weight\u001b[0m\n",
      "\u001b[35mbert.pooler.dense.bias→pooler.dense.bias\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/1 [00:00<?, ?it/s]#015100%|██████████| 1/1 [00:00<00:00, 40.21it/s]\u001b[0m\n",
      "\u001b[34mTest Data 4 Accuracy: 0.5000\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Aug/2021:03:49:37 +0000] \"POST /invocations HTTP/1.1\" 200 43 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m#015  0%|          | 0/1 [00:00<?, ?it/s]#015100%|██████████| 1/1 [00:00<00:00, 40.21it/s]\u001b[0m\n",
      "\u001b[35mTest Data 4 Accuracy: 0.5000\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [17/Aug/2021:03:49:37 +0000] \"POST /invocations HTTP/1.1\" 200 43 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "Transform results: \n",
      "Score_Class,Sentence-Score\n",
      "0,0\n",
      "2,1\n",
      "2,2\n",
      "2,3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformer.transform(data_location + '/Pick4-Refmt_Serialized-Sen-ELVA.PILOT.PRE-POST-TEST.csv', content_type='text/csv', split_type='Line')\n",
    "transformer.wait()\n",
    "\n",
    "s3_client = sess.boto_session.client('s3')\n",
    "s3_client.download_file(sess.default_bucket(), \"{}/Pick4-Refmt_Serialized-Sen-ELVA.PILOT.PRE-POST-TEST.csv.out\".format(transform_output_folder), '/tmp/Pick4-Refmt_Serialized-Sen-ELVA.PILOT.PRE-POST-TEST.csv.out')\n",
    "with open('/tmp/Pick4-Refmt_Serialized-Sen-ELVA.PILOT.PRE-POST-TEST.csv.out') as f:\n",
    "    results = f.readlines()   \n",
    "print(\"Transform results: \\n{}\".format(''.join(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
