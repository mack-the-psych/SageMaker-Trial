{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Sending build context to Docker daemon  40.45kB\n",
      "Step 1/32 : FROM nvidia/cuda:10.0-cudnn7-devel-ubuntu16.04\n",
      " ---> a2b601423810\n",
      "Step 2/32 : RUN apt-get -y update && apt-get -y upgrade && apt-get install -y --no-install-recommends          curl          git          unzip          bzip2          libgl1-mesa-glx          wget          nginx          ca-certificates     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> b5f6d86f5533\n",
      "Step 3/32 : RUN git clone https://github.com/pyenv/pyenv.git .pyenv\n",
      " ---> Using cache\n",
      " ---> c854103b5a41\n",
      "Step 4/32 : WORKDIR /\n",
      " ---> Using cache\n",
      " ---> 957c994db84c\n",
      "Step 5/32 : ENV HOME  /\n",
      " ---> Using cache\n",
      " ---> 27c71b3998be\n",
      "Step 6/32 : ENV PYENV_ROOT /.pyenv\n",
      " ---> Using cache\n",
      " ---> 80c3e877ef64\n",
      "Step 7/32 : ENV PATH $PYENV_ROOT/shims:$PYENV_ROOT/bin:$PATH\n",
      " ---> Using cache\n",
      " ---> 199a9b88e52b\n",
      "Step 8/32 : RUN pyenv install anaconda3-5.0.0\n",
      " ---> Using cache\n",
      " ---> 717d77725e2b\n",
      "Step 9/32 : RUN pyenv global anaconda3-5.0.0\n",
      " ---> Using cache\n",
      " ---> b639fd98a6da\n",
      "Step 10/32 : RUN pyenv rehash\n",
      " ---> Using cache\n",
      " ---> f5377581f5fc\n",
      "Step 11/32 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> db6c6539aa87\n",
      "Step 12/32 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> 6667b50c8e06\n",
      "Step 13/32 : ENV PATH=\"/opt/program:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 8f99613ef064\n",
      "Step 14/32 : ENV PYTHONIOENCODING=utf-8\n",
      " ---> Using cache\n",
      " ---> cf6522d6ca99\n",
      "Step 15/32 : WORKDIR /opt/program\n",
      " ---> Using cache\n",
      " ---> 54c429d7f787\n",
      "Step 16/32 : RUN git clone https://github.com/mack-the-psych/plimac3.git\n",
      " ---> Using cache\n",
      " ---> 66af310ee098\n",
      "Step 17/32 : RUN echo \"/opt/program/plimac3/Lib\" > /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/plimac-custom.pth\n",
      " ---> Using cache\n",
      " ---> 3120ccf51083\n",
      "Step 18/32 : RUN echo \"/opt/program/plimac3/Tools\" >> /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/plimac-custom.pth\n",
      " ---> Using cache\n",
      " ---> e440e01ea67f\n",
      "Step 19/32 : RUN conda install -c anaconda setuptools\n",
      " ---> Using cache\n",
      " ---> 63927781ff89\n",
      "Step 20/32 : RUN pip install --upgrade pip &&     pip install tensorflow-gpu==1.14.0 --user &&     pip install ml_metrics==0.1.4 &&     pip install --upgrade scipy==1.1.0 &&     conda clean --all &&     conda install pytorch==1.0.0 torchvision==0.2.1 cuda100 -c pytorch &&     pip install torchtext==0.4.0 &&     pip install attrdict==2.0.1 &&     pip uninstall --yes numpy &&     pip install numpy==1.16.4 &&     pip uninstall --yes gast &&     pip install gast==0.2.2 &&     pip install -U gevent==1.4.0 --ignore-installed &&     pip install gunicorn\n",
      " ---> Using cache\n",
      " ---> f870cc40659b\n",
      "Step 21/32 : WORKDIR /opt/program\n",
      " ---> Using cache\n",
      " ---> 2989eee88517\n",
      "Step 22/32 : RUN git clone https://github.com/mack-the-psych/vdok3.git\n",
      " ---> Using cache\n",
      " ---> 1b65c601a885\n",
      "Step 23/32 : RUN echo \"/opt/program/vdok3/prep\" > /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/vdok3-custom.pth\n",
      " ---> Using cache\n",
      " ---> 85a14a32954f\n",
      "Step 24/32 : RUN echo \"/opt/program/vdok3/extract\" >> /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/vdok3-custom.pth\n",
      " ---> Using cache\n",
      " ---> 099cfd6884aa\n",
      "Step 25/32 : RUN echo \"/opt/program/vdok3/process\" >> /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/vdok3-custom.pth\n",
      " ---> Using cache\n",
      " ---> 3ce8cff4d71f\n",
      "Step 26/32 : RUN echo \"/opt/program/vdok3/reorganize\" >> /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/vdok3-custom.pth\n",
      " ---> Using cache\n",
      " ---> 445ac3839f65\n",
      "Step 27/32 : RUN echo \"/opt/program/vdok3/train\" >> /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/vdok3-custom.pth\n",
      " ---> Using cache\n",
      " ---> f37bd30ec44e\n",
      "Step 28/32 : RUN echo \"/opt/program/vdok3/train/pytorch_advanced/nlp_sentiment_bert\" >> /.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/vdok3-custom.pth\n",
      " ---> Using cache\n",
      " ---> dc1da164c638\n",
      "Step 29/32 : WORKDIR /opt/program/vdok3/train/pytorch_advanced/nlp_sentiment_bert\n",
      " ---> Using cache\n",
      " ---> 86c36d32dc08\n",
      "Step 30/32 : RUN python make_folders_and_data_downloads.py\n",
      " ---> Using cache\n",
      " ---> b4e65be159dd\n",
      "Step 31/32 : COPY vdok3_sage /opt/program\n",
      " ---> e5666d600eca\n",
      "Step 32/32 : WORKDIR /opt/program\n",
      " ---> Running in 47cb740f93ac\n",
      "Removing intermediate container 47cb740f93ac\n",
      " ---> 79ca8384bffe\n",
      "Successfully built 79ca8384bffe\n",
      "Successfully tagged sagemaker-vdok3-bert-cv-sen:latest\n",
      "The push refers to repository [822408253028.dkr.ecr.us-west-2.amazonaws.com/sagemaker-vdok3-bert-cv-sen]\n",
      "ead959607dc0: Preparing\n",
      "b7f793376060: Preparing\n",
      "8339cd294f3c: Preparing\n",
      "9268c8fab61c: Preparing\n",
      "a62e789283df: Preparing\n",
      "ff299fef7bef: Preparing\n",
      "b24c5c608c56: Preparing\n",
      "2ea929d6007c: Preparing\n",
      "ca09ca2bcb2e: Preparing\n",
      "bb9187b12db4: Preparing\n",
      "89f495db704b: Preparing\n",
      "94c9d7de566b: Preparing\n",
      "7f135caf8c69: Preparing\n",
      "100bff3109c3: Preparing\n",
      "8f8ed080b291: Preparing\n",
      "4d51678be568: Preparing\n",
      "1f5a63d7f4d4: Preparing\n",
      "0fd8836e22c0: Preparing\n",
      "0c96895290e7: Preparing\n",
      "3ed0e2ee239d: Preparing\n",
      "2ba1a08ff949: Preparing\n",
      "bb394fa92897: Preparing\n",
      "814091c00ea1: Preparing\n",
      "64629579ad3f: Preparing\n",
      "49327771e79d: Preparing\n",
      "6439774c5a66: Preparing\n",
      "1431e91b47ef: Preparing\n",
      "ac17ecb205fb: Preparing\n",
      "1a1a19626b20: Preparing\n",
      "5b7dc8292d9b: Preparing\n",
      "bbc674332e2e: Preparing\n",
      "da2785b7bb16: Preparing\n",
      "89f495db704b: Waiting\n",
      "94c9d7de566b: Waiting\n",
      "7f135caf8c69: Waiting\n",
      "100bff3109c3: Waiting\n",
      "8f8ed080b291: Waiting\n",
      "4d51678be568: Waiting\n",
      "1f5a63d7f4d4: Waiting\n",
      "0fd8836e22c0: Waiting\n",
      "0c96895290e7: Waiting\n",
      "3ed0e2ee239d: Waiting\n",
      "2ba1a08ff949: Waiting\n",
      "bb394fa92897: Waiting\n",
      "814091c00ea1: Waiting\n",
      "64629579ad3f: Waiting\n",
      "49327771e79d: Waiting\n",
      "6439774c5a66: Waiting\n",
      "1431e91b47ef: Waiting\n",
      "ac17ecb205fb: Waiting\n",
      "1a1a19626b20: Waiting\n",
      "5b7dc8292d9b: Waiting\n",
      "bbc674332e2e: Waiting\n",
      "da2785b7bb16: Waiting\n",
      "ff299fef7bef: Waiting\n",
      "b24c5c608c56: Waiting\n",
      "2ea929d6007c: Waiting\n",
      "ca09ca2bcb2e: Waiting\n",
      "bb9187b12db4: Waiting\n",
      "9268c8fab61c: Pushed\n",
      "ead959607dc0: Pushed\n",
      "8339cd294f3c: Pushed\n",
      "a62e789283df: Pushed\n",
      "ff299fef7bef: Pushed\n",
      "2ea929d6007c: Pushed\n",
      "b24c5c608c56: Pushed\n",
      "94c9d7de566b: Pushed\n",
      "ca09ca2bcb2e: Pushed\n",
      "7f135caf8c69: Pushed\n",
      "8f8ed080b291: Pushed\n",
      "4d51678be568: Pushed\n",
      "1f5a63d7f4d4: Pushed\n",
      "100bff3109c3: Pushed\n",
      "89f495db704b: Pushed\n",
      "0c96895290e7: Pushed\n",
      "3ed0e2ee239d: Pushed\n",
      "bb394fa92897: Pushed\n",
      "b7f793376060: Pushed\n",
      "64629579ad3f: Pushed\n",
      "2ba1a08ff949: Pushed\n",
      "6439774c5a66: Pushed\n",
      "1431e91b47ef: Pushed\n",
      "ac17ecb205fb: Pushed\n",
      "1a1a19626b20: Pushed\n",
      "5b7dc8292d9b: Pushed\n",
      "bbc674332e2e: Pushed\n",
      "da2785b7bb16: Pushed\n",
      "49327771e79d: Pushed\n",
      "814091c00ea1: Pushed\n",
      "0fd8836e22c0: Pushed\n",
      "bb9187b12db4: Pushed\n",
      "latest: digest: sha256:530a7d72f198d5ee69cacc22e5c7ad5c32d9d6c73e054fdc1521f7e58bc45c95 size: 7021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.9 ms, sys: 5.18 ms, total: 25 ms\n",
      "Wall time: 6min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "# Makoto.Sano@Mack-the-Psych.com\n",
    "algorithm_name=sagemaker-vdok3-bert-cv-sen\n",
    "\n",
    "cd container\n",
    "\n",
    "chmod +x vdok3_sage/train\n",
    "chmod +x vdok3_sage/serve\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build  -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "# Makoto.Sano@Mack-the-Psych.com\n",
    "prefix = 'vdok3_bert_cv_sen'\n",
    "\n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sess = sage.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIRECTORY = 'data'\n",
    "\n",
    "data_location = sess.upload_data(WORK_DIRECTORY, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-13 03:42:38 Starting - Starting the training job...\n",
      "2021-03-13 03:42:40 Starting - Launching requested ML instancesProfilerReport-1615606958: InProgress\n",
      ".........\n",
      "2021-03-13 03:44:35 Starting - Preparing the instances for training......\n",
      "2021-03-13 03:45:39 Downloading - Downloading input data\n",
      "2021-03-13 03:45:39 Training - Downloading the training image.....................\n",
      "2021-03-13 03:49:07 Training - Training image download completed. Training in progress...\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34mStarting the training.\u001b[0m\n",
      "\u001b[34mbert.embeddings.word_embeddings.weight→embeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.position_embeddings.weight→embeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.token_type_embeddings.weight→embeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.gamma→embeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.beta→embeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.weight→encoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.bias→encoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.weight→encoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.bias→encoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.weight→encoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.bias→encoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.weight→encoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.bias→encoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.gamma→encoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.beta→encoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.weight→encoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.bias→encoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.weight→encoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.bias→encoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.gamma→encoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.beta→encoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.weight→encoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.bias→encoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.weight→encoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.bias→encoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.weight→encoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.bias→encoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.weight→encoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.bias→encoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.gamma→encoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.beta→encoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.weight→encoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.bias→encoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.weight→encoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.bias→encoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.gamma→encoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.beta→encoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.weight→encoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.bias→encoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.weight→encoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.bias→encoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.weight→encoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.bias→encoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.weight→encoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.bias→encoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.gamma→encoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.beta→encoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.weight→encoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.bias→encoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.weight→encoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.bias→encoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.gamma→encoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.beta→encoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.weight→encoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.bias→encoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.weight→encoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.bias→encoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.weight→encoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.bias→encoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.weight→encoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.bias→encoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.gamma→encoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.beta→encoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.weight→encoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.bias→encoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.weight→encoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.bias→encoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.gamma→encoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.beta→encoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.weight→encoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.bias→encoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.weight→encoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.bias→encoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.weight→encoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.bias→encoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.weight→encoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.bias→encoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.gamma→encoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.beta→encoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.weight→encoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.bias→encoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.weight→encoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.bias→encoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.gamma→encoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.beta→encoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.weight→encoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.bias→encoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.weight→encoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.bias→encoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.weight→encoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.bias→encoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.weight→encoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.bias→encoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.gamma→encoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.beta→encoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.weight→encoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.bias→encoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.weight→encoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.bias→encoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.gamma→encoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.beta→encoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.weight→encoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.bias→encoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.weight→encoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.bias→encoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.weight→encoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.bias→encoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.weight→encoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.bias→encoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.gamma→encoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.beta→encoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.weight→encoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.bias→encoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.weight→encoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.bias→encoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.gamma→encoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.beta→encoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.weight→encoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.bias→encoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.weight→encoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.bias→encoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.weight→encoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.bias→encoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.weight→encoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.bias→encoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.gamma→encoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.beta→encoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.weight→encoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.bias→encoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.weight→encoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.bias→encoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.gamma→encoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.beta→encoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.weight→encoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.bias→encoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.weight→encoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.bias→encoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.weight→encoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.bias→encoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.weight→encoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.bias→encoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.gamma→encoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.beta→encoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.weight→encoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.bias→encoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.weight→encoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.bias→encoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.gamma→encoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.beta→encoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.weight→encoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.bias→encoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.weight→encoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.bias→encoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.weight→encoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.bias→encoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.weight→encoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.bias→encoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.gamma→encoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.beta→encoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.weight→encoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.bias→encoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.weight→encoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.bias→encoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.gamma→encoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.beta→encoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.weight→encoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.bias→encoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.weight→encoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.bias→encoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.weight→encoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.bias→encoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.weight→encoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.bias→encoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.gamma→encoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.beta→encoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.weight→encoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.bias→encoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.weight→encoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.bias→encoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.gamma→encoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.beta→encoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.weight→encoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.bias→encoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.weight→encoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.bias→encoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.weight→encoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.bias→encoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.weight→encoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.bias→encoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.gamma→encoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.beta→encoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.weight→encoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.bias→encoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.weight→encoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.bias→encoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.gamma→encoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.beta→encoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.weight→pooler.dense.weight\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.bias→pooler.dense.bias\u001b[0m\n",
      "\u001b[34m----------------\u001b[0m\n",
      "\u001b[34mRANDOM SET:  0\u001b[0m\n",
      "\u001b[34mConcat Value Len: 5020\u001b[0m\n",
      "\u001b[34m(tensor([[  101,  1996,  3778,  ...,     0,     0,     0],\n",
      "        [  101,  2726, 17046,  ...,     0,     0,     0],\n",
      "        [  101,  2017,  2064,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1996,  3011,  ...,     0,     0,     0],\n",
      "        [  101,  3888,  6198,  ...,     0,     0,     0],\n",
      "        [  101,  8836,  4536,  ...,     0,     0,     0]]), tensor([42, 64, 39, 53, 92, 48, 68, 93, 73, 88, 58, 68, 68, 67, 94, 68, 56, 35,\n",
      "        42, 81, 58, 68, 48, 65, 68, 52, 76, 51, 32, 56, 77, 52]))\u001b[0m\n",
      "\u001b[34mtensor([0, 0, 1, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 1, 0])\u001b[0m\n",
      "\u001b[34m['[CLS]', 'thomas', 'edison', 'created', 'the', 'first', 'light', 'bulb', '.', 'he', 'is', 'an', 'inventor', '.', 'sam', 'born', 'created', 'a', 'machine', 'that', 'makes', 'lo', '##lli', '##pop', '##s', '.', 'he', 'is', 'an', 'inventor', '.', 'josephine', 'cochrane', 'created', 'the', 'dish', '##wash', '##er', '.', 'she', 'is', 'an', 'inventor', '.', 'ellen', 'och', '##oa', 'created', 'a', 'system', 'to', 'build', 'things', 'with', 'a', 'robot', '.', 'she', 'is', 'an', 'inventor', '.', 'nr', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34mUsing device:  cuda:0\u001b[0m\n",
      "\u001b[34m-----start-------\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.6384 || 10iter: 0.9364 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.7667 || 10iter: 0.8934 sec. || Accuracy: 0.625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.3566 || 10iter: 0.8932 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.4661 || 10iter: 0.8963 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.3741 || 10iter: 0.9003 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.3908 || 10iter: 0.8991 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.5514 || 10iter: 0.9007 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.5934 || 10iter: 0.8947 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.2101 || 10iter: 0.8961 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.3324 || 10iter: 0.8981 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.2548 || 10iter: 0.8997 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.3247 || 10iter: 0.9038 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mEpoch 1/10 | train |  Loss: 0.5326 Acc: 0.7938\u001b[0m\n",
      "\u001b[34mEpoch 1/10 |  val  |  Loss: 0.5464 Acc: 0.7958\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.4614 || 10iter: 0.9055 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.2780 || 10iter: 0.9017 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.4639 || 10iter: 0.9042 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.4357 || 10iter: 0.9020 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.3218 || 10iter: 0.8988 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.3978 || 10iter: 0.9025 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.4468 || 10iter: 0.8987 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.3369 || 10iter: 0.8989 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.3090 || 10iter: 0.8977 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.4233 || 10iter: 0.8976 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.4476 || 10iter: 0.8977 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.3463 || 10iter: 0.8975 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mEpoch 2/10 | train |  Loss: 0.3678 Acc: 0.8399\u001b[0m\n",
      "\u001b[34mEpoch 2/10 |  val  |  Loss: 0.3777 Acc: 0.8416\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.3860 || 10iter: 0.9033 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.3694 || 10iter: 0.8985 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.3135 || 10iter: 0.9020 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.3281 || 10iter: 0.9015 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.2934 || 10iter: 0.9017 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.4881 || 10iter: 0.9026 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.4835 || 10iter: 0.9081 sec. || Accuracy: 0.75\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.2452 || 10iter: 0.9023 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.3148 || 10iter: 0.8998 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2742 || 10iter: 0.9034 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.3288 || 10iter: 0.9058 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.2547 || 10iter: 0.9140 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mEpoch 3/10 | train |  Loss: 0.3319 Acc: 0.8556\u001b[0m\n",
      "\u001b[34mEpoch 3/10 |  val  |  Loss: 0.3498 Acc: 0.8526\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1737 || 10iter: 0.9068 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.2161 || 10iter: 0.9023 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.2418 || 10iter: 0.9029 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.3783 || 10iter: 0.9007 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.2448 || 10iter: 0.9008 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2171 || 10iter: 0.9002 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.3774 || 10iter: 0.8994 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.3651 || 10iter: 0.9026 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.2158 || 10iter: 0.9034 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.3267 || 10iter: 0.9008 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.2034 || 10iter: 0.9019 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.5524 || 10iter: 0.9007 sec. || Accuracy: 0.71875\u001b[0m\n",
      "\u001b[34mEpoch 4/10 | train |  Loss: 0.3046 Acc: 0.8668\u001b[0m\n",
      "\u001b[34mEpoch 4/10 |  val  |  Loss: 0.3392 Acc: 0.8625\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.3232 || 10iter: 0.9060 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.4025 || 10iter: 0.9009 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.3166 || 10iter: 0.9013 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.3831 || 10iter: 0.9001 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.2777 || 10iter: 0.9000 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2016 || 10iter: 0.8999 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.2209 || 10iter: 0.9021 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.3648 || 10iter: 0.9044 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.2398 || 10iter: 0.9007 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0667 || 10iter: 0.9029 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.2753 || 10iter: 0.9020 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.3530 || 10iter: 0.9004 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mEpoch 5/10 | train |  Loss: 0.2867 Acc: 0.8810\u001b[0m\n",
      "\u001b[34mEpoch 5/10 |  val  |  Loss: 0.3197 Acc: 0.8665\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.2660 || 10iter: 0.9127 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0878 || 10iter: 0.9052 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.3045 || 10iter: 0.9021 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.3146 || 10iter: 0.9021 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.2642 || 10iter: 0.9031 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2277 || 10iter: 0.9020 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.3426 || 10iter: 0.9039 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.4550 || 10iter: 0.9067 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1454 || 10iter: 0.9110 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2739 || 10iter: 0.9085 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.2951 || 10iter: 0.9054 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1762 || 10iter: 0.9052 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mEpoch 6/10 | train |  Loss: 0.2754 Acc: 0.8877\u001b[0m\n",
      "\u001b[34mEpoch 6/10 |  val  |  Loss: 0.3105 Acc: 0.8635\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1828 || 10iter: 0.9089 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.2424 || 10iter: 0.9059 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1494 || 10iter: 0.9095 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.3296 || 10iter: 0.9100 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.2192 || 10iter: 0.9053 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2492 || 10iter: 0.9142 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.3194 || 10iter: 0.9121 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.2512 || 10iter: 0.9131 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.2964 || 10iter: 0.9075 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.3649 || 10iter: 0.9069 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1151 || 10iter: 0.9040 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.2731 || 10iter: 0.9047 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mEpoch 7/10 | train |  Loss: 0.2490 Acc: 0.8999\u001b[0m\n",
      "\u001b[34mEpoch 7/10 |  val  |  Loss: 0.3099 Acc: 0.8715\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0923 || 10iter: 0.9103 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.3677 || 10iter: 0.9053 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.3189 || 10iter: 0.9046 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.2902 || 10iter: 0.9057 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.4084 || 10iter: 0.9053 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.4970 || 10iter: 0.9058 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.2953 || 10iter: 0.9081 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.3428 || 10iter: 0.9075 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.4137 || 10iter: 0.9072 sec. || Accuracy: 0.78125\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2619 || 10iter: 0.9063 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0558 || 10iter: 0.9053 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.2935 || 10iter: 0.9044 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mEpoch 8/10 | train |  Loss: 0.2465 Acc: 0.8959\u001b[0m\n",
      "\u001b[34mEpoch 8/10 |  val  |  Loss: 0.3074 Acc: 0.8645\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1594 || 10iter: 0.9110 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1619 || 10iter: 0.9058 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.2862 || 10iter: 0.9096 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.2283 || 10iter: 0.9067 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1765 || 10iter: 0.9068 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.1730 || 10iter: 0.9083 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.2189 || 10iter: 0.9090 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.2872 || 10iter: 0.9076 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.2431 || 10iter: 0.9075 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1809 || 10iter: 0.9077 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1206 || 10iter: 0.9073 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.4156 || 10iter: 0.9064 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mEpoch 9/10 | train |  Loss: 0.2168 Acc: 0.9099\u001b[0m\n",
      "\u001b[34mEpoch 9/10 |  val  |  Loss: 0.3005 Acc: 0.8745\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1761 || 10iter: 0.9130 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1575 || 10iter: 0.9074 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1966 || 10iter: 0.9104 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1294 || 10iter: 0.9079 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1793 || 10iter: 0.9084 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.1829 || 10iter: 0.9110 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1605 || 10iter: 0.9089 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1745 || 10iter: 0.9154 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1527 || 10iter: 0.9086 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2485 || 10iter: 0.9132 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.2571 || 10iter: 0.9101 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1618 || 10iter: 0.9115 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mEpoch 10/10 | train |  Loss: 0.2086 Acc: 0.9156\u001b[0m\n",
      "\u001b[34mEpoch 10/10 |  val  |  Loss: 0.3095 Acc: 0.8775\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/53 [00:00<?, ?it/s]#015  4%|▍         | 2/53 [00:00<00:04, 12.08it/s]#015  8%|▊         | 4/53 [00:00<00:04, 12.06it/s]#015 11%|█▏        | 6/53 [00:00<00:03, 12.06it/s]#015 15%|█▌        | 8/53 [00:00<00:03, 12.06it/s]#015 19%|█▉        | 10/53 [00:00<00:03, 12.06it/s]#015 23%|██▎       | 12/53 [00:00<00:03, 12.06it/s]#015 26%|██▋       | 14/53 [00:01<00:03, 12.03it/s]#015 30%|███       | 16/53 [00:01<00:03, 12.01it/s]#015 34%|███▍      | 18/53 [00:01<00:02, 12.02it/s]#015 38%|███▊      | 20/53 [00:01<00:02, 12.01it/s]#015 42%|████▏     | 22/53 [00:01<00:02, 12.00it/s]#015 45%|████▌     | 24/53 [00:01<00:02, 12.00it/s]#015 49%|████▉     | 26/53 [00:02<00:02, 11.99it/s]#015 53%|█████▎    | 28/53 [00:02<00:02, 12.00it/s]#015 57%|█████▋    | 30/53 [00:02<00:01, 12.00it/s]#015 60%|██████    | 32/53 [00:02<00:01, 12.02it/s]#015 64%|██████▍   | 34/53 [00:02<00:01, 12.02it/s]#015 68%|██████▊   | 36/53 [00:02<00:01, 12.02it/s]#015 72%|███████▏  | 38/53 [00:03<00:01, 12.02it/s]#015 75%|███████▌  | 40/53 [00:03<00:01, 12.03it/s]#015 79%|███████▉  | 42/53 [00:03<00:00, 12.03it/s]#015 83%|████████▎ | 44/53 [00:03<00:00, 12.04it/s]#015 87%|████████▋ | 46/53 [00:03<00:00, 12.04it/s]#015 91%|█████████ | 48/53 [00:03<00:00, 12.04it/s]#015 94%|█████████▍| 50/53 [00:04<00:00, 12.02it/s]#015 98%|█████████▊| 52/53 [00:04<00:00, 12.01it/s]#015100%|██████████| 53/53 [00:04<00:00, 12.18it/s]\u001b[0m\n",
      "\u001b[34mTest Data 1673 Accuracy: 0.9050\u001b[0m\n",
      "\u001b[34mRecall                      0.9050\u001b[0m\n",
      "\u001b[34mPrecision                   0.8997\u001b[0m\n",
      "\u001b[34mF1                          0.9006\u001b[0m\n",
      "\u001b[34mKappa                       0.7507\u001b[0m\n",
      "\u001b[34mQuadratic Weighted Kappa    0.8113\u001b[0m\n",
      "\u001b[34mdtype: float64\u001b[0m\n",
      "\u001b[34mConfusion Matrix:\n",
      "      0    1   2  3\u001b[0m\n",
      "\u001b[34m0  1239   19   7  2\u001b[0m\n",
      "\u001b[34m1    49  188  20  0\u001b[0m\n",
      "\u001b[34m2    16   27  82  1\u001b[0m\n",
      "\u001b[34m3     3    0  15  5\u001b[0m\n",
      "\u001b[34m----------------\u001b[0m\n",
      "\u001b[34mRANDOM SET:  1\u001b[0m\n",
      "\u001b[34mConcat Value Len: 5020\u001b[0m\n",
      "\u001b[34m(tensor([[  101,  1996,  3778,  ...,     0,     0,     0],\n",
      "        [  101,  2726, 17046,  ...,     0,     0,     0],\n",
      "        [  101,  2017,  2064,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1996,  3011,  ...,     0,     0,     0],\n",
      "        [  101,  2116,  7074,  ...,     0,     0,     0],\n",
      "        [  101,  8836,  4536,  ...,     0,     0,     0]]), tensor([ 42,  64,  39,  53,  36,  82,  68,  93,  73,  71,  99,  68,  68,  67,\n",
      "         42,  23,  56,  35,  80,  81,  58, 126,  93,  65,  68,  82,  81,  51,\n",
      "         32,  56,  32,  52]))\u001b[0m\n",
      "\u001b[34mtensor([0, 0, 1, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 2, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0])\u001b[0m\n",
      "\u001b[34m['[CLS]', 'thomas', 'edison', 'created', 'the', 'first', 'light', 'bulb', '.', 'he', 'is', 'an', 'inventor', '.', 'sam', 'born', 'created', 'a', 'machine', 'that', 'makes', 'lo', '##lli', '##pop', '##s', '.', 'he', 'is', 'an', 'inventor', '.', 'josephine', 'cochrane', 'created', 'the', 'dish', '##wash', '##er', '.', 'she', 'is', 'an', 'inventor', '.', 'ellen', 'och', '##oa', 'created', 'a', 'system', 'to', 'build', 'things', 'with', 'a', 'robot', '.', 'she', 'is', 'an', 'inventor', '.', 'nr', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34mUsing device:  cuda:0\u001b[0m\n",
      "\u001b[34m-----start-------\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.3527 || 10iter: 0.9089 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.2172 || 10iter: 0.9067 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0964 || 10iter: 0.9087 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1908 || 10iter: 0.9075 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.2939 || 10iter: 0.9081 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0313 || 10iter: 0.9099 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.3866 || 10iter: 0.9157 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.2643 || 10iter: 0.9112 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.2245 || 10iter: 0.9118 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1708 || 10iter: 0.9077 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1856 || 10iter: 0.9087 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1870 || 10iter: 0.9068 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mEpoch 1/10 | train |  Loss: 0.3156 Acc: 0.8765\u001b[0m\n",
      "\u001b[34mEpoch 1/10 |  val  |  Loss: 0.2832 Acc: 0.8904\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.3067 || 10iter: 0.9127 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1754 || 10iter: 0.9082 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.2345 || 10iter: 0.9103 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.2439 || 10iter: 0.9072 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1402 || 10iter: 0.9078 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2305 || 10iter: 0.9078 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1574 || 10iter: 0.9085 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.2343 || 10iter: 0.9097 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1720 || 10iter: 0.9076 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2863 || 10iter: 0.9087 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.2156 || 10iter: 0.9083 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.3092 || 10iter: 0.9055 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mEpoch 2/10 | train |  Loss: 0.2327 Acc: 0.9036\u001b[0m\n",
      "\u001b[34mEpoch 2/10 |  val  |  Loss: 0.2746 Acc: 0.8865\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.2061 || 10iter: 0.9112 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1931 || 10iter: 0.9062 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1050 || 10iter: 0.9071 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1331 || 10iter: 0.9101 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1556 || 10iter: 0.9059 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2624 || 10iter: 0.9060 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.2122 || 10iter: 0.9085 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.0730 || 10iter: 0.9071 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1635 || 10iter: 0.9085 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2819 || 10iter: 0.9088 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1021 || 10iter: 0.9097 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1151 || 10iter: 0.9126 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 3/10 | train |  Loss: 0.2101 Acc: 0.9161\u001b[0m\n",
      "\u001b[34mEpoch 3/10 |  val  |  Loss: 0.2811 Acc: 0.8884\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1088 || 10iter: 0.9125 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.2413 || 10iter: 0.9090 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1442 || 10iter: 0.9102 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.2230 || 10iter: 0.9139 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1429 || 10iter: 0.9099 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2739 || 10iter: 0.9116 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1724 || 10iter: 0.9120 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.2437 || 10iter: 0.9171 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.0826 || 10iter: 0.9086 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2766 || 10iter: 0.9096 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.2301 || 10iter: 0.9101 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1437 || 10iter: 0.9128 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 4/10 | train |  Loss: 0.2011 Acc: 0.9161\u001b[0m\n",
      "\u001b[34mEpoch 4/10 |  val  |  Loss: 0.2674 Acc: 0.8875\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1183 || 10iter: 0.9205 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.4974 || 10iter: 0.9083 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1439 || 10iter: 0.9097 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.2663 || 10iter: 0.9094 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1281 || 10iter: 0.9148 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2336 || 10iter: 0.9085 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0834 || 10iter: 0.9085 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.0800 || 10iter: 0.9109 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1378 || 10iter: 0.9100 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0852 || 10iter: 0.9096 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1797 || 10iter: 0.9084 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1744 || 10iter: 0.9092 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mEpoch 5/10 | train |  Loss: 0.1882 Acc: 0.9260\u001b[0m\n",
      "\u001b[34mEpoch 5/10 |  val  |  Loss: 0.2824 Acc: 0.8954\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1514 || 10iter: 0.9198 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1097 || 10iter: 0.9125 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.2769 || 10iter: 0.9131 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.0954 || 10iter: 0.9119 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1153 || 10iter: 0.9111 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.3078 || 10iter: 0.9112 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1632 || 10iter: 0.9129 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1781 || 10iter: 0.9143 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.3645 || 10iter: 0.9117 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1068 || 10iter: 0.9081 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1323 || 10iter: 0.9094 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1308 || 10iter: 0.9091 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 6/10 | train |  Loss: 0.1743 Acc: 0.9338\u001b[0m\n",
      "\u001b[34mEpoch 6/10 |  val  |  Loss: 0.3096 Acc: 0.8775\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.2421 || 10iter: 0.9170 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1168 || 10iter: 0.9106 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.2392 || 10iter: 0.9099 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1382 || 10iter: 0.9086 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0982 || 10iter: 0.9103 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.1136 || 10iter: 0.9103 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.2559 || 10iter: 0.9101 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1651 || 10iter: 0.9108 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.2326 || 10iter: 0.9124 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2460 || 10iter: 0.9137 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1671 || 10iter: 0.9143 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1435 || 10iter: 0.9180 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mEpoch 7/10 | train |  Loss: 0.1594 Acc: 0.9328\u001b[0m\n",
      "\u001b[34mEpoch 7/10 |  val  |  Loss: 0.2520 Acc: 0.9034\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0437 || 10iter: 0.9223 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1479 || 10iter: 0.9176 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1305 || 10iter: 0.9153 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.2847 || 10iter: 0.9148 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1757 || 10iter: 0.9124 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2080 || 10iter: 0.9144 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1041 || 10iter: 0.9165 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1842 || 10iter: 0.9243 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.0604 || 10iter: 0.9121 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2153 || 10iter: 0.9105 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0562 || 10iter: 0.9127 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.2032 || 10iter: 0.9146 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mEpoch 8/10 | train |  Loss: 0.1455 Acc: 0.9417\u001b[0m\n",
      "\u001b[34mEpoch 8/10 |  val  |  Loss: 0.2822 Acc: 0.8884\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0585 || 10iter: 0.9181 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0707 || 10iter: 0.9137 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.2189 || 10iter: 0.9108 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1558 || 10iter: 0.9124 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0639 || 10iter: 0.9119 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.1263 || 10iter: 0.9131 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.2347 || 10iter: 0.9097 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.2161 || 10iter: 0.9118 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1762 || 10iter: 0.9146 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1768 || 10iter: 0.9151 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.2353 || 10iter: 0.9166 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1737 || 10iter: 0.9158 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mEpoch 9/10 | train |  Loss: 0.1413 Acc: 0.9447\u001b[0m\n",
      "\u001b[34mEpoch 9/10 |  val  |  Loss: 0.2578 Acc: 0.8994\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0661 || 10iter: 0.9208 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0844 || 10iter: 0.9142 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1288 || 10iter: 0.9213 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1283 || 10iter: 0.9141 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0266 || 10iter: 0.9178 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.1613 || 10iter: 0.9137 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.2109 || 10iter: 0.9135 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.2104 || 10iter: 0.9152 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1232 || 10iter: 0.9128 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0277 || 10iter: 0.9136 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.2013 || 10iter: 0.9122 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0656 || 10iter: 0.9112 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mEpoch 10/10 | train |  Loss: 0.1296 Acc: 0.9485\u001b[0m\n",
      "\u001b[34mEpoch 10/10 |  val  |  Loss: 0.2874 Acc: 0.8914\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/53 [00:00<?, ?it/s]#015  4%|▍         | 2/53 [00:00<00:04, 12.15it/s]#015  8%|▊         | 4/53 [00:00<00:04, 12.13it/s]#015 11%|█▏        | 6/53 [00:00<00:03, 12.10it/s]#015 15%|█▌        | 8/53 [00:00<00:03, 12.09it/s]#015 19%|█▉        | 10/53 [00:00<00:03, 12.07it/s]#015 23%|██▎       | 12/53 [00:00<00:03, 12.04it/s]#015 26%|██▋       | 14/53 [00:01<00:03, 12.03it/s]#015 30%|███       | 16/53 [00:01<00:03, 12.02it/s]#015 34%|███▍      | 18/53 [00:01<00:02, 12.01it/s]#015 38%|███▊      | 20/53 [00:01<00:02, 12.01it/s]#015 42%|████▏     | 22/53 [00:01<00:02, 12.02it/s]#015 45%|████▌     | 24/53 [00:01<00:02, 12.02it/s]#015 49%|████▉     | 26/53 [00:02<00:02, 12.01it/s]#015 53%|█████▎    | 28/53 [00:02<00:02, 12.00it/s]#015 57%|█████▋    | 30/53 [00:02<00:01, 12.01it/s]#015 60%|██████    | 32/53 [00:02<00:01, 12.01it/s]#015 64%|██████▍   | 34/53 [00:02<00:01, 12.01it/s]#015 68%|██████▊   | 36/53 [00:02<00:01, 12.01it/s]#015 72%|███████▏  | 38/53 [00:03<00:01, 12.02it/s]#015 75%|███████▌  | 40/53 [00:03<00:01, 12.00it/s]#015 79%|███████▉  | 42/53 [00:03<00:00, 12.00it/s]#015 83%|████████▎ | 44/53 [00:03<00:00, 11.98it/s]#015 87%|████████▋ | 46/53 [00:03<00:00, 11.98it/s]#015 91%|█████████ | 48/53 [00:03<00:00, 11.98it/s]#015 94%|█████████▍| 50/53 [00:04<00:00, 11.99it/s]#015 98%|█████████▊| 52/53 [00:04<00:00, 11.98it/s]#015100%|██████████| 53/53 [00:04<00:00, 12.17it/s]\u001b[0m\n",
      "\u001b[34mTest Data 1673 Accuracy: 0.9277\u001b[0m\n",
      "\u001b[34mRecall                      0.9277\u001b[0m\n",
      "\u001b[34mPrecision                   0.9297\u001b[0m\n",
      "\u001b[34mF1                          0.9285\u001b[0m\n",
      "\u001b[34mKappa                       0.8140\u001b[0m\n",
      "\u001b[34mQuadratic Weighted Kappa    0.8651\u001b[0m\n",
      "\u001b[34mdtype: float64\u001b[0m\n",
      "\u001b[34mConfusion Matrix:\n",
      "      0    1   2   3\u001b[0m\n",
      "\u001b[34m0  1247   28   9   1\u001b[0m\n",
      "\u001b[34m1    16  196  29   1\u001b[0m\n",
      "\u001b[34m2     5   20  99   4\u001b[0m\n",
      "\u001b[34m3     3    1   4  10\u001b[0m\n",
      "\u001b[34m----------------\u001b[0m\n",
      "\u001b[34mRANDOM SET:  2\u001b[0m\n",
      "\u001b[34mConcat Value Len: 5020\u001b[0m\n",
      "\u001b[34m(tensor([[  101,  1996,  4650,  ...,     0,     0,     0],\n",
      "        [  101,  2726, 17046,  ...,     0,     0,     0],\n",
      "        [  101,  2023, 12779,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1996,  4650,  ...,     0,     0,     0],\n",
      "        [  101,  2116,  7074,  ...,     0,     0,     0],\n",
      "        [  101,  8836,  4536,  ...,     0,     0,     0]]), tensor([ 53,  64,  74,  63,  36,  82,  68,  56,  82,  71,  99,  68,  68,  67,\n",
      "         42,  23,  68,  56,  80,  81,  75, 126,  93,  65,  42,  82,  81,  51,\n",
      "         32,  53,  32,  52]))\u001b[0m\n",
      "\u001b[34mtensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 2, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0])\u001b[0m\n",
      "\u001b[34m['[CLS]', 'thomas', 'edison', 'created', 'the', 'first', 'light', 'bulb', '.', 'he', 'is', 'an', 'inventor', '.', 'sam', 'born', 'created', 'a', 'machine', 'that', 'makes', 'lo', '##lli', '##pop', '##s', '.', 'he', 'is', 'an', 'inventor', '.', 'josephine', 'cochrane', 'created', 'the', 'dish', '##wash', '##er', '.', 'she', 'is', 'an', 'inventor', '.', 'ellen', 'och', '##oa', 'created', 'a', 'system', 'to', 'build', 'things', 'with', 'a', 'robot', '.', 'she', 'is', 'an', 'inventor', '.', 'nr', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34mUsing device:  cuda:0\u001b[0m\n",
      "\u001b[34m-----start-------\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.3257 || 10iter: 0.9127 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1590 || 10iter: 0.9145 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0900 || 10iter: 0.9134 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.2384 || 10iter: 0.9130 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.2956 || 10iter: 0.9170 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2453 || 10iter: 0.9127 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1735 || 10iter: 0.9133 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.2376 || 10iter: 0.9140 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.2579 || 10iter: 0.9128 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2821 || 10iter: 0.9147 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1149 || 10iter: 0.9147 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.2180 || 10iter: 0.9159 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mEpoch 1/10 | train |  Loss: 0.2451 Acc: 0.9026\u001b[0m\n",
      "\u001b[34mEpoch 1/10 |  val  |  Loss: 0.2444 Acc: 0.9074\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1609 || 10iter: 0.9167 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1894 || 10iter: 0.9139 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1031 || 10iter: 0.9098 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.2371 || 10iter: 0.9131 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1185 || 10iter: 0.9094 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2315 || 10iter: 0.9112 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0505 || 10iter: 0.9095 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1887 || 10iter: 0.9089 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1050 || 10iter: 0.9109 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2315 || 10iter: 0.9104 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.3016 || 10iter: 0.9078 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.2069 || 10iter: 0.9090 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mEpoch 2/10 | train |  Loss: 0.1675 Acc: 0.9320\u001b[0m\n",
      "\u001b[34mEpoch 2/10 |  val  |  Loss: 0.2457 Acc: 0.9104\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0466 || 10iter: 0.9128 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1252 || 10iter: 0.9086 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1919 || 10iter: 0.9112 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1067 || 10iter: 0.9137 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.2205 || 10iter: 0.9138 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.1461 || 10iter: 0.9139 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0754 || 10iter: 0.9116 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1369 || 10iter: 0.9142 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1384 || 10iter: 0.9157 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1594 || 10iter: 0.9096 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0910 || 10iter: 0.9089 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0775 || 10iter: 0.9098 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 3/10 | train |  Loss: 0.1549 Acc: 0.9380\u001b[0m\n",
      "\u001b[34mEpoch 3/10 |  val  |  Loss: 0.2546 Acc: 0.9064\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0410 || 10iter: 0.9164 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1310 || 10iter: 0.9117 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1127 || 10iter: 0.9102 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1196 || 10iter: 0.9143 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1396 || 10iter: 0.9110 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0974 || 10iter: 0.9091 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.2137 || 10iter: 0.9097 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.2560 || 10iter: 0.9107 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.0694 || 10iter: 0.9095 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1006 || 10iter: 0.9140 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.2670 || 10iter: 0.9083 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1092 || 10iter: 0.9113 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 4/10 | train |  Loss: 0.1348 Acc: 0.9472\u001b[0m\n",
      "\u001b[34mEpoch 4/10 |  val  |  Loss: 0.2434 Acc: 0.9114\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1472 || 10iter: 0.9150 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1671 || 10iter: 0.9114 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0382 || 10iter: 0.9167 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1995 || 10iter: 0.9182 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0738 || 10iter: 0.9258 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0967 || 10iter: 0.9211 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0381 || 10iter: 0.9134 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1770 || 10iter: 0.9093 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1891 || 10iter: 0.9094 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2470 || 10iter: 0.9101 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0651 || 10iter: 0.9113 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1204 || 10iter: 0.9104 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mEpoch 5/10 | train |  Loss: 0.1281 Acc: 0.9460\u001b[0m\n",
      "\u001b[34mEpoch 5/10 |  val  |  Loss: 0.2461 Acc: 0.9133\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0678 || 10iter: 0.9163 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0931 || 10iter: 0.9098 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0878 || 10iter: 0.9116 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.0343 || 10iter: 0.9095 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0302 || 10iter: 0.9086 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.1857 || 10iter: 0.9106 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1455 || 10iter: 0.9102 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1875 || 10iter: 0.9101 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1788 || 10iter: 0.9106 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0996 || 10iter: 0.9084 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1586 || 10iter: 0.9132 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1588 || 10iter: 0.9113 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 6/10 | train |  Loss: 0.1180 Acc: 0.9559\u001b[0m\n",
      "\u001b[34mEpoch 6/10 |  val  |  Loss: 0.2764 Acc: 0.8994\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0219 || 10iter: 0.9156 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0755 || 10iter: 0.9103 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0719 || 10iter: 0.9147 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1133 || 10iter: 0.9091 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1930 || 10iter: 0.9116 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.1223 || 10iter: 0.9120 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0547 || 10iter: 0.9095 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.0679 || 10iter: 0.9108 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.0656 || 10iter: 0.9095 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0769 || 10iter: 0.9094 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1716 || 10iter: 0.9126 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0955 || 10iter: 0.9109 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mEpoch 7/10 | train |  Loss: 0.1116 Acc: 0.9577\u001b[0m\n",
      "\u001b[34mEpoch 7/10 |  val  |  Loss: 0.2548 Acc: 0.9163\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0824 || 10iter: 0.9166 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.2076 || 10iter: 0.9110 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1763 || 10iter: 0.9143 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1428 || 10iter: 0.9109 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0984 || 10iter: 0.9115 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2358 || 10iter: 0.9115 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0619 || 10iter: 0.9114 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1735 || 10iter: 0.9106 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.0437 || 10iter: 0.9103 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1178 || 10iter: 0.9107 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1560 || 10iter: 0.9160 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0652 || 10iter: 0.9128 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 8/10 | train |  Loss: 0.1046 Acc: 0.9602\u001b[0m\n",
      "\u001b[34mEpoch 8/10 |  val  |  Loss: 0.2691 Acc: 0.9104\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1046 || 10iter: 0.9183 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0140 || 10iter: 0.9129 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0862 || 10iter: 0.9195 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1201 || 10iter: 0.9149 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0266 || 10iter: 0.9221 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.1022 || 10iter: 0.9156 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1084 || 10iter: 0.9143 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1020 || 10iter: 0.9139 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1046 || 10iter: 0.9116 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1775 || 10iter: 0.9115 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.3000 || 10iter: 0.9103 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1199 || 10iter: 0.9151 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 9/10 | train |  Loss: 0.1007 Acc: 0.9629\u001b[0m\n",
      "\u001b[34mEpoch 9/10 |  val  |  Loss: 0.2800 Acc: 0.9094\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0399 || 10iter: 0.9146 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0570 || 10iter: 0.9136 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0489 || 10iter: 0.9191 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.0194 || 10iter: 0.9184 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0406 || 10iter: 0.9118 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0876 || 10iter: 0.9152 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0669 || 10iter: 0.9121 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1470 || 10iter: 0.9108 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1125 || 10iter: 0.9105 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0077 || 10iter: 0.9105 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0344 || 10iter: 0.9103 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1727 || 10iter: 0.9113 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mEpoch 10/10 | train |  Loss: 0.0922 Acc: 0.9674\u001b[0m\n",
      "\u001b[34mEpoch 10/10 |  val  |  Loss: 0.2701 Acc: 0.9143\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/53 [00:00<?, ?it/s]#015  4%|▍         | 2/53 [00:00<00:04, 12.17it/s]#015  8%|▊         | 4/53 [00:00<00:04, 12.14it/s]#015 11%|█▏        | 6/53 [00:00<00:03, 12.10it/s]#015 15%|█▌        | 8/53 [00:00<00:03, 12.07it/s]#015 19%|█▉        | 10/53 [00:00<00:03, 12.05it/s]#015 23%|██▎       | 12/53 [00:00<00:03, 12.05it/s]#015 26%|██▋       | 14/53 [00:01<00:03, 12.04it/s]#015 30%|███       | 16/53 [00:01<00:03, 12.03it/s]#015 34%|███▍      | 18/53 [00:01<00:02, 12.02it/s]#015 38%|███▊      | 20/53 [00:01<00:02, 12.02it/s]#015 42%|████▏     | 22/53 [00:01<00:02, 12.02it/s]#015 45%|████▌     | 24/53 [00:01<00:02, 12.00it/s]#015 49%|████▉     | 26/53 [00:02<00:02, 12.01it/s]#015 53%|█████▎    | 28/53 [00:02<00:02, 12.01it/s]#015 57%|█████▋    | 30/53 [00:02<00:01, 12.01it/s]#015 60%|██████    | 32/53 [00:02<00:01, 12.01it/s]#015 64%|██████▍   | 34/53 [00:02<00:01, 12.02it/s]#015 68%|██████▊   | 36/53 [00:02<00:01, 12.02it/s]#015 72%|███████▏  | 38/53 [00:03<00:01, 12.01it/s]#015 75%|███████▌  | 40/53 [00:03<00:01, 12.01it/s]#015 79%|███████▉  | 42/53 [00:03<00:00, 12.02it/s]#015 83%|████████▎ | 44/53 [00:03<00:00, 12.01it/s]#015 87%|████████▋ | 46/53 [00:03<00:00, 12.01it/s]#015 91%|█████████ | 48/53 [00:03<00:00, 12.01it/s]#015 94%|█████████▍| 50/53 [00:04<00:00, 12.02it/s]#015 98%|█████████▊| 52/53 [00:04<00:00, 12.01it/s]#015100%|██████████| 53/53 [00:04<00:00, 12.18it/s]\u001b[0m\n",
      "\u001b[34mTest Data 1673 Accuracy: 0.9331\u001b[0m\n",
      "\u001b[34mRecall                      0.9331\u001b[0m\n",
      "\u001b[34mPrecision                   0.9373\u001b[0m\n",
      "\u001b[34mF1                          0.9345\u001b[0m\n",
      "\u001b[34mKappa                       0.8349\u001b[0m\n",
      "\u001b[34mQuadratic Weighted Kappa    0.8677\u001b[0m\n",
      "\u001b[34mdtype: float64\u001b[0m\n",
      "\u001b[34mConfusion Matrix:\n",
      "      0    1   2  3\u001b[0m\n",
      "\u001b[34m0  1217   31  15  0\u001b[0m\n",
      "\u001b[34m1    17  240  26  0\u001b[0m\n",
      "\u001b[34m2     6   14  95  0\u001b[0m\n",
      "\u001b[34m3     1    0   2  9\u001b[0m\n",
      "\u001b[34m----------------\u001b[0m\n",
      "\u001b[34mRANDOM SET:  3\u001b[0m\n",
      "\u001b[34mConcat Value Len: 5019\u001b[0m\n",
      "\u001b[34m(tensor([[  101,  2726, 17046,  ...,     0,     0,     0],\n",
      "        [  101,  2017,  2064,  ...,     0,     0,     0],\n",
      "        [  101,  1045,  3266,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  9155, 28166,  ...,     0,     0,     0],\n",
      "        [  101,  9155,  7126,  ...,     0,     0,     0],\n",
      "        [  101,  9155,  7126,  ...,     0,     0,     0]]), tensor([ 69,  41,  23,  56,  92,  68,  35,  58,  63,  82,  85,  41,  84,  71,\n",
      "         99,  35,  92,  81,  23,  99,  63,  57, 127,  56,  78,  93,  32,  99,\n",
      "         68,  81,  60,  58]))\u001b[0m\n",
      "\u001b[34mtensor([1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0])\u001b[0m\n",
      "\u001b[34m['[CLS]', 'you', 'can', 'measure', 'how', 'long', 'something', 'is', 'with', 'a', 'ruler', '.', 'you', 'can', 'measure', 'weight', 'with', 'a', 'scale', '.', 'you', 'can', 'measure', 'pressure', 'in', 'the', 'atmosphere', 'with', 'a', 'bar', '##ometer', '.', 'i', 'measure', 'to', 'see', 'how', 'long', 'things', 'are', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34mUsing device:  cuda:0\u001b[0m\n",
      "\u001b[34m-----start-------\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.5137 || 10iter: 0.9119 sec. || Accuracy: 0.8125\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.2853 || 10iter: 0.9093 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1461 || 10iter: 0.9119 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.3350 || 10iter: 0.9090 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.3363 || 10iter: 0.9100 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2634 || 10iter: 0.9120 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0998 || 10iter: 0.9114 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1926 || 10iter: 0.9099 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1782 || 10iter: 0.9109 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.3495 || 10iter: 0.9105 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.2010 || 10iter: 0.9131 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1882 || 10iter: 0.9111 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mEpoch 1/10 | train |  Loss: 0.3006 Acc: 0.8802\u001b[0m\n",
      "\u001b[34mEpoch 1/10 |  val  |  Loss: 0.1618 Acc: 0.9373\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1825 || 10iter: 0.9290 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1758 || 10iter: 0.9174 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1845 || 10iter: 0.9209 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.0812 || 10iter: 0.9225 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1087 || 10iter: 0.9106 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.2881 || 10iter: 0.9107 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0955 || 10iter: 0.9092 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.0471 || 10iter: 0.9091 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.0869 || 10iter: 0.9085 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.2355 || 10iter: 0.9075 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0902 || 10iter: 0.9096 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.2500 || 10iter: 0.9094 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mEpoch 2/10 | train |  Loss: 0.1549 Acc: 0.9397\u001b[0m\n",
      "\u001b[34mEpoch 2/10 |  val  |  Loss: 0.1847 Acc: 0.9373\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.4508 || 10iter: 0.9146 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1252 || 10iter: 0.9137 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0894 || 10iter: 0.9163 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.2308 || 10iter: 0.9106 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.2749 || 10iter: 0.9083 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.1728 || 10iter: 0.9108 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0904 || 10iter: 0.9089 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1225 || 10iter: 0.9076 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.2635 || 10iter: 0.9087 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0993 || 10iter: 0.9099 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1374 || 10iter: 0.9094 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.2760 || 10iter: 0.9095 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mEpoch 3/10 | train |  Loss: 0.1446 Acc: 0.9457\u001b[0m\n",
      "\u001b[34mEpoch 3/10 |  val  |  Loss: 0.1617 Acc: 0.9442\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0437 || 10iter: 0.9176 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.1980 || 10iter: 0.9124 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1238 || 10iter: 0.9118 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1718 || 10iter: 0.9080 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1382 || 10iter: 0.9089 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0327 || 10iter: 0.9132 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1643 || 10iter: 0.9125 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1392 || 10iter: 0.9095 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1282 || 10iter: 0.9087 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0306 || 10iter: 0.9087 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1220 || 10iter: 0.9098 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.1453 || 10iter: 0.9092 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mEpoch 4/10 | train |  Loss: 0.1199 Acc: 0.9537\u001b[0m\n",
      "\u001b[34mEpoch 4/10 |  val  |  Loss: 0.1784 Acc: 0.9333\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1093 || 10iter: 0.9153 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0904 || 10iter: 0.9095 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0763 || 10iter: 0.9098 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1475 || 10iter: 0.9118 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0261 || 10iter: 0.9103 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0550 || 10iter: 0.9095 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1064 || 10iter: 0.9105 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.2578 || 10iter: 0.9087 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1445 || 10iter: 0.9102 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1340 || 10iter: 0.9097 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0665 || 10iter: 0.9094 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0776 || 10iter: 0.9091 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 5/10 | train |  Loss: 0.1210 Acc: 0.9549\u001b[0m\n",
      "\u001b[34mEpoch 5/10 |  val  |  Loss: 0.1810 Acc: 0.9422\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.1800 || 10iter: 0.9173 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0452 || 10iter: 0.9198 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0945 || 10iter: 0.9142 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.0826 || 10iter: 0.9213 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.1030 || 10iter: 0.9160 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0761 || 10iter: 0.9101 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0708 || 10iter: 0.9112 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1997 || 10iter: 0.9098 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.0646 || 10iter: 0.9096 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0266 || 10iter: 0.9116 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0365 || 10iter: 0.9135 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0715 || 10iter: 0.9126 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 6/10 | train |  Loss: 0.1006 Acc: 0.9639\u001b[0m\n",
      "\u001b[34mEpoch 6/10 |  val  |  Loss: 0.1954 Acc: 0.9363\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0547 || 10iter: 0.9167 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0722 || 10iter: 0.9103 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1263 || 10iter: 0.9097 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1391 || 10iter: 0.9093 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0544 || 10iter: 0.9118 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0984 || 10iter: 0.9108 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1187 || 10iter: 0.9251 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.0629 || 10iter: 0.9107 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1141 || 10iter: 0.9109 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0633 || 10iter: 0.9151 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0086 || 10iter: 0.9129 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0443 || 10iter: 0.9104 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 7/10 | train |  Loss: 0.0953 Acc: 0.9629\u001b[0m\n",
      "\u001b[34mEpoch 7/10 |  val  |  Loss: 0.1848 Acc: 0.9412\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0826 || 10iter: 0.9161 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.3063 || 10iter: 0.9102 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0453 || 10iter: 0.9120 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.1745 || 10iter: 0.9110 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0818 || 10iter: 0.9117 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0403 || 10iter: 0.9112 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0775 || 10iter: 0.9124 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.0302 || 10iter: 0.9125 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1044 || 10iter: 0.9110 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0694 || 10iter: 0.9116 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.1572 || 10iter: 0.9143 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0476 || 10iter: 0.9173 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 8/10 | train |  Loss: 0.0920 Acc: 0.9654\u001b[0m\n",
      "\u001b[34mEpoch 8/10 |  val  |  Loss: 0.1928 Acc: 0.9353\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0707 || 10iter: 0.9207 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0801 || 10iter: 0.9147 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.1421 || 10iter: 0.9178 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.0268 || 10iter: 0.9165 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0780 || 10iter: 0.9160 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0129 || 10iter: 0.9134 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.1001 || 10iter: 0.9124 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.0725 || 10iter: 0.9128 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.0570 || 10iter: 0.9171 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.1249 || 10iter: 0.9113 sec. || Accuracy: 0.90625\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.3140 || 10iter: 0.9127 sec. || Accuracy: 0.84375\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.2807 || 10iter: 0.9125 sec. || Accuracy: 0.875\u001b[0m\n",
      "\u001b[34mEpoch 9/10 | train |  Loss: 0.0906 Acc: 0.9639\u001b[0m\n",
      "\u001b[34mEpoch 9/10 |  val  |  Loss: 0.1927 Acc: 0.9343\u001b[0m\n",
      "\u001b[34mIteration 10 || Loss: 0.0431 || 10iter: 0.9223 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 20 || Loss: 0.0372 || 10iter: 0.9221 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 30 || Loss: 0.0911 || 10iter: 0.9231 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 40 || Loss: 0.0679 || 10iter: 0.9199 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 50 || Loss: 0.0708 || 10iter: 0.9166 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 60 || Loss: 0.0854 || 10iter: 0.9167 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 70 || Loss: 0.0170 || 10iter: 0.9160 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 80 || Loss: 0.1696 || 10iter: 0.9116 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 90 || Loss: 0.1087 || 10iter: 0.9113 sec. || Accuracy: 0.9375\u001b[0m\n",
      "\u001b[34mIteration 100 || Loss: 0.0154 || 10iter: 0.9179 sec. || Accuracy: 1.0\u001b[0m\n",
      "\u001b[34mIteration 110 || Loss: 0.0602 || 10iter: 0.9199 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mIteration 120 || Loss: 0.0808 || 10iter: 0.9247 sec. || Accuracy: 0.96875\u001b[0m\n",
      "\u001b[34mEpoch 10/10 | train |  Loss: 0.0814 Acc: 0.9716\u001b[0m\n",
      "\u001b[34mEpoch 10/10 |  val  |  Loss: 0.1875 Acc: 0.9422\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/53 [00:00<?, ?it/s]#015  4%|▍         | 2/53 [00:00<00:04, 12.08it/s]#015  8%|▊         | 4/53 [00:00<00:04, 12.06it/s]#015 11%|█▏        | 6/53 [00:00<00:03, 12.05it/s]#015 15%|█▌        | 8/53 [00:00<00:03, 12.04it/s]#015 19%|█▉        | 10/53 [00:00<00:03, 12.03it/s]#015 23%|██▎       | 12/53 [00:00<00:03, 12.03it/s]#015 26%|██▋       | 14/53 [00:01<00:03, 12.02it/s]#015 30%|███       | 16/53 [00:01<00:03, 12.01it/s]#015 34%|███▍      | 18/53 [00:01<00:02, 12.01it/s]#015 38%|███▊      | 20/53 [00:01<00:02, 12.01it/s]#015 42%|████▏     | 22/53 [00:01<00:02, 12.00it/s]#015 45%|████▌     | 24/53 [00:01<00:02, 11.99it/s]#015 49%|████▉     | 26/53 [00:02<00:02, 11.99it/s]#015 53%|█████▎    | 28/53 [00:02<00:02, 11.99it/s]#015 57%|█████▋    | 30/53 [00:02<00:01, 12.01it/s]#015 60%|██████    | 32/53 [00:02<00:01, 12.01it/s]#015 64%|██████▍   | 34/53 [00:02<00:01, 12.01it/s]#015 68%|██████▊   | 36/53 [00:02<00:01, 12.01it/s]#015 72%|███████▏  | 38/53 [00:03<00:01, 12.01it/s]#015 75%|███████▌  | 40/53 [00:03<00:01, 12.01it/s]#015 79%|███████▉  | 42/53 [00:03<00:00, 12.01it/s]#015 83%|████████▎ | 44/53 [00:03<00:00, 12.00it/s]#015 87%|████████▋ | 46/53 [00:03<00:00, 11.99it/s]#015 91%|█████████ | 48/53 [00:03<00:00, 11.99it/s]#015 94%|█████████▍| 50/53 [00:04<00:00, 11.99it/s]#015 98%|█████████▊| 52/53 [00:04<00:00, 11.99it/s]#015100%|██████████| 53/53 [00:04<00:00, 12.16it/s]\u001b[0m\n",
      "\u001b[34mTest Data 1674 Accuracy: 0.9534\u001b[0m\n",
      "\u001b[34mRecall                      0.9534\u001b[0m\n",
      "\u001b[34mPrecision                   0.9551\u001b[0m\n",
      "\u001b[34mF1                          0.9539\u001b[0m\n",
      "\u001b[34mKappa                       0.8868\u001b[0m\n",
      "\u001b[34mQuadratic Weighted Kappa    0.9292\u001b[0m\n",
      "\u001b[34mdtype: float64\u001b[0m\n",
      "\u001b[34mConfusion Matrix:\n",
      "      0    1    2  3\u001b[0m\n",
      "\u001b[34m0  1227   26    3  1\u001b[0m\n",
      "\u001b[34m1     7  247   14  0\u001b[0m\n",
      "\u001b[34m2     0   19  114  2\u001b[0m\n",
      "\u001b[34m3     1    0    5  8\u001b[0m\n",
      "\u001b[34m----------------\u001b[0m\n",
      "\u001b[34mALL DATA (Macro Average):\n",
      "         Recall  Precision        F1     Kappa  Quadratic Weighted Kappa\u001b[0m\n",
      "\u001b[34mcount  4.000000   4.000000  4.000000  4.000000                  4.000000\u001b[0m\n",
      "\u001b[34mmean   0.929800   0.930450  0.929375  0.821600                  0.868325\u001b[0m\n",
      "\u001b[34mstd    0.019894   0.023099  0.022034  0.056310                  0.048195\u001b[0m\n",
      "\u001b[34mmin    0.905000   0.899700  0.900600  0.750700                  0.811300\u001b[0m\n",
      "\u001b[34m25%    0.922025   0.922200  0.921525  0.798175                  0.851650\u001b[0m\n",
      "\u001b[34m50%    0.930400   0.933500  0.931500  0.824450                  0.866400\u001b[0m\n",
      "\u001b[34m75%    0.938175   0.941750  0.939350  0.847875                  0.883075\u001b[0m\n",
      "\u001b[34mmax    0.953400   0.955100  0.953900  0.886800                  0.929200\u001b[0m\n",
      "\u001b[34m----------------\u001b[0m\n",
      "\u001b[34mALL DATA (Micro Average):\u001b[0m\n",
      "\u001b[34mRecall                      0.9298\u001b[0m\n",
      "\u001b[34mPrecision                   0.9304\u001b[0m\n",
      "\u001b[34mF1                          0.9298\u001b[0m\n",
      "\u001b[34mKappa                       0.8231\u001b[0m\n",
      "\u001b[34mQuadratic Weighted Kappa    0.8686\u001b[0m\n",
      "\u001b[34mdtype: float64\u001b[0m\n",
      "\u001b[34mConfusion Matrix:\n",
      "      0    1    2   3\u001b[0m\n",
      "\u001b[34m0  4930  104   34   4\u001b[0m\n",
      "\u001b[34m1    89  871   89   1\u001b[0m\n",
      "\u001b[34m2    27   80  390   7\u001b[0m\n",
      "\u001b[34m3     8    1   26  32\u001b[0m\n",
      "\u001b[34mTraining complete.\u001b[0m\n",
      "\n",
      "2021-03-13 04:00:39 Uploading - Uploading generated training model\n",
      "2021-03-13 04:03:39 Completed - Training job completed\n",
      "Training seconds: 1083\n",
      "Billable seconds: 1083\n"
     ]
    }
   ],
   "source": [
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "\n",
    "# Makoto.Sano@Mack-the-Psych.com\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/sagemaker-vdok3-bert-cv-sen:latest'.format(account, region)\n",
    "vdok3bert = sage.estimator.Estimator(image,\n",
    "                       role, 1, 'ml.p3.2xlarge',\n",
    "                       output_path=\"s3://{}/output\".format(sess.default_bucket()),\n",
    "                       sagemaker_session=sess)\n",
    "vdok3bert.fit(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "predictor = vdok3bert.deploy(1, 'ml.p3.2xlarge', serializer=csv_serializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score_Class,Sentence-Score\n",
      "0,0\n",
      "2,1\n",
      "2,2\n",
      "2,3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_in = pd.read_csv('data/Pick4-Refmt_Serialized-Sen-ELVA.PILOT.PRE-POST-TEST.csv')\n",
    "np_in = np.vstack((np.array(df_in.columns), df_in.to_numpy()))\n",
    "print(predictor.predict(np_in).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "sess.delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_output_folder = \"batch-transform-output\"\n",
    "output_path=\"s3://{}/{}\".format(sess.default_bucket(), transform_output_folder)\n",
    "\n",
    "transformer = vdok3bert.transformer(instance_count=1,\n",
    "                               instance_type='ml.p3.2xlarge',\n",
    "                               output_path=output_path,\n",
    "                               assemble_with='Line',\n",
    "                               accept='text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................................\u001b[34mStarting the inference server with 8 workers.\u001b[0m\n",
      "\u001b[34m2021/03/13 04:36:25 [crit] 42#42: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [13/Mar/2021:04:36:25 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2021/03/13 04:36:25 [crit] 42#42: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [13/Mar/2021:04:36:25 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2021/03/13 04:36:25 [crit] 42#42: *5 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [13/Mar/2021:04:36:25 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2021/03/13 04:36:25 [crit] 42#42: *7 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [13/Mar/2021:04:36:25 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2021-03-13 04:36:25 +0000] [41] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2021-03-13 04:36:25 +0000] [41] [INFO] Listening at: unix:/tmp/gunicorn.sock (41)\u001b[0m\n",
      "\u001b[34m[2021-03-13 04:36:25 +0000] [41] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-03-13 04:36:25 +0000] [45] [INFO] Booting worker with pid: 45\u001b[0m\n",
      "\u001b[34m[2021-03-13 04:36:25 +0000] [46] [INFO] Booting worker with pid: 46\u001b[0m\n",
      "\u001b[34m[2021-03-13 04:36:25 +0000] [54] [INFO] Booting worker with pid: 54\u001b[0m\n",
      "\u001b[34m[2021-03-13 04:36:25 +0000] [62] [INFO] Booting worker with pid: 62\u001b[0m\n",
      "\u001b[34m[2021-03-13 04:36:25 +0000] [63] [INFO] Booting worker with pid: 63\u001b[0m\n",
      "\u001b[34m[2021-03-13 04:36:25 +0000] [64] [INFO] Booting worker with pid: 64\u001b[0m\n",
      "\u001b[34m[2021-03-13 04:36:25 +0000] [80] [INFO] Booting worker with pid: 80\u001b[0m\n",
      "\u001b[34m[2021-03-13 04:36:25 +0000] [89] [INFO] Booting worker with pid: 89\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34mbert.embeddings.word_embeddings.weight→embeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.position_embeddings.weight→embeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.token_type_embeddings.weight→embeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.gamma→embeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.beta→embeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.weight→encoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.bias→encoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.weight→encoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.bias→encoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.weight→encoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.bias→encoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.weight→encoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.bias→encoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.gamma→encoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.beta→encoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.weight→encoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.bias→encoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.weight→encoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.bias→encoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.gamma→encoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.beta→encoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.weight→encoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.bias→encoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.weight→encoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.bias→encoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.weight→encoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.bias→encoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.weight→encoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.bias→encoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.gamma→encoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.beta→encoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.weight→encoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.bias→encoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.weight→encoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.bias→encoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.gamma→encoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.beta→encoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.weight→encoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.bias→encoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.weight→encoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.bias→encoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.weight→encoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.bias→encoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.weight→encoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.bias→encoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.gamma→encoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.beta→encoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.weight→encoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.bias→encoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.weight→encoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.bias→encoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.gamma→encoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.beta→encoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.weight→encoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.bias→encoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.weight→encoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.bias→encoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.weight→encoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.bias→encoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.weight→encoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.bias→encoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.gamma→encoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.beta→encoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.weight→encoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.bias→encoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.weight→encoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.bias→encoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.gamma→encoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.beta→encoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.weight→encoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.bias→encoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.weight→encoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.bias→encoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.weight→encoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.bias→encoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.weight→encoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.bias→encoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.gamma→encoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.beta→encoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.weight→encoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.bias→encoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.weight→encoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.bias→encoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.gamma→encoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.beta→encoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.weight→encoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.bias→encoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.weight→encoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.bias→encoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.weight→encoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.bias→encoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.weight→encoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.bias→encoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.gamma→encoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.beta→encoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.weight→encoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.bias→encoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.weight→encoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.bias→encoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.gamma→encoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.beta→encoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.weight→encoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.bias→encoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.weight→encoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.bias→encoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.weight→encoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.bias→encoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.weight→encoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.bias→encoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.gamma→encoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.beta→encoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.weight→encoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.bias→encoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.weight→encoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.bias→encoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.gamma→encoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.beta→encoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.weight→encoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.bias→encoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.weight→encoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.bias→encoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.weight→encoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.bias→encoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.weight→encoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.bias→encoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.gamma→encoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.beta→encoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.weight→encoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.bias→encoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.weight→encoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.bias→encoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.gamma→encoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.beta→encoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.weight→encoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.bias→encoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.weight→encoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.bias→encoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.weight→encoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.bias→encoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.weight→encoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.bias→encoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.gamma→encoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.beta→encoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.weight→encoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.bias→encoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.weight→encoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.bias→encoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.gamma→encoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.beta→encoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.weight→encoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.bias→encoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.weight→encoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.bias→encoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.weight→encoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.bias→encoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.weight→encoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.bias→encoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.gamma→encoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.beta→encoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.weight→encoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.bias→encoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.weight→encoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.bias→encoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.gamma→encoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.beta→encoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.weight→encoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.bias→encoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.weight→encoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.bias→encoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.weight→encoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.bias→encoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.weight→encoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.bias→encoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.gamma→encoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.beta→encoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.weight→encoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.bias→encoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.weight→encoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.bias→encoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.gamma→encoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.beta→encoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.weight→encoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.bias→encoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.weight→encoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.bias→encoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.weight→encoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.bias→encoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.weight→encoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.bias→encoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.gamma→encoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.beta→encoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.weight→encoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.bias→encoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.weight→encoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.bias→encoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.gamma→encoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.beta→encoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.weight→pooler.dense.weight\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.bias→pooler.dense.bias\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [13/Mar/2021:04:36:39 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [13/Mar/2021:04:36:39 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 4 records\u001b[0m\n",
      "\u001b[34mbert.embeddings.word_embeddings.weight→embeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.position_embeddings.weight→embeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.token_type_embeddings.weight→embeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.gamma→embeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.beta→embeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.weight→encoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.bias→encoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.weight→encoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.bias→encoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.weight→encoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.bias→encoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.weight→encoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.bias→encoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.gamma→encoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.beta→encoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.weight→encoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.bias→encoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.weight→encoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.bias→encoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.gamma→encoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.beta→encoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.weight→encoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.bias→encoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.weight→encoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.bias→encoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.weight→encoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.bias→encoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.weight→encoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.bias→encoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.gamma→encoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.beta→encoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.weight→encoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.bias→encoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.weight→encoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.bias→encoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.gamma→encoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.beta→encoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.weight→encoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.bias→encoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.weight→encoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.bias→encoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.weight→encoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.bias→encoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.weight→encoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.bias→encoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.gamma→encoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.beta→encoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.weight→encoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.bias→encoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.weight→encoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.bias→encoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.gamma→encoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.beta→encoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.weight→encoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.bias→encoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.weight→encoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.bias→encoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.weight→encoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.bias→encoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.weight→encoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.bias→encoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.gamma→encoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.beta→encoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.weight→encoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.bias→encoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.weight→encoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.bias→encoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.gamma→encoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.beta→encoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.weight→encoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.bias→encoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.weight→encoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.bias→encoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.weight→encoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.bias→encoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.weight→encoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.bias→encoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.gamma→encoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.beta→encoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.weight→encoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.bias→encoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.weight→encoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.bias→encoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.gamma→encoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.beta→encoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.weight→encoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.bias→encoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.weight→encoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.bias→encoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.weight→encoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.bias→encoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.weight→encoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.bias→encoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.gamma→encoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.beta→encoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.weight→encoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.bias→encoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.weight→encoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.bias→encoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.gamma→encoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.beta→encoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.weight→encoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.bias→encoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.weight→encoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.bias→encoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.weight→encoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.bias→encoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.weight→encoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.bias→encoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.gamma→encoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.beta→encoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.weight→encoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.bias→encoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.weight→encoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.bias→encoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.gamma→encoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.beta→encoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.weight→encoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.bias→encoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.weight→encoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.bias→encoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.weight→encoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.bias→encoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.weight→encoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.bias→encoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.gamma→encoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.beta→encoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.weight→encoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.bias→encoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.weight→encoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.bias→encoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.gamma→encoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.beta→encoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.weight→encoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.bias→encoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.weight→encoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.bias→encoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.weight→encoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.bias→encoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.weight→encoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.bias→encoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.gamma→encoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.beta→encoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.weight→encoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.bias→encoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.weight→encoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.bias→encoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.gamma→encoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.beta→encoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.weight→encoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.bias→encoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.weight→encoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.bias→encoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.weight→encoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.bias→encoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.weight→encoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.bias→encoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.gamma→encoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.beta→encoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.weight→encoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.bias→encoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.weight→encoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.bias→encoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.gamma→encoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.beta→encoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.weight→encoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.bias→encoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.weight→encoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.bias→encoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.weight→encoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.bias→encoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.weight→encoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.bias→encoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.gamma→encoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.beta→encoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.weight→encoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.bias→encoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.weight→encoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.bias→encoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.gamma→encoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.beta→encoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.weight→encoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.bias→encoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.weight→encoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.bias→encoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.weight→encoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.bias→encoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.weight→encoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.bias→encoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.gamma→encoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.beta→encoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.weight→encoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.bias→encoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.weight→encoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.bias→encoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.gamma→encoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.beta→encoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.weight→pooler.dense.weight\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.bias→pooler.dense.bias\u001b[0m\n",
      "\u001b[32m2021-03-13T04:36:39.984:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/1 [00:00<?, ?it/s]#015100%|██████████| 1/1 [00:00<00:00, 36.30it/s]\u001b[0m\n",
      "\u001b[34mTest Data 4 Accuracy: 0.5000\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [13/Mar/2021:04:36:49 +0000] \"POST /invocations HTTP/1.1\" 200 43 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m#015  0%|          | 0/1 [00:00<?, ?it/s]#015100%|██████████| 1/1 [00:00<00:00, 36.30it/s]\u001b[0m\n",
      "\u001b[35mTest Data 4 Accuracy: 0.5000\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [13/Mar/2021:04:36:49 +0000] \"POST /invocations HTTP/1.1\" 200 43 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\n",
      "\u001b[34mStarting the inference server with 8 workers.\u001b[0m\n",
      "\u001b[34m2021/03/13 04:36:25 [crit] 42#42: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [13/Mar/2021:04:36:25 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2021/03/13 04:36:25 [crit] 42#42: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [13/Mar/2021:04:36:25 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mStarting the inference server with 8 workers.\u001b[0m\n",
      "\u001b[35m2021/03/13 04:36:25 [crit] 42#42: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [13/Mar/2021:04:36:25 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2021/03/13 04:36:25 [crit] 42#42: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [13/Mar/2021:04:36:25 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2021/03/13 04:36:25 [crit] 42#42: *5 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [13/Mar/2021:04:36:25 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2021/03/13 04:36:25 [crit] 42#42: *7 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [13/Mar/2021:04:36:25 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2021-03-13 04:36:25 +0000] [41] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2021-03-13 04:36:25 +0000] [41] [INFO] Listening at: unix:/tmp/gunicorn.sock (41)\u001b[0m\n",
      "\u001b[34m[2021-03-13 04:36:25 +0000] [41] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-03-13 04:36:25 +0000] [45] [INFO] Booting worker with pid: 45\u001b[0m\n",
      "\u001b[34m[2021-03-13 04:36:25 +0000] [46] [INFO] Booting worker with pid: 46\u001b[0m\n",
      "\u001b[34m[2021-03-13 04:36:25 +0000] [54] [INFO] Booting worker with pid: 54\u001b[0m\n",
      "\u001b[34m[2021-03-13 04:36:25 +0000] [62] [INFO] Booting worker with pid: 62\u001b[0m\n",
      "\u001b[34m[2021-03-13 04:36:25 +0000] [63] [INFO] Booting worker with pid: 63\u001b[0m\n",
      "\u001b[34m[2021-03-13 04:36:25 +0000] [64] [INFO] Booting worker with pid: 64\u001b[0m\n",
      "\u001b[34m[2021-03-13 04:36:25 +0000] [80] [INFO] Booting worker with pid: 80\u001b[0m\n",
      "\u001b[34m[2021-03-13 04:36:25 +0000] [89] [INFO] Booting worker with pid: 89\u001b[0m\n",
      "\u001b[35m2021/03/13 04:36:25 [crit] 42#42: *5 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [13/Mar/2021:04:36:25 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2021/03/13 04:36:25 [crit] 42#42: *7 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [13/Mar/2021:04:36:25 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2021-03-13 04:36:25 +0000] [41] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[35m[2021-03-13 04:36:25 +0000] [41] [INFO] Listening at: unix:/tmp/gunicorn.sock (41)\u001b[0m\n",
      "\u001b[35m[2021-03-13 04:36:25 +0000] [41] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2021-03-13 04:36:25 +0000] [45] [INFO] Booting worker with pid: 45\u001b[0m\n",
      "\u001b[35m[2021-03-13 04:36:25 +0000] [46] [INFO] Booting worker with pid: 46\u001b[0m\n",
      "\u001b[35m[2021-03-13 04:36:25 +0000] [54] [INFO] Booting worker with pid: 54\u001b[0m\n",
      "\u001b[35m[2021-03-13 04:36:25 +0000] [62] [INFO] Booting worker with pid: 62\u001b[0m\n",
      "\u001b[35m[2021-03-13 04:36:25 +0000] [63] [INFO] Booting worker with pid: 63\u001b[0m\n",
      "\u001b[35m[2021-03-13 04:36:25 +0000] [64] [INFO] Booting worker with pid: 64\u001b[0m\n",
      "\u001b[35m[2021-03-13 04:36:25 +0000] [80] [INFO] Booting worker with pid: 80\u001b[0m\n",
      "\u001b[35m[2021-03-13 04:36:25 +0000] [89] [INFO] Booting worker with pid: 89\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[35m/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34mbert.embeddings.word_embeddings.weight→embeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.position_embeddings.weight→embeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.token_type_embeddings.weight→embeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.gamma→embeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.beta→embeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.weight→encoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.bias→encoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.weight→encoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.bias→encoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.weight→encoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.bias→encoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.weight→encoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.bias→encoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.gamma→encoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.beta→encoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.weight→encoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.bias→encoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.weight→encoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.bias→encoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.gamma→encoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.beta→encoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.weight→encoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.bias→encoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.embeddings.word_embeddings.weight→embeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[35mbert.embeddings.position_embeddings.weight→embeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[35mbert.embeddings.token_type_embeddings.weight→embeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[35mbert.embeddings.LayerNorm.gamma→embeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.embeddings.LayerNorm.beta→embeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.query.weight→encoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.query.bias→encoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.key.weight→encoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.key.bias→encoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.value.weight→encoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.value.bias→encoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.dense.weight→encoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.dense.bias→encoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.LayerNorm.gamma→encoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.LayerNorm.beta→encoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.intermediate.dense.weight→encoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.intermediate.dense.bias→encoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.dense.weight→encoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.dense.bias→encoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.LayerNorm.gamma→encoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.LayerNorm.beta→encoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.query.weight→encoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.query.bias→encoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.weight→encoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.bias→encoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.weight→encoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.bias→encoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.weight→encoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.bias→encoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.gamma→encoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.beta→encoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.weight→encoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.bias→encoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.weight→encoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.bias→encoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.gamma→encoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.beta→encoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.weight→encoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.bias→encoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.weight→encoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.bias→encoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.weight→encoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.bias→encoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.weight→encoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.bias→encoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.gamma→encoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.beta→encoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.weight→encoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.bias→encoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.weight→encoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.bias→encoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.gamma→encoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.beta→encoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.weight→encoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.bias→encoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.weight→encoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.bias→encoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.weight→encoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.bias→encoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.key.weight→encoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.key.bias→encoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.value.weight→encoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.value.bias→encoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.dense.weight→encoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.dense.bias→encoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.LayerNorm.gamma→encoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.LayerNorm.beta→encoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.intermediate.dense.weight→encoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.intermediate.dense.bias→encoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.dense.weight→encoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.dense.bias→encoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.LayerNorm.gamma→encoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.LayerNorm.beta→encoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.query.weight→encoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.query.bias→encoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.key.weight→encoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.key.bias→encoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.value.weight→encoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.value.bias→encoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.dense.weight→encoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.dense.bias→encoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.LayerNorm.gamma→encoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.LayerNorm.beta→encoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.intermediate.dense.weight→encoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.intermediate.dense.bias→encoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.dense.weight→encoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.dense.bias→encoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.LayerNorm.gamma→encoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.LayerNorm.beta→encoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.query.weight→encoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.query.bias→encoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.key.weight→encoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.key.bias→encoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.value.weight→encoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.value.bias→encoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.weight→encoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.bias→encoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.gamma→encoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.beta→encoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.weight→encoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.bias→encoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.weight→encoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.bias→encoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.gamma→encoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.beta→encoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.weight→encoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.bias→encoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.weight→encoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.bias→encoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.weight→encoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.bias→encoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.weight→encoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.bias→encoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.gamma→encoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.beta→encoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.weight→encoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.bias→encoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.weight→encoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.bias→encoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.gamma→encoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.beta→encoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.weight→encoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.bias→encoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.weight→encoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.bias→encoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.weight→encoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.bias→encoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.weight→encoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.bias→encoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.gamma→encoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.dense.weight→encoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.dense.bias→encoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.LayerNorm.gamma→encoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.LayerNorm.beta→encoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.intermediate.dense.weight→encoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.intermediate.dense.bias→encoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.dense.weight→encoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.dense.bias→encoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.LayerNorm.gamma→encoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.LayerNorm.beta→encoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.query.weight→encoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.query.bias→encoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.key.weight→encoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.key.bias→encoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.value.weight→encoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.value.bias→encoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.dense.weight→encoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.dense.bias→encoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.LayerNorm.gamma→encoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.LayerNorm.beta→encoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.intermediate.dense.weight→encoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.intermediate.dense.bias→encoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.dense.weight→encoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.dense.bias→encoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.LayerNorm.gamma→encoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.LayerNorm.beta→encoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.query.weight→encoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.query.bias→encoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.key.weight→encoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.key.bias→encoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.value.weight→encoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.value.bias→encoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.dense.weight→encoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.dense.bias→encoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.LayerNorm.gamma→encoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.beta→encoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.weight→encoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.bias→encoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.weight→encoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.bias→encoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.gamma→encoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.beta→encoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.weight→encoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.bias→encoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.weight→encoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.bias→encoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.weight→encoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.bias→encoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.weight→encoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.bias→encoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.gamma→encoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.beta→encoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.weight→encoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.bias→encoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.weight→encoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.bias→encoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.gamma→encoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.beta→encoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.weight→encoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.bias→encoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.weight→encoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.bias→encoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.weight→encoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.bias→encoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.weight→encoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.bias→encoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.gamma→encoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.beta→encoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.weight→encoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.LayerNorm.beta→encoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.intermediate.dense.weight→encoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.intermediate.dense.bias→encoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.dense.weight→encoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.dense.bias→encoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.LayerNorm.gamma→encoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.LayerNorm.beta→encoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.query.weight→encoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.query.bias→encoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.key.weight→encoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.key.bias→encoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.value.weight→encoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.value.bias→encoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.dense.weight→encoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.dense.bias→encoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.LayerNorm.gamma→encoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.LayerNorm.beta→encoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.intermediate.dense.weight→encoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.intermediate.dense.bias→encoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.dense.weight→encoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.dense.bias→encoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.LayerNorm.gamma→encoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.LayerNorm.beta→encoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.query.weight→encoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.query.bias→encoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.key.weight→encoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.key.bias→encoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.value.weight→encoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.value.bias→encoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.dense.weight→encoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.dense.bias→encoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.LayerNorm.gamma→encoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.LayerNorm.beta→encoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.intermediate.dense.weight→encoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.bias→encoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.weight→encoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.bias→encoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.gamma→encoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.beta→encoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.weight→encoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.bias→encoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.weight→encoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.bias→encoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.weight→encoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.bias→encoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.weight→encoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.bias→encoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.gamma→encoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.beta→encoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.weight→encoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.bias→encoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.weight→encoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.bias→encoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.gamma→encoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.beta→encoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.weight→encoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.bias→encoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.weight→encoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.bias→encoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.weight→encoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.bias→encoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.weight→encoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.bias→encoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.gamma→encoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.beta→encoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.weight→encoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.bias→encoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.weight→encoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.bias→encoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.intermediate.dense.bias→encoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.dense.weight→encoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.dense.bias→encoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.LayerNorm.gamma→encoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.LayerNorm.beta→encoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.query.weight→encoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.query.bias→encoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.key.weight→encoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.key.bias→encoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.value.weight→encoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.value.bias→encoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.dense.weight→encoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.dense.bias→encoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.LayerNorm.gamma→encoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.LayerNorm.beta→encoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.intermediate.dense.weight→encoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.intermediate.dense.bias→encoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.dense.weight→encoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.dense.bias→encoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.LayerNorm.gamma→encoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.LayerNorm.beta→encoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.query.weight→encoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.query.bias→encoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.key.weight→encoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.key.bias→encoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.value.weight→encoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.value.bias→encoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.dense.weight→encoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.dense.bias→encoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.LayerNorm.gamma→encoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.LayerNorm.beta→encoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.intermediate.dense.weight→encoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.intermediate.dense.bias→encoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.dense.weight→encoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.dense.bias→encoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.gamma→encoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.beta→encoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.weight→encoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.bias→encoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.weight→encoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.bias→encoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.weight→encoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.bias→encoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.weight→encoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.bias→encoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.gamma→encoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.beta→encoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.weight→encoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.bias→encoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.weight→encoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.bias→encoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.gamma→encoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.beta→encoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.weight→encoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.bias→encoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.weight→encoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.bias→encoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.weight→encoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.bias→encoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.weight→encoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.bias→encoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.gamma→encoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.beta→encoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.weight→encoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.bias→encoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.weight→encoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.bias→encoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.gamma→encoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.beta→encoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.weight→pooler.dense.weight\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.bias→pooler.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.LayerNorm.gamma→encoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.LayerNorm.beta→encoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.query.weight→encoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.query.bias→encoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.key.weight→encoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.key.bias→encoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.value.weight→encoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.value.bias→encoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.dense.weight→encoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.dense.bias→encoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.LayerNorm.gamma→encoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.LayerNorm.beta→encoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.intermediate.dense.weight→encoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.intermediate.dense.bias→encoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.dense.weight→encoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.dense.bias→encoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.LayerNorm.gamma→encoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.LayerNorm.beta→encoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.query.weight→encoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.query.bias→encoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.key.weight→encoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.key.bias→encoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.value.weight→encoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.value.bias→encoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.dense.weight→encoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.dense.bias→encoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.LayerNorm.gamma→encoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.LayerNorm.beta→encoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.intermediate.dense.weight→encoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.intermediate.dense.bias→encoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.dense.weight→encoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.dense.bias→encoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.LayerNorm.gamma→encoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.LayerNorm.beta→encoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.pooler.dense.weight→pooler.dense.weight\u001b[0m\n",
      "\u001b[35mbert.pooler.dense.bias→pooler.dense.bias\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [13/Mar/2021:04:36:39 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [13/Mar/2021:04:36:39 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 4 records\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [13/Mar/2021:04:36:39 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [13/Mar/2021:04:36:39 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 4 records\u001b[0m\n",
      "\u001b[32m2021-03-13T04:36:39.984:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34mbert.embeddings.word_embeddings.weight→embeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.position_embeddings.weight→embeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.token_type_embeddings.weight→embeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.gamma→embeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.embeddings.LayerNorm.beta→embeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.weight→encoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.query.bias→encoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.weight→encoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.key.bias→encoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.weight→encoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.self.value.bias→encoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.weight→encoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.dense.bias→encoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.gamma→encoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.attention.output.LayerNorm.beta→encoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.weight→encoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.intermediate.dense.bias→encoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.weight→encoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.dense.bias→encoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.gamma→encoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.0.output.LayerNorm.beta→encoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.weight→encoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.query.bias→encoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.weight→encoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.key.bias→encoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.weight→encoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.self.value.bias→encoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.weight→encoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.dense.bias→encoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.gamma→encoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.attention.output.LayerNorm.beta→encoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.embeddings.word_embeddings.weight→embeddings.word_embeddings.weight\u001b[0m\n",
      "\u001b[35mbert.embeddings.position_embeddings.weight→embeddings.position_embeddings.weight\u001b[0m\n",
      "\u001b[35mbert.embeddings.token_type_embeddings.weight→embeddings.token_type_embeddings.weight\u001b[0m\n",
      "\u001b[35mbert.embeddings.LayerNorm.gamma→embeddings.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.embeddings.LayerNorm.beta→embeddings.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.query.weight→encoder.layer.0.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.query.bias→encoder.layer.0.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.key.weight→encoder.layer.0.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.key.bias→encoder.layer.0.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.value.weight→encoder.layer.0.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.self.value.bias→encoder.layer.0.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.dense.weight→encoder.layer.0.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.dense.bias→encoder.layer.0.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.LayerNorm.gamma→encoder.layer.0.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.attention.output.LayerNorm.beta→encoder.layer.0.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.intermediate.dense.weight→encoder.layer.0.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.intermediate.dense.bias→encoder.layer.0.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.dense.weight→encoder.layer.0.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.dense.bias→encoder.layer.0.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.LayerNorm.gamma→encoder.layer.0.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.0.output.LayerNorm.beta→encoder.layer.0.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.query.weight→encoder.layer.1.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.query.bias→encoder.layer.1.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.key.weight→encoder.layer.1.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.key.bias→encoder.layer.1.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.value.weight→encoder.layer.1.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.self.value.bias→encoder.layer.1.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.dense.weight→encoder.layer.1.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.dense.bias→encoder.layer.1.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.LayerNorm.gamma→encoder.layer.1.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.attention.output.LayerNorm.beta→encoder.layer.1.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.weight→encoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.intermediate.dense.bias→encoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.weight→encoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.dense.bias→encoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.gamma→encoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.1.output.LayerNorm.beta→encoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.weight→encoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.query.bias→encoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.weight→encoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.key.bias→encoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.weight→encoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.self.value.bias→encoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.weight→encoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.dense.bias→encoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.gamma→encoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.attention.output.LayerNorm.beta→encoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.weight→encoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.intermediate.dense.bias→encoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.weight→encoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.dense.bias→encoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.gamma→encoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.2.output.LayerNorm.beta→encoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.weight→encoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.query.bias→encoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.weight→encoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.key.bias→encoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.weight→encoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.self.value.bias→encoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.weight→encoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.dense.bias→encoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.gamma→encoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.attention.output.LayerNorm.beta→encoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.weight→encoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.intermediate.dense.bias→encoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.weight→encoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.dense.bias→encoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.intermediate.dense.weight→encoder.layer.1.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.intermediate.dense.bias→encoder.layer.1.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.dense.weight→encoder.layer.1.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.dense.bias→encoder.layer.1.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.LayerNorm.gamma→encoder.layer.1.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.1.output.LayerNorm.beta→encoder.layer.1.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.query.weight→encoder.layer.2.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.query.bias→encoder.layer.2.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.key.weight→encoder.layer.2.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.key.bias→encoder.layer.2.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.value.weight→encoder.layer.2.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.self.value.bias→encoder.layer.2.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.dense.weight→encoder.layer.2.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.dense.bias→encoder.layer.2.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.LayerNorm.gamma→encoder.layer.2.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.attention.output.LayerNorm.beta→encoder.layer.2.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.intermediate.dense.weight→encoder.layer.2.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.intermediate.dense.bias→encoder.layer.2.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.dense.weight→encoder.layer.2.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.dense.bias→encoder.layer.2.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.LayerNorm.gamma→encoder.layer.2.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.2.output.LayerNorm.beta→encoder.layer.2.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.query.weight→encoder.layer.3.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.query.bias→encoder.layer.3.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.key.weight→encoder.layer.3.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.key.bias→encoder.layer.3.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.value.weight→encoder.layer.3.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.self.value.bias→encoder.layer.3.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.dense.weight→encoder.layer.3.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.dense.bias→encoder.layer.3.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.LayerNorm.gamma→encoder.layer.3.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.attention.output.LayerNorm.beta→encoder.layer.3.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.intermediate.dense.weight→encoder.layer.3.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.intermediate.dense.bias→encoder.layer.3.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.dense.weight→encoder.layer.3.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.dense.bias→encoder.layer.3.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.gamma→encoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.3.output.LayerNorm.beta→encoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.weight→encoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.query.bias→encoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.weight→encoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.key.bias→encoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.weight→encoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.self.value.bias→encoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.weight→encoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.dense.bias→encoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.gamma→encoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.attention.output.LayerNorm.beta→encoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.weight→encoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.intermediate.dense.bias→encoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.weight→encoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.dense.bias→encoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.gamma→encoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.4.output.LayerNorm.beta→encoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.weight→encoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.query.bias→encoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.weight→encoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.key.bias→encoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.weight→encoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.self.value.bias→encoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.weight→encoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.dense.bias→encoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.gamma→encoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.attention.output.LayerNorm.beta→encoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.weight→encoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.intermediate.dense.bias→encoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.weight→encoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.dense.bias→encoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.gamma→encoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.5.output.LayerNorm.beta→encoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.weight→encoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.query.bias→encoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.weight→encoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.key.bias→encoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.LayerNorm.gamma→encoder.layer.3.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.3.output.LayerNorm.beta→encoder.layer.3.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.query.weight→encoder.layer.4.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.query.bias→encoder.layer.4.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.key.weight→encoder.layer.4.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.key.bias→encoder.layer.4.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.value.weight→encoder.layer.4.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.self.value.bias→encoder.layer.4.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.dense.weight→encoder.layer.4.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.dense.bias→encoder.layer.4.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.LayerNorm.gamma→encoder.layer.4.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.attention.output.LayerNorm.beta→encoder.layer.4.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.intermediate.dense.weight→encoder.layer.4.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.intermediate.dense.bias→encoder.layer.4.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.dense.weight→encoder.layer.4.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.dense.bias→encoder.layer.4.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.LayerNorm.gamma→encoder.layer.4.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.4.output.LayerNorm.beta→encoder.layer.4.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.query.weight→encoder.layer.5.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.query.bias→encoder.layer.5.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.key.weight→encoder.layer.5.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.key.bias→encoder.layer.5.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.value.weight→encoder.layer.5.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.self.value.bias→encoder.layer.5.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.dense.weight→encoder.layer.5.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.dense.bias→encoder.layer.5.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.LayerNorm.gamma→encoder.layer.5.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.attention.output.LayerNorm.beta→encoder.layer.5.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.intermediate.dense.weight→encoder.layer.5.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.intermediate.dense.bias→encoder.layer.5.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.dense.weight→encoder.layer.5.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.dense.bias→encoder.layer.5.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.LayerNorm.gamma→encoder.layer.5.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.5.output.LayerNorm.beta→encoder.layer.5.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.query.weight→encoder.layer.6.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.query.bias→encoder.layer.6.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.key.weight→encoder.layer.6.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.key.bias→encoder.layer.6.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.weight→encoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.self.value.bias→encoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.weight→encoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.dense.bias→encoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.gamma→encoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.attention.output.LayerNorm.beta→encoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.weight→encoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.intermediate.dense.bias→encoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.weight→encoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.dense.bias→encoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.gamma→encoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.6.output.LayerNorm.beta→encoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.weight→encoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.query.bias→encoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.weight→encoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.key.bias→encoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.weight→encoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.self.value.bias→encoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.weight→encoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.dense.bias→encoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.gamma→encoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.attention.output.LayerNorm.beta→encoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.weight→encoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.intermediate.dense.bias→encoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.weight→encoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.dense.bias→encoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.gamma→encoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.7.output.LayerNorm.beta→encoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.weight→encoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.query.bias→encoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.weight→encoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.key.bias→encoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.weight→encoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.self.value.bias→encoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.weight→encoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.value.weight→encoder.layer.6.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.self.value.bias→encoder.layer.6.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.dense.weight→encoder.layer.6.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.dense.bias→encoder.layer.6.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.LayerNorm.gamma→encoder.layer.6.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.attention.output.LayerNorm.beta→encoder.layer.6.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.intermediate.dense.weight→encoder.layer.6.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.intermediate.dense.bias→encoder.layer.6.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.dense.weight→encoder.layer.6.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.dense.bias→encoder.layer.6.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.LayerNorm.gamma→encoder.layer.6.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.6.output.LayerNorm.beta→encoder.layer.6.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.query.weight→encoder.layer.7.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.query.bias→encoder.layer.7.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.key.weight→encoder.layer.7.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.key.bias→encoder.layer.7.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.value.weight→encoder.layer.7.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.self.value.bias→encoder.layer.7.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.dense.weight→encoder.layer.7.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.dense.bias→encoder.layer.7.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.LayerNorm.gamma→encoder.layer.7.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.attention.output.LayerNorm.beta→encoder.layer.7.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.intermediate.dense.weight→encoder.layer.7.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.intermediate.dense.bias→encoder.layer.7.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.dense.weight→encoder.layer.7.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.dense.bias→encoder.layer.7.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.LayerNorm.gamma→encoder.layer.7.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.7.output.LayerNorm.beta→encoder.layer.7.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.query.weight→encoder.layer.8.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.query.bias→encoder.layer.8.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.key.weight→encoder.layer.8.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.key.bias→encoder.layer.8.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.value.weight→encoder.layer.8.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.self.value.bias→encoder.layer.8.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.dense.weight→encoder.layer.8.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.dense.bias→encoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.gamma→encoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.attention.output.LayerNorm.beta→encoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.weight→encoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.intermediate.dense.bias→encoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.weight→encoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.dense.bias→encoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.gamma→encoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.8.output.LayerNorm.beta→encoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.weight→encoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.query.bias→encoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.weight→encoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.key.bias→encoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.weight→encoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.self.value.bias→encoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.weight→encoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.dense.bias→encoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.gamma→encoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.attention.output.LayerNorm.beta→encoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.weight→encoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.intermediate.dense.bias→encoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.weight→encoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.dense.bias→encoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.gamma→encoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.9.output.LayerNorm.beta→encoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.weight→encoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.query.bias→encoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.weight→encoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.key.bias→encoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.weight→encoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.self.value.bias→encoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.weight→encoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.dense.bias→encoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.gamma→encoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.attention.output.LayerNorm.beta→encoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.weight→encoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.dense.bias→encoder.layer.8.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.LayerNorm.gamma→encoder.layer.8.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.attention.output.LayerNorm.beta→encoder.layer.8.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.intermediate.dense.weight→encoder.layer.8.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.intermediate.dense.bias→encoder.layer.8.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.dense.weight→encoder.layer.8.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.dense.bias→encoder.layer.8.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.LayerNorm.gamma→encoder.layer.8.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.8.output.LayerNorm.beta→encoder.layer.8.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.query.weight→encoder.layer.9.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.query.bias→encoder.layer.9.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.key.weight→encoder.layer.9.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.key.bias→encoder.layer.9.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.value.weight→encoder.layer.9.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.self.value.bias→encoder.layer.9.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.dense.weight→encoder.layer.9.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.dense.bias→encoder.layer.9.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.LayerNorm.gamma→encoder.layer.9.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.attention.output.LayerNorm.beta→encoder.layer.9.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.intermediate.dense.weight→encoder.layer.9.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.intermediate.dense.bias→encoder.layer.9.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.dense.weight→encoder.layer.9.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.dense.bias→encoder.layer.9.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.LayerNorm.gamma→encoder.layer.9.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.9.output.LayerNorm.beta→encoder.layer.9.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.query.weight→encoder.layer.10.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.query.bias→encoder.layer.10.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.key.weight→encoder.layer.10.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.key.bias→encoder.layer.10.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.value.weight→encoder.layer.10.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.self.value.bias→encoder.layer.10.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.dense.weight→encoder.layer.10.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.dense.bias→encoder.layer.10.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.LayerNorm.gamma→encoder.layer.10.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.attention.output.LayerNorm.beta→encoder.layer.10.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.intermediate.dense.weight→encoder.layer.10.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.intermediate.dense.bias→encoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.weight→encoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.dense.bias→encoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.gamma→encoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.10.output.LayerNorm.beta→encoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.weight→encoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.query.bias→encoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.weight→encoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.key.bias→encoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.weight→encoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.self.value.bias→encoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.weight→encoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.dense.bias→encoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.gamma→encoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.attention.output.LayerNorm.beta→encoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.weight→encoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.intermediate.dense.bias→encoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.weight→encoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.dense.bias→encoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.gamma→encoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[34mbert.encoder.layer.11.output.LayerNorm.beta→encoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.weight→pooler.dense.weight\u001b[0m\n",
      "\u001b[34mbert.pooler.dense.bias→pooler.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.intermediate.dense.bias→encoder.layer.10.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.dense.weight→encoder.layer.10.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.dense.bias→encoder.layer.10.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.LayerNorm.gamma→encoder.layer.10.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.10.output.LayerNorm.beta→encoder.layer.10.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.query.weight→encoder.layer.11.attention.selfattn.query.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.query.bias→encoder.layer.11.attention.selfattn.query.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.key.weight→encoder.layer.11.attention.selfattn.key.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.key.bias→encoder.layer.11.attention.selfattn.key.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.value.weight→encoder.layer.11.attention.selfattn.value.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.self.value.bias→encoder.layer.11.attention.selfattn.value.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.dense.weight→encoder.layer.11.attention.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.dense.bias→encoder.layer.11.attention.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.LayerNorm.gamma→encoder.layer.11.attention.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.attention.output.LayerNorm.beta→encoder.layer.11.attention.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.intermediate.dense.weight→encoder.layer.11.intermediate.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.intermediate.dense.bias→encoder.layer.11.intermediate.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.dense.weight→encoder.layer.11.output.dense.weight\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.dense.bias→encoder.layer.11.output.dense.bias\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.LayerNorm.gamma→encoder.layer.11.output.LayerNorm.gamma\u001b[0m\n",
      "\u001b[35mbert.encoder.layer.11.output.LayerNorm.beta→encoder.layer.11.output.LayerNorm.beta\u001b[0m\n",
      "\u001b[35mbert.pooler.dense.weight→pooler.dense.weight\u001b[0m\n",
      "\u001b[35mbert.pooler.dense.bias→pooler.dense.bias\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/1 [00:00<?, ?it/s]#015100%|██████████| 1/1 [00:00<00:00, 36.30it/s]\u001b[0m\n",
      "\u001b[34mTest Data 4 Accuracy: 0.5000\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [13/Mar/2021:04:36:49 +0000] \"POST /invocations HTTP/1.1\" 200 43 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m#015  0%|          | 0/1 [00:00<?, ?it/s]#015100%|██████████| 1/1 [00:00<00:00, 36.30it/s]\u001b[0m\n",
      "\u001b[35mTest Data 4 Accuracy: 0.5000\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [13/Mar/2021:04:36:49 +0000] \"POST /invocations HTTP/1.1\" 200 43 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "Transform results: \n",
      "Score_Class,Sentence-Score\n",
      "0,0\n",
      "2,1\n",
      "2,2\n",
      "2,3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformer.transform(data_location + '/Pick4-Refmt_Serialized-Sen-ELVA.PILOT.PRE-POST-TEST.csv', content_type='text/csv', split_type='Line')\n",
    "transformer.wait()\n",
    "\n",
    "s3_client = sess.boto_session.client('s3')\n",
    "s3_client.download_file(sess.default_bucket(), \"{}/Pick4-Refmt_Serialized-Sen-ELVA.PILOT.PRE-POST-TEST.csv.out\".format(transform_output_folder), '/tmp/Pick4-Refmt_Serialized-Sen-ELVA.PILOT.PRE-POST-TEST.csv.out')\n",
    "with open('/tmp/Pick4-Refmt_Serialized-Sen-ELVA.PILOT.PRE-POST-TEST.csv.out') as f:\n",
    "    results = f.readlines()   \n",
    "print(\"Transform results: \\n{}\".format(''.join(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
