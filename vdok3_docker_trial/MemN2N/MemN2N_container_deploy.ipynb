{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Sending build context to Docker daemon  40.45kB\n",
      "Step 1/16 : FROM continuumio/anaconda3:4.4.0\n",
      "4.4.0: Pulling from continuumio/anaconda3\n",
      "8ad8b3f87b37: Pulling fs layer\n",
      "fb691515f399: Pulling fs layer\n",
      "6c3051db0635: Pulling fs layer\n",
      "66faddd8f0d6: Pulling fs layer\n",
      "66faddd8f0d6: Waiting\n",
      "8ad8b3f87b37: Verifying Checksum\n",
      "8ad8b3f87b37: Download complete\n",
      "fb691515f399: Verifying Checksum\n",
      "fb691515f399: Download complete\n",
      "66faddd8f0d6: Verifying Checksum\n",
      "66faddd8f0d6: Download complete\n",
      "8ad8b3f87b37: Pull complete\n",
      "6c3051db0635: Verifying Checksum\n",
      "6c3051db0635: Download complete\n",
      "fb691515f399: Pull complete\n",
      "6c3051db0635: Pull complete\n",
      "66faddd8f0d6: Pull complete\n",
      "Digest: sha256:c6bb52bffe028b4b436b085afa4044db9b3d687a95468c92578467c9c2d4ac31\n",
      "Status: Downloaded newer image for continuumio/anaconda3:4.4.0\n",
      " ---> 795ad88c47ff\n",
      "Step 2/16 : RUN conda install -c anaconda setuptools\n",
      " ---> Running in 0f6b4fa3d1ff\n",
      "Fetching package metadata ...........\n",
      "Solving package specifications: .\n",
      "\n",
      "Package plan for installation in environment /opt/conda:\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    brotlipy:               0.7.0-py36h7b6447c_1000 anaconda\n",
      "    certifi:                2020.6.20-py36_0        anaconda\n",
      "    conda-package-handling: 1.6.1-py36h7b6447c_0    anaconda\n",
      "    libgcc-ng:              9.1.0-hdf63c60_0        anaconda\n",
      "    pysocks:                1.7.1-py36_0            anaconda\n",
      "    tqdm:                   4.49.0-py_0             anaconda\n",
      "    urllib3:                1.25.10-py_0            anaconda\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "    conda:                  4.3.21-py36_0                    --> 4.8.5-py36_0         anaconda\n",
      "    conda-env:              2.6.0-0                          --> 2.6.0-h36134e3_1     anaconda\n",
      "    pycosat:                0.6.2-py36_0                     --> 0.6.3-py36h7b6447c_0 anaconda\n",
      "    requests:               2.14.2-py36_0                    --> 2.24.0-py_0          anaconda\n",
      "    setuptools:             27.2.0-py36_0                    --> 49.6.0-py36_0        anaconda\n",
      "\n",
      "Proceed ([y]/n)? \n",
      "conda-env-2.6. 100% |###############################| Time: 0:00:00   2.97 MB/s\n",
      "libgcc-ng-9.1. 100% |###############################| Time: 0:00:00  62.60 MB/s\n",
      "certifi-2020.6 100% |###############################| Time: 0:00:00  57.53 MB/s\n",
      "pycosat-0.6.3- 100% |###############################| Time: 0:00:00  51.15 MB/s\n",
      "pysocks-1.7.1- 100% |###############################| Time: 0:00:00  37.20 MB/s\n",
      "tqdm-4.49.0-py 100% |###############################| Time: 0:00:00  41.49 MB/s\n",
      "conda-package- 100% |###############################| Time: 0:00:00  63.11 MB/s\n",
      "setuptools-49. 100% |###############################| Time: 0:00:00  63.48 MB/s\n",
      "brotlipy-0.7.0 100% |###############################| Time: 0:00:00  61.05 MB/s\n",
      "urllib3-1.25.1 100% |###############################| Time: 0:00:00  50.00 MB/s\n",
      "requests-2.24. 100% |###############################| Time: 0:00:00  40.08 MB/s\n",
      "conda-4.8.5-py 100% |###############################| Time: 0:00:00  63.69 MB/s\n",
      "Removing intermediate container 0f6b4fa3d1ff\n",
      " ---> 9363fa5ff149\n",
      "Step 3/16 : RUN apt-get -y update && apt-get install -y --no-install-recommends          libgl1-mesa-glx          wget          nginx          ca-certificates     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Running in 80324d71b02f\n",
      "Get:1 http://security.debian.org jessie/updates InRelease [44.9 kB]\n",
      "Ign http://httpredir.debian.org jessie InRelease\n",
      "Get:2 http://security.debian.org jessie/updates/main amd64 Packages [992 kB]\n",
      "Get:3 http://httpredir.debian.org jessie-updates InRelease [16.3 kB]\n",
      "Get:4 http://httpredir.debian.org jessie Release.gpg [1652 B]\n",
      "Get:5 http://httpredir.debian.org jessie-updates/main amd64 Packages [20 B]\n",
      "Get:6 http://httpredir.debian.org jessie Release [77.3 kB]\n",
      "Get:7 http://httpredir.debian.org jessie/main amd64 Packages [9098 kB]\n",
      "Fetched 10.2 MB in 2s (3603 kB/s)\n",
      "Reading package lists...\n",
      "\u001b[91mW: There is no public key available for the following key IDs:\n",
      "AA8E81B4331F7F50\n",
      "W: Size of file /var/lib/apt/lists/httpredir.debian.org_debian_dists_jessie-updates_main_binary-amd64_Packages.gz is not what the server reported 20 17567\n",
      "\u001b[0mReading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following extra packages will be installed:\n",
      "  fontconfig-config fonts-dejavu-core init-system-helpers libdrm2\n",
      "  libfontconfig1 libfreetype6 libgd3 libgeoip1 libglapi-mesa libjbig0\n",
      "  libjpeg62-turbo libpng12-0 libtiff5 libvpx1 libx11-xcb1 libxcb-dri2-0\n",
      "  libxcb-dri3-0 libxcb-glx0 libxcb-present0 libxcb-sync1 libxdamage1\n",
      "  libxfixes3 libxpm4 libxshmfence1 libxslt1.1 libxxf86vm1 nginx-common\n",
      "  nginx-full\n",
      "Suggested packages:\n",
      "  libgd-tools geoip-bin fcgiwrap nginx-doc ssl-cert\n",
      "Recommended packages:\n",
      "  geoip-database libgl1-mesa-dri\n",
      "The following NEW packages will be installed:\n",
      "  fontconfig-config fonts-dejavu-core init-system-helpers libdrm2\n",
      "  libfontconfig1 libfreetype6 libgd3 libgeoip1 libgl1-mesa-glx libglapi-mesa\n",
      "  libjbig0 libjpeg62-turbo libpng12-0 libtiff5 libvpx1 libx11-xcb1\n",
      "  libxcb-dri2-0 libxcb-dri3-0 libxcb-glx0 libxcb-present0 libxcb-sync1\n",
      "  libxdamage1 libxfixes3 libxpm4 libxshmfence1 libxslt1.1 libxxf86vm1 nginx\n",
      "  nginx-common nginx-full\n",
      "The following packages will be upgraded:\n",
      "  ca-certificates wget\n",
      "2 upgraded, 30 newly installed, 0 to remove and 94 not upgraded.\n",
      "Need to get 5637 kB of archives.\n",
      "After this operation, 13.1 MB of additional disk space will be used.\n",
      "Get:1 http://security.debian.org/ jessie/updates/main libfreetype6 amd64 2.5.2-3+deb8u4 [467 kB]\n",
      "Get:2 http://httpredir.debian.org/debian/ jessie/main libdrm2 amd64 2.4.58-2 [29.9 kB]\n",
      "Get:3 http://httpredir.debian.org/debian/ jessie/main libpng12-0 amd64 1.2.50-2+deb8u3 [173 kB]\n",
      "Get:4 http://security.debian.org/ jessie/updates/main libjpeg62-turbo amd64 1:1.3.1-12+deb8u2 [117 kB]\n",
      "Get:5 http://security.debian.org/ jessie/updates/main libtiff5 amd64 4.0.3-12.3+deb8u10 [223 kB]\n",
      "Get:6 http://httpredir.debian.org/debian/ jessie/main fonts-dejavu-core all 2.34-1 [1047 kB]\n",
      "Get:7 http://security.debian.org/ jessie/updates/main libvpx1 amd64 1.3.0-3+deb8u3 [600 kB]\n",
      "Get:8 http://security.debian.org/ jessie/updates/main libgd3 amd64 2.1.0-5+deb8u14 [148 kB]\n",
      "Get:9 http://security.debian.org/ jessie/updates/main libglapi-mesa amd64 10.3.2-1+deb8u2 [53.9 kB]\n",
      "Get:10 http://security.debian.org/ jessie/updates/main libx11-xcb1 amd64 2:1.6.2-3+deb8u2 [163 kB]\n",
      "Get:11 http://security.debian.org/ jessie/updates/main libgl1-mesa-glx amd64 10.3.2-1+deb8u2 [181 kB]\n",
      "Get:12 http://security.debian.org/ jessie/updates/main libxslt1.1 amd64 1.1.28-2+deb8u6 [233 kB]\n",
      "Get:13 http://security.debian.org/ jessie/updates/main wget amd64 1.16-1+deb8u7 [496 kB]\n",
      "Get:14 http://httpredir.debian.org/debian/ jessie/main fontconfig-config all 2.11.0-6.3+deb8u1 [274 kB]\n",
      "Get:15 http://security.debian.org/ jessie/updates/main ca-certificates all 20141019+deb8u4 [185 kB]\n",
      "Get:16 http://httpredir.debian.org/debian/ jessie/main libfontconfig1 amd64 2.11.0-6.3+deb8u1 [329 kB]\n",
      "Get:17 http://security.debian.org/ jessie/updates/main nginx-common all 1.6.2-5+deb8u6 [88.4 kB]\n",
      "Get:18 http://security.debian.org/ jessie/updates/main nginx-full amd64 1.6.2-5+deb8u6 [431 kB]\n",
      "Get:19 http://httpredir.debian.org/debian/ jessie/main libjbig0 amd64 2.1-3.1 [30.7 kB]\n",
      "Get:20 http://httpredir.debian.org/debian/ jessie/main libxpm4 amd64 1:3.5.12-0+deb8u1 [49.2 kB]\n",
      "Get:21 http://security.debian.org/ jessie/updates/main nginx all 1.6.2-5+deb8u6 [72.9 kB]\n",
      "Get:22 http://httpredir.debian.org/debian/ jessie/main libgeoip1 amd64 1.6.2-4 [90.8 kB]\n",
      "Get:23 http://httpredir.debian.org/debian/ jessie/main libxcb-dri2-0 amd64 1.10-3+b1 [12.9 kB]\n",
      "Get:24 http://httpredir.debian.org/debian/ jessie/main libxcb-dri3-0 amd64 1.10-3+b1 [11.1 kB]\n",
      "Get:25 http://httpredir.debian.org/debian/ jessie/main libxcb-glx0 amd64 1.10-3+b1 [27.4 kB]\n",
      "Get:26 http://httpredir.debian.org/debian/ jessie/main libxcb-present0 amd64 1.10-3+b1 [11.1 kB]\n",
      "Get:27 http://httpredir.debian.org/debian/ jessie/main libxcb-sync1 amd64 1.10-3+b1 [14.4 kB]\n",
      "Get:28 http://httpredir.debian.org/debian/ jessie/main libxfixes3 amd64 1:5.0.1-2+deb8u1 [21.1 kB]\n",
      "Get:29 http://httpredir.debian.org/debian/ jessie/main libxdamage1 amd64 1:1.1.4-2+b1 [14.7 kB]\n",
      "Get:30 http://httpredir.debian.org/debian/ jessie/main libxshmfence1 amd64 1.1-4 [6736 B]\n",
      "Get:31 http://httpredir.debian.org/debian/ jessie/main libxxf86vm1 amd64 1:1.1.3-1+b1 [19.6 kB]\n",
      "Get:32 http://httpredir.debian.org/debian/ jessie/main init-system-helpers all 1.22 [14.0 kB]\n",
      "\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n",
      "\u001b[0mFetched 5637 kB in 0s (24.0 MB/s)\n",
      "Selecting previously unselected package libdrm2:amd64.\n",
      "(Reading database ... 13124 files and directories currently installed.)\n",
      "Preparing to unpack .../libdrm2_2.4.58-2_amd64.deb ...\n",
      "Unpacking libdrm2:amd64 (2.4.58-2) ...\n",
      "Selecting previously unselected package libpng12-0:amd64.\n",
      "Preparing to unpack .../libpng12-0_1.2.50-2+deb8u3_amd64.deb ...\n",
      "Unpacking libpng12-0:amd64 (1.2.50-2+deb8u3) ...\n",
      "Selecting previously unselected package libfreetype6:amd64.\n",
      "Preparing to unpack .../libfreetype6_2.5.2-3+deb8u4_amd64.deb ...\n",
      "Unpacking libfreetype6:amd64 (2.5.2-3+deb8u4) ...\n",
      "Selecting previously unselected package fonts-dejavu-core.\n",
      "Preparing to unpack .../fonts-dejavu-core_2.34-1_all.deb ...\n",
      "Unpacking fonts-dejavu-core (2.34-1) ...\n",
      "Selecting previously unselected package fontconfig-config.\n",
      "Preparing to unpack .../fontconfig-config_2.11.0-6.3+deb8u1_all.deb ...\n",
      "Unpacking fontconfig-config (2.11.0-6.3+deb8u1) ...\n",
      "Selecting previously unselected package libfontconfig1:amd64.\n",
      "Preparing to unpack .../libfontconfig1_2.11.0-6.3+deb8u1_amd64.deb ...\n",
      "Unpacking libfontconfig1:amd64 (2.11.0-6.3+deb8u1) ...\n",
      "Selecting previously unselected package libjpeg62-turbo:amd64.\n",
      "Preparing to unpack .../libjpeg62-turbo_1%3a1.3.1-12+deb8u2_amd64.deb ...\n",
      "Unpacking libjpeg62-turbo:amd64 (1:1.3.1-12+deb8u2) ...\n",
      "Selecting previously unselected package libjbig0:amd64.\n",
      "Preparing to unpack .../libjbig0_2.1-3.1_amd64.deb ...\n",
      "Unpacking libjbig0:amd64 (2.1-3.1) ...\n",
      "Selecting previously unselected package libtiff5:amd64.\n",
      "Preparing to unpack .../libtiff5_4.0.3-12.3+deb8u10_amd64.deb ...\n",
      "Unpacking libtiff5:amd64 (4.0.3-12.3+deb8u10) ...\n",
      "Selecting previously unselected package libvpx1:amd64.\n",
      "Preparing to unpack .../libvpx1_1.3.0-3+deb8u3_amd64.deb ...\n",
      "Unpacking libvpx1:amd64 (1.3.0-3+deb8u3) ...\n",
      "Selecting previously unselected package libxpm4:amd64.\n",
      "Preparing to unpack .../libxpm4_1%3a3.5.12-0+deb8u1_amd64.deb ...\n",
      "Unpacking libxpm4:amd64 (1:3.5.12-0+deb8u1) ...\n",
      "Selecting previously unselected package libgd3:amd64.\n",
      "Preparing to unpack .../libgd3_2.1.0-5+deb8u14_amd64.deb ...\n",
      "Unpacking libgd3:amd64 (2.1.0-5+deb8u14) ...\n",
      "Selecting previously unselected package libgeoip1:amd64.\n",
      "Preparing to unpack .../libgeoip1_1.6.2-4_amd64.deb ...\n",
      "Unpacking libgeoip1:amd64 (1.6.2-4) ...\n",
      "Selecting previously unselected package libglapi-mesa:amd64.\n",
      "Preparing to unpack .../libglapi-mesa_10.3.2-1+deb8u2_amd64.deb ...\n",
      "Unpacking libglapi-mesa:amd64 (10.3.2-1+deb8u2) ...\n",
      "Selecting previously unselected package libx11-xcb1:amd64.\n",
      "Preparing to unpack .../libx11-xcb1_2%3a1.6.2-3+deb8u2_amd64.deb ...\n",
      "Unpacking libx11-xcb1:amd64 (2:1.6.2-3+deb8u2) ...\n",
      "Selecting previously unselected package libxcb-dri2-0:amd64.\n",
      "Preparing to unpack .../libxcb-dri2-0_1.10-3+b1_amd64.deb ...\n",
      "Unpacking libxcb-dri2-0:amd64 (1.10-3+b1) ...\n",
      "Selecting previously unselected package libxcb-dri3-0:amd64.\n",
      "Preparing to unpack .../libxcb-dri3-0_1.10-3+b1_amd64.deb ...\n",
      "Unpacking libxcb-dri3-0:amd64 (1.10-3+b1) ...\n",
      "Selecting previously unselected package libxcb-glx0:amd64.\n",
      "Preparing to unpack .../libxcb-glx0_1.10-3+b1_amd64.deb ...\n",
      "Unpacking libxcb-glx0:amd64 (1.10-3+b1) ...\n",
      "Selecting previously unselected package libxcb-present0:amd64.\n",
      "Preparing to unpack .../libxcb-present0_1.10-3+b1_amd64.deb ...\n",
      "Unpacking libxcb-present0:amd64 (1.10-3+b1) ...\n",
      "Selecting previously unselected package libxcb-sync1:amd64.\n",
      "Preparing to unpack .../libxcb-sync1_1.10-3+b1_amd64.deb ...\n",
      "Unpacking libxcb-sync1:amd64 (1.10-3+b1) ...\n",
      "Selecting previously unselected package libxfixes3:amd64.\n",
      "Preparing to unpack .../libxfixes3_1%3a5.0.1-2+deb8u1_amd64.deb ...\n",
      "Unpacking libxfixes3:amd64 (1:5.0.1-2+deb8u1) ...\n",
      "Selecting previously unselected package libxdamage1:amd64.\n",
      "Preparing to unpack .../libxdamage1_1%3a1.1.4-2+b1_amd64.deb ...\n",
      "Unpacking libxdamage1:amd64 (1:1.1.4-2+b1) ...\n",
      "Selecting previously unselected package libxshmfence1:amd64.\n",
      "Preparing to unpack .../libxshmfence1_1.1-4_amd64.deb ...\n",
      "Unpacking libxshmfence1:amd64 (1.1-4) ...\n",
      "Selecting previously unselected package libxxf86vm1:amd64.\n",
      "Preparing to unpack .../libxxf86vm1_1%3a1.1.3-1+b1_amd64.deb ...\n",
      "Unpacking libxxf86vm1:amd64 (1:1.1.3-1+b1) ...\n",
      "Selecting previously unselected package libgl1-mesa-glx:amd64.\n",
      "Preparing to unpack .../libgl1-mesa-glx_10.3.2-1+deb8u2_amd64.deb ...\n",
      "Unpacking libgl1-mesa-glx:amd64 (10.3.2-1+deb8u2) ...\n",
      "Selecting previously unselected package libxslt1.1:amd64.\n",
      "Preparing to unpack .../libxslt1.1_1.1.28-2+deb8u6_amd64.deb ...\n",
      "Unpacking libxslt1.1:amd64 (1.1.28-2+deb8u6) ...\n",
      "Selecting previously unselected package init-system-helpers.\n",
      "Preparing to unpack .../init-system-helpers_1.22_all.deb ...\n",
      "Unpacking init-system-helpers (1.22) ...\n",
      "Preparing to unpack .../wget_1.16-1+deb8u7_amd64.deb ...\n",
      "Unpacking wget (1.16-1+deb8u7) over (1.16-1+deb8u2) ...\n",
      "Preparing to unpack .../ca-certificates_20141019+deb8u4_all.deb ...\n",
      "Unpacking ca-certificates (20141019+deb8u4) over (20141019+deb8u3) ...\n",
      "Selecting previously unselected package nginx-common.\n",
      "Preparing to unpack .../nginx-common_1.6.2-5+deb8u6_all.deb ...\n",
      "Unpacking nginx-common (1.6.2-5+deb8u6) ...\n",
      "Selecting previously unselected package nginx-full.\n",
      "Preparing to unpack .../nginx-full_1.6.2-5+deb8u6_amd64.deb ...\n",
      "Unpacking nginx-full (1.6.2-5+deb8u6) ...\n",
      "Selecting previously unselected package nginx.\n",
      "Preparing to unpack .../nginx_1.6.2-5+deb8u6_all.deb ...\n",
      "Unpacking nginx (1.6.2-5+deb8u6) ...\n",
      "Processing triggers for systemd (215-17+deb8u4) ...\n",
      "Setting up libdrm2:amd64 (2.4.58-2) ...\n",
      "Setting up libpng12-0:amd64 (1.2.50-2+deb8u3) ...\n",
      "Setting up libfreetype6:amd64 (2.5.2-3+deb8u4) ...\n",
      "Setting up fonts-dejavu-core (2.34-1) ...\n",
      "Setting up fontconfig-config (2.11.0-6.3+deb8u1) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\n",
      "debconf: falling back to frontend: Readline\n",
      "Setting up libfontconfig1:amd64 (2.11.0-6.3+deb8u1) ...\n",
      "Setting up libjpeg62-turbo:amd64 (1:1.3.1-12+deb8u2) ...\n",
      "Setting up libjbig0:amd64 (2.1-3.1) ...\n",
      "Setting up libtiff5:amd64 (4.0.3-12.3+deb8u10) ...\n",
      "Setting up libvpx1:amd64 (1.3.0-3+deb8u3) ...\n",
      "Setting up libxpm4:amd64 (1:3.5.12-0+deb8u1) ...\n",
      "Setting up libgd3:amd64 (2.1.0-5+deb8u14) ...\n",
      "Setting up libgeoip1:amd64 (1.6.2-4) ...\n",
      "Setting up libglapi-mesa:amd64 (10.3.2-1+deb8u2) ...\n",
      "Setting up libx11-xcb1:amd64 (2:1.6.2-3+deb8u2) ...\n",
      "Setting up libxcb-dri2-0:amd64 (1.10-3+b1) ...\n",
      "Setting up libxcb-dri3-0:amd64 (1.10-3+b1) ...\n",
      "Setting up libxcb-glx0:amd64 (1.10-3+b1) ...\n",
      "Setting up libxcb-present0:amd64 (1.10-3+b1) ...\n",
      "Setting up libxcb-sync1:amd64 (1.10-3+b1) ...\n",
      "Setting up libxfixes3:amd64 (1:5.0.1-2+deb8u1) ...\n",
      "Setting up libxdamage1:amd64 (1:1.1.4-2+b1) ...\n",
      "Setting up libxshmfence1:amd64 (1.1-4) ...\n",
      "Setting up libxxf86vm1:amd64 (1:1.1.3-1+b1) ...\n",
      "Setting up libgl1-mesa-glx:amd64 (10.3.2-1+deb8u2) ...\n",
      "Setting up libxslt1.1:amd64 (1.1.28-2+deb8u6) ...\n",
      "Setting up init-system-helpers (1.22) ...\n",
      "Setting up wget (1.16-1+deb8u7) ...\n",
      "Setting up ca-certificates (20141019+deb8u4) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\n",
      "debconf: falling back to frontend: Readline\n",
      "Updating certificates in /etc/ssl/certs... 20 added, 42 removed; done.\n",
      "Setting up nginx-common (1.6.2-5+deb8u6) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\n",
      "debconf: falling back to frontend: Readline\n",
      "Setting up nginx-full (1.6.2-5+deb8u6) ...\n",
      "invoke-rc.d: policy-rc.d denied execution of start.\n",
      "Setting up nginx (1.6.2-5+deb8u6) ...\n",
      "Processing triggers for libc-bin (2.19-18+deb8u4) ...\n",
      "Processing triggers for ca-certificates (20141019+deb8u4) ...\n",
      "Updating certificates in /etc/ssl/certs... 0 added, 0 removed; done.\n",
      "Running hooks in /etc/ca-certificates/update.d....done.\n",
      "Processing triggers for systemd (215-17+deb8u4) ...\n",
      "Removing intermediate container 80324d71b02f\n",
      " ---> 4e4df7c3a352\n",
      "Step 4/16 : RUN pip install --upgrade pip &&     pip install janome==0.3.10 &&     pip install tensorflow==1.14.0 --user &&     pip install ml_metrics==0.1.4 &&     pip install --upgrade scipy==1.1.0 &&     pip uninstall --yes numpy &&     pip install numpy==1.16.4 &&     pip uninstall --yes gast &&     pip install gast==0.2.2 &&     pip install flask &&     pip install -U gevent==1.4.0 --ignore-installed &&     pip install gunicorn\n",
      " ---> Running in 5ea67a3c4317\n",
      "Collecting pip\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/5f/528232275f6509b1fff703c9280e58951a81abe24640905de621c9f81839/pip-20.2.3-py2.py3-none-any.whl (1.5MB)\n",
      "Installing collected packages: pip\n",
      "  Found existing installation: pip 9.0.1\n",
      "    Uninstalling pip-9.0.1:\n",
      "      Successfully uninstalled pip-9.0.1\n",
      "Successfully installed pip-20.2.3\n",
      "Collecting janome==0.3.10\n",
      "  Downloading Janome-0.3.10-py2.py3-none-any.whl (21.5 MB)\n",
      "Installing collected packages: janome\n",
      "Successfully installed janome-0.3.10\n",
      "Collecting tensorflow==1.14.0\n",
      "  Downloading tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2 MB)\n",
      "Collecting tensorboard<1.15.0,>=1.14.0\n",
      "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting keras-applications>=1.0.6\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "Collecting google-pasta>=0.1.6\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.32.0-cp36-cp36m-manylinux2014_x86_64.whl (3.8 MB)\n",
      "Collecting astor>=0.6.0\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting gast>=0.2.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting numpy<2.0,>=1.14.5\n",
      "  Downloading numpy-1.19.2-cp36-cp36m-manylinux2010_x86_64.whl (14.5 MB)\n",
      "Collecting absl-py>=0.7.0\n",
      "  Downloading absl_py-0.10.0-py3-none-any.whl (127 kB)\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
      "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
      "Collecting wrapt>=1.11.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow==1.14.0) (1.10.0)\n",
      "Collecting protobuf>=3.6.1\n",
      "  Downloading protobuf-3.13.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting keras-preprocessing>=1.0.5\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorflow==1.14.0) (0.29.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.2.2-py3-none-any.whl (88 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (0.12.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (49.6.0.post20200814)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.7.0)\n",
      "Collecting importlib-metadata; python_version < \"3.8\"\n",
      "  Downloading importlib_metadata-2.0.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.2.0-py3-none-any.whl (5.1 kB)\n",
      "Building wheels for collected packages: termcolor, wrapt\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=5680 sha256=a9d27c589fe931202feb52c12c98fac747d0822ff16471432d112ac9e3e75817\n",
      "  Stored in directory: /root/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-py3-none-any.whl size=21397 sha256=b53e5845946ae267c1fab88d981cf76686b345950ee4cd3a85848083d8d7b3d1\n",
      "  Stored in directory: /root/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\n",
      "Successfully built termcolor wrapt\n",
      "Installing collected packages: zipp, importlib-metadata, markdown, numpy, grpcio, protobuf, absl-py, tensorboard, termcolor, keras-applications, google-pasta, astor, gast, tensorflow-estimator, wrapt, keras-preprocessing, tensorflow\n",
      "\u001b[91m  WARNING: The script markdown_py is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\u001b[0m\u001b[91m  WARNING: The scripts f2py, f2py3 and f2py3.6 are installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\u001b[0m\u001b[91m  WARNING: The script tensorboard is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\u001b[0m\u001b[91m  WARNING: The scripts freeze_graph, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\u001b[0mSuccessfully installed absl-py-0.10.0 astor-0.8.1 gast-0.4.0 google-pasta-0.2.0 grpcio-1.32.0 importlib-metadata-2.0.0 keras-applications-1.0.8 keras-preprocessing-1.1.2 markdown-3.2.2 numpy-1.19.2 protobuf-3.13.0 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0 termcolor-1.1.0 wrapt-1.12.1 zipp-3.2.0\n",
      "Collecting ml_metrics==0.1.4\n",
      "  Downloading ml_metrics-0.1.4.tar.gz (5.0 kB)\n",
      "Requirement already satisfied: numpy in /root/.local/lib/python3.6/site-packages (from ml_metrics==0.1.4) (1.19.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from ml_metrics==0.1.4) (0.20.1)\n",
      "Requirement already satisfied: python-dateutil>=2 in /opt/conda/lib/python3.6/site-packages (from pandas->ml_metrics==0.1.4) (2.6.0)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.6/site-packages (from pandas->ml_metrics==0.1.4) (2017.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2->pandas->ml_metrics==0.1.4) (1.10.0)\n",
      "Building wheels for collected packages: ml-metrics\n",
      "  Building wheel for ml-metrics (setup.py): started\n",
      "  Building wheel for ml-metrics (setup.py): finished with status 'done'\n",
      "  Created wheel for ml-metrics: filename=ml_metrics-0.1.4-py3-none-any.whl size=8543 sha256=774ed9dd69f1277dc827931abbd8389ac795f5ac7fca05da3da08f8721eb07ee\n",
      "  Stored in directory: /root/.cache/pip/wheels/18/ae/7a/7b60c579f0de920aa060c609cc17472ea20c7cfe657ee8cf5c\n",
      "Successfully built ml-metrics\n",
      "Installing collected packages: ml-metrics\n",
      "Successfully installed ml-metrics-0.1.4\n",
      "Collecting scipy==1.1.0\n",
      "  Downloading scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2 MB)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.8.2 in /root/.local/lib/python3.6/site-packages (from scipy==1.1.0) (1.19.2)\n",
      "Installing collected packages: scipy\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 0.19.0\n",
      "    Uninstalling scipy-0.19.0:\n",
      "      Successfully uninstalled scipy-0.19.0\n",
      "Successfully installed scipy-1.1.0\n",
      "Found existing installation: numpy 1.19.2\n",
      "Uninstalling numpy-1.19.2:\n",
      "  Successfully uninstalled numpy-1.19.2\n",
      "Collecting numpy==1.16.4\n",
      "  Downloading numpy-1.16.4-cp36-cp36m-manylinux1_x86_64.whl (17.3 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.12.1\n",
      "    Uninstalling numpy-1.12.1:\n",
      "      Successfully uninstalled numpy-1.12.1\n",
      "Successfully installed numpy-1.16.4\n",
      "Found existing installation: gast 0.4.0\n",
      "Uninstalling gast-0.4.0:\n",
      "  Successfully uninstalled gast-0.4.0\n",
      "Collecting gast==0.2.2\n",
      "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
      "Building wheels for collected packages: gast\n",
      "  Building wheel for gast (setup.py): started\n",
      "  Building wheel for gast (setup.py): finished with status 'done'\n",
      "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7636 sha256=eb07e9b278f233103e1fd1b8ebd84837120e212741341f93e4b09ff2ec39413d\n",
      "  Stored in directory: /root/.cache/pip/wheels/19/a7/b9/0740c7a3a7d1d348f04823339274b90de25fbcd217b2ee1fbe\n",
      "Successfully built gast\n",
      "Installing collected packages: gast\n",
      "Successfully installed gast-0.2.2\n",
      "Requirement already satisfied: flask in /opt/conda/lib/python3.6/site-packages (0.12.2)\n",
      "Requirement already satisfied: Werkzeug>=0.7 in /opt/conda/lib/python3.6/site-packages (from flask) (0.12.2)\n",
      "Requirement already satisfied: Jinja2>=2.4 in /opt/conda/lib/python3.6/site-packages (from flask) (2.9.6)\n",
      "Requirement already satisfied: itsdangerous>=0.21 in /opt/conda/lib/python3.6/site-packages (from flask) (0.24)\n",
      "Requirement already satisfied: click>=2.0 in /opt/conda/lib/python3.6/site-packages (from flask) (6.7)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.6/site-packages (from Jinja2>=2.4->flask) (0.23)\n",
      "Collecting gevent==1.4.0\n",
      "  Downloading gevent-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (5.5 MB)\n",
      "Collecting greenlet>=0.4.14; platform_python_implementation == \"CPython\"\n",
      "  Downloading greenlet-0.4.17-cp36-cp36m-manylinux1_x86_64.whl (44 kB)\n",
      "Installing collected packages: greenlet, gevent\n",
      "Successfully installed gevent-1.4.0 greenlet-0.4.17\n",
      "Collecting gunicorn\n",
      "  Downloading gunicorn-20.0.4-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: setuptools>=3.0 in /opt/conda/lib/python3.6/site-packages (from gunicorn) (49.6.0.post20200814)\n",
      "Installing collected packages: gunicorn\n",
      "Successfully installed gunicorn-20.0.4\n",
      "Removing intermediate container 5ea67a3c4317\n",
      " ---> ed9c54f160d3\n",
      "Step 5/16 : RUN python -m nltk.downloader book\n",
      " ---> Running in 03f08f847db1\n",
      "[nltk_data] Downloading collection 'book'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
      "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
      "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
      "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
      "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
      "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
      "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
      "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
      "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
      "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
      "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/names.zip.\n",
      "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
      "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
      "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
      "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
      "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
      "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
      "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
      "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
      "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
      "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
      "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
      "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
      "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/words.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
      "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
      "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /root/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection book\n",
      "\u001b[91m/opt/conda/lib/python3.6/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "\u001b[0mRemoving intermediate container 03f08f847db1\n",
      " ---> 6f504b260a4d\n",
      "Step 6/16 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Running in 4cb8199982b6\n",
      "Removing intermediate container 4cb8199982b6\n",
      " ---> a1e0cc927a8a\n",
      "Step 7/16 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Running in ae659d8eaa45\n",
      "Removing intermediate container ae659d8eaa45\n",
      " ---> 1d9dc43d6705\n",
      "Step 8/16 : ENV PATH=\"/opt/program:${PATH}\"\n",
      " ---> Running in f76a737d7348\n",
      "Removing intermediate container f76a737d7348\n",
      " ---> 0d6fcc801d16\n",
      "Step 9/16 : WORKDIR /opt/program\n",
      " ---> Running in dc9c8577ee89\n",
      "Removing intermediate container dc9c8577ee89\n",
      " ---> f407d6c8afa3\n",
      "Step 10/16 : RUN git clone https://github.com/mack-the-psych/plimac3.git\n",
      " ---> Running in c2f94f1824b8\n",
      "\u001b[91mCloning into 'plimac3'...\n",
      "\u001b[0mRemoving intermediate container c2f94f1824b8\n",
      " ---> 5d34b97c0b55\n",
      "Step 11/16 : RUN git clone https://github.com/mack-the-psych/vdok3.git\n",
      " ---> Running in e0876b6907d3\n",
      "\u001b[91mCloning into 'vdok3'...\n",
      "\u001b[0mRemoving intermediate container e0876b6907d3\n",
      " ---> cdb80565574d\n",
      "Step 12/16 : RUN echo \"/opt/program/plimac3/Lib\" > /opt/conda/lib/python3.6/site-packages/plimac-custom.pth\n",
      " ---> Running in 96e060bc8f14\n",
      "Removing intermediate container 96e060bc8f14\n",
      " ---> 7896b7cd4637\n",
      "Step 13/16 : RUN echo \"/opt/program/plimac3/Tools\" >> /opt/conda/lib/python3.6/site-packages/plimac-custom.pth\n",
      " ---> Running in 1838d52f2e52\n",
      "Removing intermediate container 1838d52f2e52\n",
      " ---> ec8e08f73c4d\n",
      "Step 14/16 : RUN echo \"/opt/program/vdok3/train\" >> /opt/conda/lib/python3.6/site-packages/plimac-custom.pth\n",
      " ---> Running in f7f53e8e81c4\n",
      "Removing intermediate container f7f53e8e81c4\n",
      " ---> 39e65d8a9d2d\n",
      "Step 15/16 : COPY vdok3_sage /opt/program\n",
      " ---> 97bec847aaf2\n",
      "Step 16/16 : WORKDIR /opt/program\n",
      " ---> Running in f01c47c0365b\n",
      "Removing intermediate container f01c47c0365b\n",
      " ---> 7e82155453ca\n",
      "Successfully built 7e82155453ca\n",
      "Successfully tagged sagemaker-vdok3-memn2n:latest\n",
      "The push refers to repository [208274468343.dkr.ecr.ap-northeast-1.amazonaws.com/sagemaker-vdok3-memn2n]\n",
      "11cbcc327595: Preparing\n",
      "c420c864565d: Preparing\n",
      "869f20f5e100: Preparing\n",
      "b6e9f04aa1d7: Preparing\n",
      "eacfc36a1e1b: Preparing\n",
      "14ee4e0f4871: Preparing\n",
      "9c05f80e206e: Preparing\n",
      "ff4e2a3ffaa8: Preparing\n",
      "6712de67a939: Preparing\n",
      "e6192cc6453b: Preparing\n",
      "00db33c760cf: Preparing\n",
      "ca173dc10e31: Preparing\n",
      "54e10c08a841: Preparing\n",
      "1f09b1beaa90: Preparing\n",
      "9e63c5bce458: Preparing\n",
      "6712de67a939: Waiting\n",
      "e6192cc6453b: Waiting\n",
      "00db33c760cf: Waiting\n",
      "ca173dc10e31: Waiting\n",
      "54e10c08a841: Waiting\n",
      "1f09b1beaa90: Waiting\n",
      "9e63c5bce458: Waiting\n",
      "14ee4e0f4871: Waiting\n",
      "9c05f80e206e: Waiting\n",
      "ff4e2a3ffaa8: Waiting\n",
      "11cbcc327595: Pushed\n",
      "c420c864565d: Pushed\n",
      "869f20f5e100: Pushed\n",
      "b6e9f04aa1d7: Pushed\n",
      "9c05f80e206e: Pushed\n",
      "eacfc36a1e1b: Pushed\n",
      "14ee4e0f4871: Pushed\n",
      "e6192cc6453b: Pushed\n",
      "ca173dc10e31: Pushed\n",
      "00db33c760cf: Pushed\n",
      "9e63c5bce458: Pushed\n",
      "1f09b1beaa90: Pushed\n",
      "ff4e2a3ffaa8: Pushed\n",
      "6712de67a939: Pushed\n",
      "54e10c08a841: Pushed\n",
      "latest: digest: sha256:6e7f15f9ba48c272c7dbc9414b139cc811a732f0fb169dafb3306e45b3b6eddd size: 3473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.7 ms, sys: 9.21 ms, total: 49.9 ms\n",
      "Wall time: 8min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "# Makoto.Sano@Mack-the-Psych.com\n",
    "algorithm_name=sagemaker-vdok3-memn2n\n",
    "\n",
    "cd container\n",
    "\n",
    "chmod +x vdok3_sage/train\n",
    "chmod +x vdok3_sage/serve\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build  -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "# Makoto.Sano@Mack-the-Psych.com\n",
    "prefix = 'vdok3_memn2n_trial'\n",
    "\n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sess = sage.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIRECTORY = 'data'\n",
    "\n",
    "data_location = sess.upload_data(WORK_DIRECTORY, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-27 08:11:51 Starting - Starting the training job...\n",
      "2020-09-27 08:11:53 Starting - Launching requested ML instances.........\n",
      "2020-09-27 08:13:24 Starting - Preparing the instances for training...\n",
      "2020-09-27 08:14:06 Downloading - Downloading input data\n",
      "2020-09-27 08:14:06 Training - Downloading the training image.........\n",
      "2020-09-27 08:15:35 Training - Training image download completed. Training in progress.\u001b[34m/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/vdok3/train/tf_memn_classify.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\u001b[0m\n",
      "\u001b[34mStarting the training.\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/vdok3/train/tf_memn_classify.py:208: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/vdok3/train/tf_memn_classify.py:209: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:\u001b[0m\n",
      "\u001b[34mThe TensorFlow contrib module will not be included in TensorFlow 2.0.\u001b[0m\n",
      "\u001b[34mFor more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\u001b[0m\n",
      "\u001b[34mIf you depend on functionality not listed there, please file an issue.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/vdok3/train/tf_memn_classify.py:149: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mThis class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/vdok3/train/tf_memn_classify.py:156: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/vdok3/train/tf_memn_classify.py:156: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCall initializer instance with the dtype argument instead of passing it to the constructor\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:738: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCall initializer instance with the dtype argument instead of passing it to the constructor\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/vdok3/train/tf_memn_classify.py:221: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/vdok3/train/tf_memn_classify.py:182: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34mTraining model...\u001b[0m\n",
      "\u001b[34m2020-09-27 08:15:46.376852: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[34m2020-09-27 08:15:46.409907: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900080000 Hz\u001b[0m\n",
      "\u001b[34m2020-09-27 08:15:46.410379: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5c8d6f0 executing computations on platform Host. Devices:\u001b[0m\n",
      "\u001b[34m2020-09-27 08:15:46.410404: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/vdok3/train/tf_memn_classify.py:236: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/vdok3/train/tf_memn_classify.py:237: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/vdok3/train/tf_memn_classify.py:238: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2020-09-27 08:15:46.892320: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\u001b[0m\n",
      "\u001b[34mepoch: 0  validation loss: 0.48683167  validation accuracy: 0.86399615\u001b[0m\n",
      "\u001b[34mepoch: 1  validation loss: 0.44033453  validation accuracy: 0.86399615\u001b[0m\n",
      "\u001b[34mepoch: 2  validation loss: 0.34137717  validation accuracy: 0.86399615\u001b[0m\n",
      "\u001b[34mepoch: 3  validation loss: 0.25091216  validation accuracy: 0.8699928\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse standard file APIs to delete files with this prefix.\u001b[0m\n",
      "\u001b[34mepoch: 4  validation loss: 0.21947068  validation accuracy: 0.9006956\u001b[0m\n",
      "\u001b[34mepoch: 5  validation loss: 0.19664462  validation accuracy: 0.9138882\u001b[0m\n",
      "\u001b[34mepoch: 6  validation loss: 0.17673685  validation accuracy: 0.9208443\u001b[0m\n",
      "\u001b[34mepoch: 7  validation loss: 0.15748489  validation accuracy: 0.93115854\u001b[0m\n",
      "\u001b[34mepoch: 8  validation loss: 0.1422456  validation accuracy: 0.9364356\u001b[0m\n",
      "\u001b[34mepoch: 9  validation loss: 0.12923867  validation accuracy: 0.9397937\u001b[0m\n",
      "\u001b[34mepoch: 10  validation loss: 0.11842429  validation accuracy: 0.9421924\u001b[0m\n",
      "\u001b[34mepoch: 11  validation loss: 0.109752916  validation accuracy: 0.94507074\u001b[0m\n",
      "\u001b[34mepoch: 12  validation loss: 0.10142533  validation accuracy: 0.95082754\u001b[0m\n",
      "\u001b[34mepoch: 13  validation loss: 0.091140784  validation accuracy: 0.9594627\u001b[0m\n",
      "\u001b[34mepoch: 14  validation loss: 0.08019078  validation accuracy: 0.967858\u001b[0m\n",
      "\u001b[34mepoch: 15  validation loss: 0.07115809  validation accuracy: 0.9728952\u001b[0m\n",
      "\u001b[34mepoch: 16  validation loss: 0.0686429  validation accuracy: 0.97505397\u001b[0m\n",
      "\u001b[34mepoch: 17  validation loss: 0.061861664  validation accuracy: 0.97505397\u001b[0m\n",
      "\u001b[34mepoch: 18  validation loss: 0.05091295  validation accuracy: 0.9824898\u001b[0m\n",
      "\u001b[34mepoch: 19  validation loss: 0.04550396  validation accuracy: 0.9846486\u001b[0m\n",
      "\u001b[34mRecall                      0.9846\u001b[0m\n",
      "\u001b[34mPrecision                   0.9847\u001b[0m\n",
      "\u001b[34mF1                          0.9846\u001b[0m\n",
      "\u001b[34mKappa                       0.9370\u001b[0m\n",
      "\u001b[34mQuadratic Weighted Kappa    0.9629\u001b[0m\n",
      "\u001b[34mdtype: float64\u001b[0m\n",
      "\u001b[34mConfusion Matrix:\n",
      "      0    1    2\u001b[0m\n",
      "\u001b[34m0  3595    6    1\u001b[0m\n",
      "\u001b[34m1     2  339   21\u001b[0m\n",
      "\u001b[34m2     3   31  171\u001b[0m\n",
      "\u001b[34mModel saved to:  /opt/ml/model/vdok3_memn2n.ckpt\u001b[0m\n",
      "\u001b[34mTraining complete.\u001b[0m\n",
      "\n",
      "2020-09-27 08:16:37 Uploading - Uploading generated training model\n",
      "2020-09-27 08:16:37 Completed - Training job completed\n",
      "Training seconds: 157\n",
      "Billable seconds: 157\n"
     ]
    }
   ],
   "source": [
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "\n",
    "# Makoto.Sano@Mack-the-Psych.com\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/sagemaker-vdok3-memn2n:latest'.format(account, region)\n",
    "vdok3memn2n = sage.estimator.Estimator(image,\n",
    "                       role, 1, 'ml.c4.2xlarge',\n",
    "                       output_path=\"s3://{}/output\".format(sess.default_bucket()),\n",
    "                       sagemaker_session=sess)\n",
    "vdok3memn2n.fit(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "predictor = vdok3memn2n.deploy(1, 'ml.m4.xlarge', serializer=csv_serializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score_Class\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_in = pd.read_csv('data/Head4-Serialized-Def-ELVA.PILOT.POST-TEST.csv')\n",
    "np_in = np.vstack((np.array(df_in.columns), df_in.to_numpy()))\n",
    "print(predictor.predict(np_in).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "Using already existing model: sagemaker-vdok3-memn2n-2020-09-27-08-11-50-836\n"
     ]
    }
   ],
   "source": [
    "transform_output_folder = \"batch-transform-output\"\n",
    "output_path=\"s3://{}/{}\".format(sess.default_bucket(), transform_output_folder)\n",
    "\n",
    "transformer = vdok3memn2n.transformer(instance_count=1,\n",
    "                               instance_type='ml.m4.xlarge',\n",
    "                               output_path=output_path,\n",
    "                               assemble_with='Line',\n",
    "                               accept='text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................\u001b[34mStarting the inference server with 4 workers.\u001b[0m\n",
      "\u001b[34m2020/09/27 08:31:18 [crit] 12#0: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [27/Sep/2020:08:31:18 +0000] \"GET /ping HTTP/1.1\" 502 172 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/27 08:31:18 [crit] 12#0: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [27/Sep/2020:08:31:18 +0000] \"GET /ping HTTP/1.1\" 502 172 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/27 08:31:18 [crit] 12#0: *5 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [27/Sep/2020:08:31:18 +0000] \"GET /ping HTTP/1.1\" 502 172 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2020-09-27 08:31:18 +0000] [11] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2020-09-27 08:31:18 +0000] [11] [INFO] Listening at: unix:/tmp/gunicorn.sock (11)\u001b[0m\n",
      "\u001b[34m[2020-09-27 08:31:18 +0000] [11] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-09-27 08:31:18 +0000] [15] [INFO] Booting worker with pid: 15\u001b[0m\n",
      "\u001b[34m[2020-09-27 08:31:18 +0000] [16] [INFO] Booting worker with pid: 16\u001b[0m\n",
      "\u001b[34m[2020-09-27 08:31:18 +0000] [17] [INFO] Booting worker with pid: 17\u001b[0m\n",
      "\u001b[34m[2020-09-27 08:31:18 +0000] [18] [INFO] Booting worker with pid: 18\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/vdok3/train/tf_memn_classify.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/vdok3/train/tf_memn_classify.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/vdok3/train/tf_memn_classify.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/vdok3/train/tf_memn_classify.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/vdok3/train/tf_memn_classify.py:373: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/vdok3/train/tf_memn_classify.py:374: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:\u001b[0m\n",
      "\u001b[34mThe TensorFlow contrib module will not be included in TensorFlow 2.0.\u001b[0m\n",
      "\u001b[34mFor more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\u001b[0m\n",
      "\u001b[34mIf you depend on functionality not listed there, please file an issue.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/vdok3/train/tf_memn_classify.py:149: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mThis class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/vdok3/train/tf_memn_classify.py:156: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/vdok3/train/tf_memn_classify.py:156: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCall initializer instance with the dtype argument instead of passing it to the constructor\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:738: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCall initializer instance with the dtype argument instead of passing it to the constructor\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/vdok3/train/tf_memn_classify.py:385: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/vdok3/train/tf_memn_classify.py:182: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/vdok3/train/tf_memn_classify.py:394: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2020-09-27 08:31:29.405112: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[34m2020-09-27 08:31:29.412931: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300040000 Hz\u001b[0m\n",
      "\u001b[34m2020-09-27 08:31:29.413285: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6fd3a50 executing computations on platform Host. Devices:\u001b[0m\n",
      "\u001b[34m2020-09-27 08:31:29.413309: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse standard file APIs to check for files with this prefix.\u001b[0m\n",
      "\u001b[34m2020-09-27 08:31:29.523943: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/vdok3/train/tf_memn_classify.py:394: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\u001b[0m\n",
      "\u001b[35m2020-09-27 08:31:29.405112: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[35m2020-09-27 08:31:29.412931: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300040000 Hz\u001b[0m\n",
      "\u001b[35m2020-09-27 08:31:29.413285: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6fd3a50 executing computations on platform Host. Devices:\u001b[0m\n",
      "\u001b[35m2020-09-27 08:31:29.413309: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse standard file APIs to check for files with this prefix.\u001b[0m\n",
      "\u001b[35m2020-09-27 08:31:29.523943: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [27/Sep/2020:08:31:29 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [27/Sep/2020:08:31:29 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 4 records\u001b[0m\n",
      "\u001b[34m[['To', 'invent', 'stuff'], ['Someone', 'that', 'saves', 'a', 'person'], ['Something', 'that', 'is', 'not', 'possible'], ['When', 'something', 'explodes']]\u001b[0m\n",
      "\u001b[34m[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0 140 504 832]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0 116 861 749 160 665]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0 118 861 510 626 678]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0 149 805 380]]\u001b[0m\n",
      "\u001b[34m[['A', 'person', 'who', 'creates', 'something', 'new', 'that', 'has', 'never', 'been', 'made', 'before'], ['Someone', 'you', 'admire', 'because', 'they', 'have', 'done', 'an', 'action', 'that', 'is', 'brave', 'or', 'new', 'or', 'good'], ['Describes', 'something', 'that', 'is', 'very', 'difficult', 'or', 'can', 'not', 'happen'], ['It', 'means', 'to', 'explode', 'or', 'to', 'burst', 'out', 'with', 'force']]\u001b[0m\n",
      "\u001b[34m[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  15 665\n",
      "  939 314 805 620 861 448 619 217 565 218]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 116 958 172 216 867 449\n",
      "  344 185 165 861 510 243 643 620 643 430]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   33 805 861 510 914 332 643 265 626 445]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   64 581 882 379 643 882 253 646 944 409]]\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [27/Sep/2020:08:31:29 +0000] \"POST /invocations HTTP/1.1\" 200 20 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [27/Sep/2020:08:31:29 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [27/Sep/2020:08:31:29 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 4 records\u001b[0m\n",
      "\u001b[35m[['To', 'invent', 'stuff'], ['Someone', 'that', 'saves', 'a', 'person'], ['Something', 'that', 'is', 'not', 'possible'], ['When', 'something', 'explodes']]\u001b[0m\n",
      "\u001b[35m[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0 140 504 832]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0 116 861 749 160 665]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0 118 861 510 626 678]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0 149 805 380]]\u001b[0m\n",
      "\u001b[35m[['A', 'person', 'who', 'creates', 'something', 'new', 'that', 'has', 'never', 'been', 'made', 'before'], ['Someone', 'you', 'admire', 'because', 'they', 'have', 'done', 'an', 'action', 'that', 'is', 'brave', 'or', 'new', 'or', 'good'], ['Describes', 'something', 'that', 'is', 'very', 'difficult', 'or', 'can', 'not', 'happen'], ['It', 'means', 'to', 'explode', 'or', 'to', 'burst', 'out', 'with', 'force']]\u001b[0m\n",
      "\u001b[35m[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  15 665\n",
      "  939 314 805 620 861 448 619 217 565 218]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 116 958 172 216 867 449\n",
      "  344 185 165 861 510 243 643 620 643 430]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   33 805 861 510 914 332 643 265 626 445]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   64 581 882 379 643 882 253 646 944 409]]\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [27/Sep/2020:08:31:29 +0000] \"POST /invocations HTTP/1.1\" 200 20 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2020-09-27T08:31:29.538:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "Transform results: \n",
      "Score_Class\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformer.transform(data_location + '/Head4-Serialized-Def-ELVA.PILOT.POST-TEST.csv', content_type='text/csv', split_type='Line')\n",
    "transformer.wait()\n",
    "\n",
    "s3_client = sess.boto_session.client('s3')\n",
    "s3_client.download_file(sess.default_bucket(), \"{}/Head4-Serialized-Def-ELVA.PILOT.POST-TEST.csv.out\".format(transform_output_folder), '/tmp/Head4-Serialized-Def-ELVA.PILOT.POST-TEST.csv.out')\n",
    "with open('/tmp/Head4-Serialized-Def-ELVA.PILOT.POST-TEST.csv.out') as f:\n",
    "    results = f.readlines()   \n",
    "print(\"Transform results: \\n{}\".format(''.join(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
